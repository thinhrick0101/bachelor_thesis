=== Distributed Training Configuration ===
Master node: node002
Master port: 29500
World size: 16
Job nodes: node[002-007,024-026,046-052]
CUDA_VISIBLE_DEVICES: 0
========================================

Distributed Training Configuration:
Rank: 2
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 11
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 4
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 9
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 8
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 7
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 14
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 13
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 10
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 0
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 12
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 15
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 3
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 1
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 6
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163

Distributed Training Configuration:
Rank: 5
World Size: 16
Local Rank: 0
Master Address: node002.localdomain
Master Port: 34163
node002:837557:837557 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.2<0>
node002:837557:837557 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node002:837557:837557 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.2<0>
node002:837557:837557 [0] NCCL INFO Using network IB
NCCL version 2.10.3+cuda11.3
node051:702037:702037 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.51<0>
node047:704977:704977 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.47<0>
node007:684967:684967 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.7<0>
node024:3578768:3578768 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.24<0>
node006:716403:716403 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.6<0>
node005:814815:814815 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.5<0>
node025:1006765:1006765 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.25<0>
node047:704977:704977 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node052:696227:696227 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.52<0>
node049:672480:672480 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.49<0>
node050:703472:703472 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.50<0>
node003:804279:804279 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.3<0>
node006:716403:716403 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node005:814815:814815 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node007:684967:684967 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node051:702037:702037 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node049:672480:672480 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node024:3578768:3578768 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node025:1006765:1006765 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node004:782783:782783 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.4<0>
node003:804279:804279 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node048:685205:685205 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.48<0>
node046:723655:723655 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.46<0>
node050:703472:703472 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node052:696227:696227 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node004:782783:782783 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node048:685205:685205 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node046:723655:723655 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node006:716403:716403 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.6<0>
node006:716403:716403 [0] NCCL INFO Using network IB
node047:704977:704977 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.47<0>
node047:704977:704977 [0] NCCL INFO Using network IB
node007:684967:684967 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.7<0>
node007:684967:684967 [0] NCCL INFO Using network IB
node051:702037:702037 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.51<0>
node051:702037:702037 [0] NCCL INFO Using network IB
node003:804279:804279 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.3<0>
node003:804279:804279 [0] NCCL INFO Using network IB
node049:672480:672480 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.49<0>
node049:672480:672480 [0] NCCL INFO Using network IB
node005:814815:814815 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.5<0>
node005:814815:814815 [0] NCCL INFO Using network IB
node046:723655:723655 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.46<0>
node046:723655:723655 [0] NCCL INFO Using network IB
node025:1006765:1006765 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.25<0>
node025:1006765:1006765 [0] NCCL INFO Using network IB
node048:685205:685205 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.48<0>
node048:685205:685205 [0] NCCL INFO Using network IB
node050:703472:703472 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.50<0>
node050:703472:703472 [0] NCCL INFO Using network IB
node052:696227:696227 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.52<0>
node052:696227:696227 [0] NCCL INFO Using network IB
node024:3578768:3578768 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.24<0>
node024:3578768:3578768 [0] NCCL INFO Using network IB
node004:782783:782783 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.4<0>
node004:782783:782783 [0] NCCL INFO Using network IB
node026:700755:700755 [0] NCCL INFO Bootstrap : Using ib0:10.149.0.26<0>
node026:700755:700755 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node026:700755:700755 [0] NCCL INFO NET/IB : Using [0]mlx4_0:1/IB ; OOB ib0:10.149.0.26<0>
node026:700755:700755 [0] NCCL INFO Using network IB
node026:700755:700771 [0] NCCL INFO Trees [0] 4/12/-1->8->0 [1] -1/-1/-1->8->9
node046:723655:723667 [0] NCCL INFO Trees [0] -1/-1/-1->9->10 [1] 10/8/-1->9->11
node046:723655:723667 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node047:704977:704989 [0] NCCL INFO Trees [0] 9/11/-1->10->12 [1] -1/-1/-1->10->9
node047:704977:704989 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node048:685205:685217 [0] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] 13/9/-1->11->7
node048:685205:685217 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node049:672480:672492 [0] NCCL INFO Trees [0] 10/14/-1->12->8 [1] -1/-1/-1->12->13
node049:672480:672492 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node050:703472:703484 [0] NCCL INFO Trees [0] -1/-1/-1->13->14 [1] 14/12/-1->13->11
node050:703472:703484 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node051:702037:702049 [0] NCCL INFO Trees [0] 13/15/-1->14->12 [1] -1/-1/-1->14->13
node051:702037:702049 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node052:696227:696239 [0] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] 7/-1/-1->15->-1
node052:696227:696239 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node002:837557:837571 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
node002:837557:837571 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
node002:837557:837571 [0] NCCL INFO Trees [0] 8/-1/-1->0->-1 [1] -1/-1/-1->0->1
node002:837557:837571 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node003:804279:804292 [0] NCCL INFO Trees [0] -1/-1/-1->1->2 [1] 2/0/-1->1->3
node003:804279:804292 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node004:782783:782795 [0] NCCL INFO Trees [0] 1/3/-1->2->4 [1] -1/-1/-1->2->1
node004:782783:782795 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node005:814815:814827 [0] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 5/1/-1->3->7
node005:814815:814827 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node006:716403:716415 [0] NCCL INFO Trees [0] 2/6/-1->4->8 [1] -1/-1/-1->4->5
node006:716403:716415 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node007:684967:684979 [0] NCCL INFO Trees [0] -1/-1/-1->5->6 [1] 6/4/-1->5->3
node007:684967:684979 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node024:3578768:3578780 [0] NCCL INFO Trees [0] 5/7/-1->6->4 [1] -1/-1/-1->6->5
node024:3578768:3578780 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node025:1006765:1006777 [0] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 11/3/-1->7->15
node025:1006765:1006777 [0] NCCL INFO Setting affinity for GPU 0 to 0f000f
node026:700755:700771 [0] NCCL INFO Channel 00 : 7[3000] -> 8[82000] [receive] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 00 : 8[82000] -> 9[3000] [receive] via NET/IB/0
node047:704977:704989 [0] NCCL INFO Channel 00 : 9[3000] -> 10[3000] [receive] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 00 : 10[3000] -> 11[3000] [receive] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 00 : 11[3000] -> 12[3000] [receive] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 00 : 12[3000] -> 13[3000] [receive] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 00 : 13[3000] -> 14[3000] [receive] via NET/IB/0
node052:696227:696239 [0] NCCL INFO Channel 00 : 14[3000] -> 15[3000] [receive] via NET/IB/0
node004:782783:782795 [0] NCCL INFO Channel 00 : 1[3000] -> 2[3000] [receive] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 00 : 0[3000] -> 1[3000] [receive] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 00 : 2[3000] -> 3[3000] [receive] via NET/IB/0
node007:684967:684979 [0] NCCL INFO Channel 00 : 4[3000] -> 5[3000] [receive] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 00 : 3[3000] -> 4[3000] [receive] via NET/IB/0
node002:837557:837571 [0] NCCL INFO Channel 00 : 15[3000] -> 0[3000] [receive] via NET/IB/0
node024:3578768:3578780 [0] NCCL INFO Channel 00 : 5[3000] -> 6[3000] [receive] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 00 : 6[3000] -> 7[3000] [receive] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 01 : 7[3000] -> 8[82000] [receive] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 01 : 8[82000] -> 9[3000] [receive] via NET/IB/0
node047:704977:704989 [0] NCCL INFO Channel 01 : 9[3000] -> 10[3000] [receive] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 01 : 10[3000] -> 11[3000] [receive] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 01 : 11[3000] -> 12[3000] [receive] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 01 : 12[3000] -> 13[3000] [receive] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 01 : 13[3000] -> 14[3000] [receive] via NET/IB/0
node052:696227:696239 [0] NCCL INFO Channel 01 : 14[3000] -> 15[3000] [receive] via NET/IB/0
node004:782783:782795 [0] NCCL INFO Channel 01 : 1[3000] -> 2[3000] [receive] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 01 : 0[3000] -> 1[3000] [receive] via NET/IB/0
node007:684967:684979 [0] NCCL INFO Channel 01 : 4[3000] -> 5[3000] [receive] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 01 : 2[3000] -> 3[3000] [receive] via NET/IB/0
node024:3578768:3578780 [0] NCCL INFO Channel 01 : 5[3000] -> 6[3000] [receive] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 01 : 3[3000] -> 4[3000] [receive] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 01 : 6[3000] -> 7[3000] [receive] via NET/IB/0
node002:837557:837571 [0] NCCL INFO Channel 01 : 15[3000] -> 0[3000] [receive] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 00 : 8[82000] -> 9[3000] [send] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 00 : 9[3000] -> 10[3000] [send] via NET/IB/0
node047:704977:704989 [0] NCCL INFO Channel 00 : 10[3000] -> 11[3000] [send] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 00 : 11[3000] -> 12[3000] [send] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 00 : 12[3000] -> 13[3000] [send] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 00 : 13[3000] -> 14[3000] [send] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 00 : 14[3000] -> 15[3000] [send] via NET/IB/0
node052:696227:696239 [0] NCCL INFO Channel 00 : 15[3000] -> 0[3000] [send] via NET/IB/0
node004:782783:782795 [0] NCCL INFO Channel 00 : 2[3000] -> 3[3000] [send] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 00 : 1[3000] -> 2[3000] [send] via NET/IB/0
node007:684967:684979 [0] NCCL INFO Channel 00 : 5[3000] -> 6[3000] [send] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 00 : 3[3000] -> 4[3000] [send] via NET/IB/0
node024:3578768:3578780 [0] NCCL INFO Channel 00 : 6[3000] -> 7[3000] [send] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 00 : 7[3000] -> 8[82000] [send] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 00 : 4[3000] -> 5[3000] [send] via NET/IB/0
node002:837557:837571 [0] NCCL INFO Channel 00 : 0[3000] -> 1[3000] [send] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 01 : 8[82000] -> 9[3000] [send] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 01 : 9[3000] -> 10[3000] [send] via NET/IB/0
node047:704977:704989 [0] NCCL INFO Channel 01 : 10[3000] -> 11[3000] [send] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 01 : 11[3000] -> 12[3000] [send] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 01 : 12[3000] -> 13[3000] [send] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 01 : 13[3000] -> 14[3000] [send] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 01 : 14[3000] -> 15[3000] [send] via NET/IB/0
node052:696227:696239 [0] NCCL INFO Channel 01 : 15[3000] -> 0[3000] [send] via NET/IB/0
node004:782783:782795 [0] NCCL INFO Channel 01 : 2[3000] -> 3[3000] [send] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 01 : 1[3000] -> 2[3000] [send] via NET/IB/0
node007:684967:684979 [0] NCCL INFO Channel 01 : 5[3000] -> 6[3000] [send] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 01 : 3[3000] -> 4[3000] [send] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 01 : 7[3000] -> 8[82000] [send] via NET/IB/0
node024:3578768:3578780 [0] NCCL INFO Channel 01 : 6[3000] -> 7[3000] [send] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 01 : 4[3000] -> 5[3000] [send] via NET/IB/0
node002:837557:837571 [0] NCCL INFO Channel 01 : 0[3000] -> 1[3000] [send] via NET/IB/0
node047:704977:704989 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node048:685205:685217 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node049:672480:672492 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node050:703472:703484 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node051:702037:702049 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node046:723655:723667 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node047:704977:704989 [0] NCCL INFO Connected all rings
node048:685205:685217 [0] NCCL INFO Connected all rings
node049:672480:672492 [0] NCCL INFO Connected all rings
node050:703472:703484 [0] NCCL INFO Connected all rings
node007:684967:684979 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node051:702037:702049 [0] NCCL INFO Connected all rings
node046:723655:723667 [0] NCCL INFO Connected all rings
node026:700755:700771 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node025:1006765:1006777 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node024:3578768:3578780 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node005:814815:814827 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node004:782783:782795 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node006:716403:716415 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node007:684967:684979 [0] NCCL INFO Connected all rings
node003:804279:804292 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node002:837557:837571 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node052:696227:696239 [0] NCCL INFO NCCL_IB_TIMEOUT set by environment to 30.
node026:700755:700771 [0] NCCL INFO Connected all rings
node024:3578768:3578780 [0] NCCL INFO Connected all rings
node025:1006765:1006777 [0] NCCL INFO Connected all rings
node004:782783:782795 [0] NCCL INFO Connected all rings
node006:716403:716415 [0] NCCL INFO Connected all rings
node005:814815:814827 [0] NCCL INFO Connected all rings
node003:804279:804292 [0] NCCL INFO Connected all rings
node002:837557:837571 [0] NCCL INFO Connected all rings
node052:696227:696239 [0] NCCL INFO Connected all rings
node047:704977:704989 [0] NCCL INFO Channel 00 : 10[3000] -> 12[3000] [send] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 00 : 10[3000] -> 12[3000] [receive] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 01 : 9[3000] -> 11[3000] [receive] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 01 : 11[3000] -> 13[3000] [receive] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 00 : 12[3000] -> 14[3000] [receive] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 01 : 9[3000] -> 11[3000] [send] via NET/IB/0
node007:684967:684979 [0] NCCL INFO Channel 01 : 3[3000] -> 5[3000] [receive] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 00 : 4[3000] -> 8[82000] [receive] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 01 : 3[3000] -> 7[3000] [receive] via NET/IB/0
node024:3578768:3578780 [0] NCCL INFO Channel 00 : 4[3000] -> 6[3000] [receive] via NET/IB/0
node004:782783:782795 [0] NCCL INFO Channel 00 : 2[3000] -> 4[3000] [send] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 00 : 2[3000] -> 4[3000] [receive] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 01 : 1[3000] -> 3[3000] [receive] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 01 : 1[3000] -> 3[3000] [send] via NET/IB/0
node052:696227:696239 [0] NCCL INFO Channel 01 : 7[3000] -> 15[3000] [receive] via NET/IB/0
node002:837557:837571 [0] NCCL INFO Channel 00 : 8[82000] -> 0[3000] [receive] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 00 : 12[3000] -> 14[3000] [send] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 01 : 11[3000] -> 13[3000] [send] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 00 : 8[82000] -> 12[3000] [send] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 01 : 7[3000] -> 11[3000] [send] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 01 : 3[3000] -> 5[3000] [send] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 00 : 4[3000] -> 6[3000] [send] via NET/IB/0
node052:696227:696239 [0] NCCL INFO Channel 01 : 15[3000] -> 7[3000] [send] via NET/IB/0
node002:837557:837571 [0] NCCL INFO Channel 00 : 0[3000] -> 8[82000] [send] via NET/IB/0
node047:704977:704989 [0] NCCL INFO Channel 00 : 12[3000] -> 10[3000] [receive] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 01 : 11[3000] -> 9[3000] [receive] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 00 : 8[82000] -> 12[3000] [receive] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 01 : 13[3000] -> 11[3000] [send] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 00 : 14[3000] -> 12[3000] [send] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 01 : 7[3000] -> 11[3000] [receive] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 01 : 3[3000] -> 1[3000] [receive] via NET/IB/0
node004:782783:782795 [0] NCCL INFO Channel 00 : 4[3000] -> 2[3000] [receive] via NET/IB/0
node007:684967:684979 [0] NCCL INFO Channel 01 : 5[3000] -> 3[3000] [send] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 01 : 3[3000] -> 7[3000] [send] via NET/IB/0
node024:3578768:3578780 [0] NCCL INFO Channel 00 : 6[3000] -> 4[3000] [send] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 00 : 4[3000] -> 8[82000] [send] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 01 : 7[3000] -> 3[3000] [receive] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 00 : 8[82000] -> 4[3000] [receive] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 00 : 0[3000] -> 8[82000] [receive] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 01 : 11[3000] -> 7[3000] [send] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 00 : 12[3000] -> 8[82000] [send] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 01 : 15[3000] -> 7[3000] [receive] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 00 : 8[82000] -> 0[3000] [send] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 01 : 7[3000] -> 15[3000] [send] via NET/IB/0
node002:837557:837571 [0] NCCL INFO Channel 01 : 1[3000] -> 0[3000] [receive] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 00 : 12[3000] -> 8[82000] [receive] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 01 : 11[3000] -> 7[3000] [receive] via NET/IB/0
node052:696227:696239 [0] NCCL INFO Channel 00 : 15[3000] -> 14[3000] [send] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 00 : 8[82000] -> 4[3000] [send] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 01 : 7[3000] -> 3[3000] [send] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 00 : 14[3000] -> 12[3000] [receive] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 01 : 13[3000] -> 11[3000] [receive] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Channel 01 : 9[3000] -> 8[82000] [receive] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 00 : 6[3000] -> 4[3000] [receive] via NET/IB/0
node025:1006765:1006777 [0] NCCL INFO Channel 00 : 7[3000] -> 6[3000] [send] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 01 : 5[3000] -> 3[3000] [receive] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 00 : 12[3000] -> 10[3000] [send] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 01 : 11[3000] -> 9[3000] [send] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 00 : 4[3000] -> 2[3000] [send] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 01 : 3[3000] -> 1[3000] [send] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 00 : 15[3000] -> 14[3000] [receive] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 00 : 14[3000] -> 13[3000] [receive] via NET/IB/0
node049:672480:672492 [0] NCCL INFO Channel 01 : 13[3000] -> 12[3000] [receive] via NET/IB/0
node047:704977:704989 [0] NCCL INFO Channel 00 : 11[3000] -> 10[3000] [receive] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 00 : 10[3000] -> 9[3000] [receive] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Channel 00 : 11[3000] -> 10[3000] [send] via NET/IB/0
node024:3578768:3578780 [0] NCCL INFO Channel 00 : 7[3000] -> 6[3000] [receive] via NET/IB/0
node007:684967:684979 [0] NCCL INFO Channel 00 : 6[3000] -> 5[3000] [receive] via NET/IB/0
node004:782783:782795 [0] NCCL INFO Channel 00 : 3[3000] -> 2[3000] [receive] via NET/IB/0
node006:716403:716415 [0] NCCL INFO Channel 01 : 5[3000] -> 4[3000] [receive] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 00 : 2[3000] -> 1[3000] [receive] via NET/IB/0
node005:814815:814827 [0] NCCL INFO Channel 00 : 3[3000] -> 2[3000] [send] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 00 : 14[3000] -> 13[3000] [send] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 01 : 14[3000] -> 13[3000] [receive] via NET/IB/0
node047:704977:704989 [0] NCCL INFO Channel 00 : 10[3000] -> 9[3000] [send] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 01 : 10[3000] -> 9[3000] [receive] via NET/IB/0
node024:3578768:3578780 [0] NCCL INFO Channel 00 : 6[3000] -> 5[3000] [send] via NET/IB/0
node007:684967:684979 [0] NCCL INFO Channel 01 : 6[3000] -> 5[3000] [receive] via NET/IB/0
node004:782783:782795 [0] NCCL INFO Channel 00 : 2[3000] -> 1[3000] [send] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 01 : 2[3000] -> 1[3000] [receive] via NET/IB/0
node051:702037:702049 [0] NCCL INFO Channel 01 : 14[3000] -> 13[3000] [send] via NET/IB/0
node050:703472:703484 [0] NCCL INFO Channel 01 : 13[3000] -> 12[3000] [send] via NET/IB/0
node047:704977:704989 [0] NCCL INFO Channel 01 : 10[3000] -> 9[3000] [send] via NET/IB/0
node046:723655:723667 [0] NCCL INFO Channel 01 : 9[3000] -> 8[82000] [send] via NET/IB/0
node052:696227:696239 [0] NCCL INFO Connected all trees
node052:696227:696239 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node052:696227:696239 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node052:696227:696239 [0] NCCL INFO comm 0x7f561c003040 rank 15 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node024:3578768:3578780 [0] NCCL INFO Channel 01 : 6[3000] -> 5[3000] [send] via NET/IB/0
node048:685205:685217 [0] NCCL INFO Connected all trees
node048:685205:685217 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node048:685205:685217 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node007:684967:684979 [0] NCCL INFO Channel 01 : 5[3000] -> 4[3000] [send] via NET/IB/0
node048:685205:685217 [0] NCCL INFO comm 0x7f589c003040 rank 11 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node004:782783:782795 [0] NCCL INFO Channel 01 : 2[3000] -> 1[3000] [send] via NET/IB/0
node003:804279:804292 [0] NCCL INFO Channel 01 : 1[3000] -> 0[3000] [send] via NET/IB/0
node026:700755:700771 [0] NCCL INFO Connected all trees
node051:702037:702049 [0] NCCL INFO Connected all trees
node051:702037:702049 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node051:702037:702049 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node026:700755:700771 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node026:700755:700771 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node026:700755:700771 [0] NCCL INFO comm 0x7fbccc003040 rank 8 nranks 16 cudaDev 0 busId 82000 - Init COMPLETE
node050:703472:703484 [0] NCCL INFO Connected all trees
node050:703472:703484 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node051:702037:702049 [0] NCCL INFO comm 0x7fc08c003040 rank 14 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node050:703472:703484 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node050:703472:703484 [0] NCCL INFO comm 0x7fde98003040 rank 13 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node049:672480:672492 [0] NCCL INFO Connected all trees
node049:672480:672492 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node049:672480:672492 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node005:814815:814827 [0] NCCL INFO Connected all trees
node005:814815:814827 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node005:814815:814827 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node049:672480:672492 [0] NCCL INFO comm 0x7f2728003040 rank 12 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node047:704977:704989 [0] NCCL INFO Connected all trees
node047:704977:704989 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node047:704977:704989 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node046:723655:723667 [0] NCCL INFO Connected all trees
node046:723655:723667 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node046:723655:723667 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node025:1006765:1006777 [0] NCCL INFO Connected all trees
node025:1006765:1006777 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node025:1006765:1006777 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node047:704977:704989 [0] NCCL INFO comm 0x7fc488003040 rank 10 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node046:723655:723667 [0] NCCL INFO comm 0x7efd08003040 rank 9 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node025:1006765:1006777 [0] NCCL INFO comm 0x7f0304003040 rank 7 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node005:814815:814827 [0] NCCL INFO comm 0x7f16a4003040 rank 3 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node006:716403:716415 [0] NCCL INFO Connected all trees
node006:716403:716415 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node006:716403:716415 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node006:716403:716415 [0] NCCL INFO comm 0x7faea8003040 rank 4 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node007:684967:684979 [0] NCCL INFO Connected all trees
node007:684967:684979 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node007:684967:684979 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node007:684967:684979 [0] NCCL INFO comm 0x7f71f0003040 rank 5 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node024:3578768:3578780 [0] NCCL INFO Connected all trees
node024:3578768:3578780 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node002:837557:837571 [0] NCCL INFO Connected all trees
node024:3578768:3578780 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node002:837557:837571 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node002:837557:837571 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node024:3578768:3578780 [0] NCCL INFO comm 0x7f643c003040 rank 6 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node002:837557:837571 [0] NCCL INFO comm 0x7f1e54003040 rank 0 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node002:837557:837557 [0] NCCL INFO Launch mode Parallel
node003:804279:804292 [0] NCCL INFO Connected all trees
node003:804279:804292 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node003:804279:804292 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node003:804279:804292 [0] NCCL INFO comm 0x7efbc0003040 rank 1 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
node004:782783:782795 [0] NCCL INFO Connected all trees
node004:782783:782795 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 8/8/512
node004:782783:782795 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer
node004:782783:782795 [0] NCCL INFO comm 0x7fd558003040 rank 2 nranks 16 cudaDev 0 busId 3000 - Init COMPLETE
Process 0/16 initialized successfully
Process 0 using device: cuda:0
Process 8/16 initialized successfully
Loading data...
Process 8 using device: cuda:0
Process 4/16 initialized successfully
Process 12/16 initialized successfully
Process 4 using device: cuda:0
Process 12 using device: cuda:0
Process 2/16 initialized successfully
Process 6/16 initialized successfully
Process 10/16 initialized successfully
Process 2 using device: cuda:0
Process 14/16 initialized successfully
Process 10 using device: cuda:0
Process 14 using device: cuda:0
Loading data from data/enwik8
Process 6 using device: cuda:0
Process 3/16 initialized successfully
Process 1/16 initialized successfully
Process 5/16 initialized successfully
Process 9/16 initialized successfully
Process 7/16 initialized successfully
Process 3 using device: cuda:0
Process 11/16 initialized successfully
Process 1 using device: cuda:0
Process 9 using device: cuda:0
Process 15/16 initialized successfully
Process 7 using device: cuda:0
Process 5 using device: cuda:0
Process 11 using device: cuda:0
Process 13/16 initialized successfully
Process 15 using device: cuda:0
Process 13 using device: cuda:0
Data loaded: 99621832 bytes
Rank 5: Loading data...
Rank 4: Loading data...
Rank 8: Loading data...
Rank 2: Loading data...
Rank 1: Loading data...
Rank 14: Loading data...
Rank 3: Loading data...
Rank 10: Loading data...
Rank 9: Loading data...
Rank 12: Loading data...
Rank 13: Loading data...
Rank 15: Loading data...
Rank 6: Loading data...
Rank 11: Loading data...
Rank 7: Loading data...
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Loading data from data/enwik8
Rank 13: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 4: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 2: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 9: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 12: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 15: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 8: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 14: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 6: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 10: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 11: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 3: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Rank 5: Data loaded: 99621832 bytes
Rank 1: Data loaded: 99621832 bytes
Creating byte tokenizer...
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Vocabulary size: 256 bytes (fixed)
Encoding text...
Encoding text...
Rank 7: Data loaded: 99621832 bytes
Creating byte tokenizer...
Vocabulary size: 256 bytes (fixed)
Encoding text...
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Rank 0: Created 2745 batches from sequence range 0-5493
Rank 0: Created 303 batches from sequence range 0-610
Created 2745 training batches and 303 validation batches
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Byte 0: < (ID: 60)
Sample text length: 100 bytes
Encoded length: 100 tokens
Byte 1: m (ID: 109)
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Byte 0: < (ID: 60)
Sample text length: 100 bytes
Byte 1: m (ID: 109)
Encoded length: 100 tokens
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Token-to-byte ratio: 1.00

Byte 7: i (ID: 105)
Example byte values (first 10):
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Rank 4: Created 2745 batches from sequence range 21972-27465
Rank 9: Created 2745 batches from sequence range 49437-54930
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Rank 4: Created 303 batches from sequence range 2440-3050
Created 2745 training batches and 303 validation batches
Rank 9: Created 303 batches from sequence range 5490-6100
Created 2745 training batches and 303 validation batches
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Rank 15: Created 2745 batches from sequence range 82395-87888
Rank 11: Created 2745 batches from sequence range 60423-65916
Rank 15: Created 303 batches from sequence range 9150-9760
Created 2745 training batches and 303 validation batches
Rank 8: Created 2745 batches from sequence range 43944-49437
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Rank 5: Created 2745 batches from sequence range 27465-32958
Rank 11: Created 303 batches from sequence range 6710-7320
Created 2745 training batches and 303 validation batches
Rank 8: Created 303 batches from sequence range 4880-5490
Created 2745 training batches and 303 validation batches
Rank 5: Created 303 batches from sequence range 3050-3660
Created 2745 training batches and 303 validation batches
Rank 13: Created 2745 batches from sequence range 71409-76902
Rank 13: Created 303 batches from sequence range 7930-8540
Created 2745 training batches and 303 validation batches
Rank 12: Created 2745 batches from sequence range 65916-71409
Rank 6: Created 2745 batches from sequence range 32958-38451
Rank 14: Created 2745 batches from sequence range 76902-82395
Rank 12: Created 303 batches from sequence range 7320-7930
Created 2745 training batches and 303 validation batches
Rank 6: Created 303 batches from sequence range 3660-4270
Created 2745 training batches and 303 validation batches
Rank 14: Created 303 batches from sequence range 8540-9150
Created 2745 training batches and 303 validation batches
Rank 10: Created 2745 batches from sequence range 54930-60423
Rank 10: Created 303 batches from sequence range 6100-6710
Created 2745 training batches and 303 validation batches
Rank 1: Created 2745 batches from sequence range 5493-10986
Rank 1: Created 303 batches from sequence range 610-1220
Created 2745 training batches and 303 validation batches
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Rank 2: Created 2745 batches from sequence range 10986-16479
Rank 2: Created 303 batches from sequence range 1220-1830
Created 2745 training batches and 303 validation batches
Rank 3: Created 2745 batches from sequence range 16479-21972
Rank 3: Created 303 batches from sequence range 1830-2440
Created 2745 training batches and 303 validation batches
Encoded length: 100000000 tokens

Analyzing byte-level tokenization...
Sample text length: 100 bytes
Encoded length: 100 tokens
Token-to-byte ratio: 1.00

Example byte values (first 10):
Byte 0: < (ID: 60)
Byte 1: m (ID: 109)
Byte 2: e (ID: 101)
Byte 3: d (ID: 100)
Byte 4: i (ID: 105)
Byte 5: a (ID: 97)
Byte 6: w (ID: 119)
Byte 7: i (ID: 105)
Byte 8: k (ID: 107)
Byte 9: i (ID: 105)
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Rank 7: Created 2745 batches from sequence range 38451-43944
Rank 7: Created 303 batches from sequence range 4270-4880
Created 2745 training batches and 303 validation batches
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
Model Parameters: 63,677,721 trainable out of 63,677,721 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda:0
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 16
[Rank 8] Epoch 1/100, Batch 10/2745, Loss: 5.6367
[Rank 14] Epoch 1/100, Batch 10/2745, Loss: 5.4363
[Rank 11] Epoch 1/100, Batch 10/2745, Loss: 5.6533
[Rank 2] Epoch 1/100, Batch 10/2745, Loss: 5.6566
[Rank 9] Epoch 1/100, Batch 10/2745, Loss: 5.5576
[Rank 3] Epoch 1/100, Batch 10/2745, Loss: 5.5899
[Rank 7] Epoch 1/100, Batch 10/2745, Loss: 5.5070
[Rank 1] Epoch 1/100, Batch 10/2745, Loss: 5.5019
[Rank 4] Epoch 1/100, Batch 10/2745, Loss: 5.6086
[Rank 5] Epoch 1/100, Batch 10/2745, Loss: 5.4877
[Rank 12] Epoch 1/100, Batch 10/2745, Loss: 5.6076
[Rank 15] Epoch 1/100, Batch 10/2745, Loss: 5.5646
[Rank 0] Epoch 1/100, Batch 10/2745, Loss: 5.5752
[Rank 13] Epoch 1/100, Batch 10/2745, Loss: 5.4357
[Rank 6] Epoch 1/100, Batch 10/2745, Loss: 5.3180
[Rank 10] Epoch 1/100, Batch 10/2745, Loss: 5.4364
[Rank 8] Epoch 1/100, Batch 20/2745, Loss: 5.5851
[Rank 8] Epoch 1/100, Batch 30/2745, Loss: 5.6124
[Rank 14] Epoch 1/100, Batch 20/2745, Loss: 5.5244
[Rank 11] Epoch 1/100, Batch 20/2745, Loss: 5.7059
[Rank 4] Epoch 1/100, Batch 20/2745, Loss: 5.6102
[Rank 5] Epoch 1/100, Batch 20/2745, Loss: 5.6132
[Rank 1] Epoch 1/100, Batch 20/2745, Loss: 5.5646
[Rank 2] Epoch 1/100, Batch 20/2745, Loss: 5.6527
[Rank 13] Epoch 1/100, Batch 20/2745, Loss: 5.4941
[Rank 9] Epoch 1/100, Batch 20/2745, Loss: 5.5333
[Rank 3] Epoch 1/100, Batch 20/2745, Loss: 5.5554
[Rank 7] Epoch 1/100, Batch 20/2745, Loss: 5.5200
[Rank 6] Epoch 1/100, Batch 20/2745, Loss: 5.5443
[Rank 15] Epoch 1/100, Batch 20/2745, Loss: 5.5588
[Rank 12] Epoch 1/100, Batch 20/2745, Loss: 5.6223
[Rank 10] Epoch 1/100, Batch 20/2745, Loss: 5.5429
[Rank 0] Epoch 1/100, Batch 20/2745, Loss: 5.5704
[Rank 8] Epoch 1/100, Batch 40/2745, Loss: 5.6346
[Rank 14] Epoch 1/100, Batch 30/2745, Loss: 5.5181
[Rank 13] Epoch 1/100, Batch 30/2745, Loss: 5.4387
[Rank 11] Epoch 1/100, Batch 30/2745, Loss: 5.6319
[Rank 4] Epoch 1/100, Batch 30/2745, Loss: 5.6216
[Rank 7] Epoch 1/100, Batch 30/2745, Loss: 5.4719
[Rank 3] Epoch 1/100, Batch 30/2745, Loss: 5.6088
[Rank 1] Epoch 1/100, Batch 30/2745, Loss: 5.5837
[Rank 9] Epoch 1/100, Batch 30/2745, Loss: 5.4689
[Rank 5] Epoch 1/100, Batch 30/2745, Loss: 5.3690
[Rank 12] Epoch 1/100, Batch 30/2745, Loss: 5.5672
[Rank 2] Epoch 1/100, Batch 30/2745, Loss: 5.6563
[Rank 6] Epoch 1/100, Batch 30/2745, Loss: 5.5505
[Rank 0] Epoch 1/100, Batch 30/2745, Loss: 5.4413
[Rank 15] Epoch 1/100, Batch 30/2745, Loss: 5.5770
[Rank 10] Epoch 1/100, Batch 30/2745, Loss: 5.5582
[Rank 8] Epoch 1/100, Batch 50/2745, Loss: 5.5627
[Rank 8] Epoch 1/100, Batch 60/2745, Loss: 5.6417
[Rank 14] Epoch 1/100, Batch 40/2745, Loss: 5.5041
[Rank 9] Epoch 1/100, Batch 40/2745, Loss: 5.3435
[Rank 11] Epoch 1/100, Batch 40/2745, Loss: 5.5294
[Rank 4] Epoch 1/100, Batch 40/2745, Loss: 5.6252
[Rank 13] Epoch 1/100, Batch 40/2745, Loss: 5.5029
[Rank 5] Epoch 1/100, Batch 40/2745, Loss: 5.4316
[Rank 7] Epoch 1/100, Batch 40/2745, Loss: 5.4840
[Rank 1] Epoch 1/100, Batch 40/2745, Loss: 5.5290
[Rank 12] Epoch 1/100, Batch 40/2745, Loss: 5.6377
[Rank 0] Epoch 1/100, Batch 40/2745, Loss: 5.5517
[Rank 6] Epoch 1/100, Batch 40/2745, Loss: 5.5091
[Rank 3] Epoch 1/100, Batch 40/2745, Loss: 5.4172
[Rank 2] Epoch 1/100, Batch 40/2745, Loss: 5.5140
[Rank 10] Epoch 1/100, Batch 40/2745, Loss: 5.5111
[Rank 15] Epoch 1/100, Batch 40/2745, Loss: 5.5039
[Rank 8] Epoch 1/100, Batch 70/2745, Loss: 5.4778
[Rank 9] Epoch 1/100, Batch 50/2745, Loss: 5.5432
[Rank 5] Epoch 1/100, Batch 50/2745, Loss: 5.3210
[Rank 14] Epoch 1/100, Batch 50/2745, Loss: 5.5460
[Rank 13] Epoch 1/100, Batch 50/2745, Loss: 5.4198
[Rank 4] Epoch 1/100, Batch 50/2745, Loss: 5.6663
[Rank 3] Epoch 1/100, Batch 50/2745, Loss: 5.5708
[Rank 7] Epoch 1/100, Batch 50/2745, Loss: 5.4827
[Rank 0] Epoch 1/100, Batch 50/2745, Loss: 5.5495
[Rank 1] Epoch 1/100, Batch 50/2745, Loss: 5.6734
[Rank 6] Epoch 1/100, Batch 50/2745, Loss: 5.5391
[Rank 11] Epoch 1/100, Batch 50/2745, Loss: 5.5989
[Rank 12] Epoch 1/100, Batch 50/2745, Loss: 5.6080
[Rank 10] Epoch 1/100, Batch 50/2745, Loss: 5.5187
[Rank 2] Epoch 1/100, Batch 50/2745, Loss: 5.4973
[Rank 15] Epoch 1/100, Batch 50/2745, Loss: 5.5193
[Rank 8] Epoch 1/100, Batch 80/2745, Loss: 5.5859
[Rank 8] Epoch 1/100, Batch 90/2745, Loss: 5.5945
[Rank 9] Epoch 1/100, Batch 60/2745, Loss: 5.5760
[Rank 4] Epoch 1/100, Batch 60/2745, Loss: 5.5690
[Rank 5] Epoch 1/100, Batch 60/2745, Loss: 5.5193
[Rank 13] Epoch 1/100, Batch 60/2745, Loss: 5.5278
[Rank 14] Epoch 1/100, Batch 60/2745, Loss: 5.4500
[Rank 0] Epoch 1/100, Batch 60/2745, Loss: 5.4434
[Rank 11] Epoch 1/100, Batch 60/2745, Loss: 5.6732
[Rank 3] Epoch 1/100, Batch 60/2745, Loss: 5.4186
[Rank 6] Epoch 1/100, Batch 60/2745, Loss: 5.5356
[Rank 1] Epoch 1/100, Batch 60/2745, Loss: 5.4824
[Rank 7] Epoch 1/100, Batch 60/2745, Loss: 5.4925
[Rank 12] Epoch 1/100, Batch 60/2745, Loss: 5.5507
[Rank 10] Epoch 1/100, Batch 60/2745, Loss: 5.4737
[Rank 15] Epoch 1/100, Batch 60/2745, Loss: 5.5550
[Rank 2] Epoch 1/100, Batch 60/2745, Loss: 5.5980
[Rank 8] Epoch 1/100, Batch 100/2745, Loss: 5.4355
[Rank 9] Epoch 1/100, Batch 70/2745, Loss: 5.5219
[Rank 4] Epoch 1/100, Batch 70/2745, Loss: 5.6732
[Rank 11] Epoch 1/100, Batch 70/2745, Loss: 5.4910
[Rank 5] Epoch 1/100, Batch 70/2745, Loss: 5.5010
[Rank 13] Epoch 1/100, Batch 70/2745, Loss: 5.3668
[Rank 14] Epoch 1/100, Batch 70/2745, Loss: 5.4878
[Rank 6] Epoch 1/100, Batch 70/2745, Loss: 5.5386
[Rank 0] Epoch 1/100, Batch 70/2745, Loss: 5.5563
[Rank 1] Epoch 1/100, Batch 70/2745, Loss: 5.6178
[Rank 3] Epoch 1/100, Batch 70/2745, Loss: 5.4974
[Rank 12] Epoch 1/100, Batch 70/2745, Loss: 5.5401
[Rank 7] Epoch 1/100, Batch 70/2745, Loss: 5.5053
[Rank 15] Epoch 1/100, Batch 70/2745, Loss: 5.5038
[Rank 10] Epoch 1/100, Batch 70/2745, Loss: 5.4933
[Rank 2] Epoch 1/100, Batch 70/2745, Loss: 5.6139
[Rank 9] Epoch 1/100, Batch 80/2745, Loss: 5.5587
[Rank 4] Epoch 1/100, Batch 80/2745, Loss: 5.6459
[Rank 5] Epoch 1/100, Batch 80/2745, Loss: 5.5336
[Rank 11] Epoch 1/100, Batch 80/2745, Loss: 5.6949
[Rank 13] Epoch 1/100, Batch 80/2745, Loss: 5.4954
[Rank 14] Epoch 1/100, Batch 80/2745, Loss: 5.5316
[Rank 0] Epoch 1/100, Batch 80/2745, Loss: 5.5368
[Rank 6] Epoch 1/100, Batch 80/2745, Loss: 5.3887
[Rank 1] Epoch 1/100, Batch 80/2745, Loss: 5.5477
[Rank 3] Epoch 1/100, Batch 80/2745, Loss: 5.5817
[Rank 7] Epoch 1/100, Batch 80/2745, Loss: 5.5573
[Rank 12] Epoch 1/100, Batch 80/2745, Loss: 5.5940
[Rank 2] Epoch 1/100, Batch 80/2745, Loss: 5.5130
[Rank 10] Epoch 1/100, Batch 80/2745, Loss: 5.5449
[Rank 15] Epoch 1/100, Batch 80/2745, Loss: 5.4718
[Rank 9] Epoch 1/100, Batch 90/2745, Loss: 5.5053
[Rank 4] Epoch 1/100, Batch 90/2745, Loss: 5.5758
[Rank 5] Epoch 1/100, Batch 90/2745, Loss: 5.5192
[Rank 11] Epoch 1/100, Batch 90/2745, Loss: 5.5532
[Rank 13] Epoch 1/100, Batch 90/2745, Loss: 5.3412
[Rank 0] Epoch 1/100, Batch 90/2745, Loss: 5.5626
[Rank 14] Epoch 1/100, Batch 90/2745, Loss: 5.5218
[Rank 1] Epoch 1/100, Batch 90/2745, Loss: 5.5405
[Rank 6] Epoch 1/100, Batch 90/2745, Loss: 5.5575
[Rank 3] Epoch 1/100, Batch 90/2745, Loss: 5.4503
[Rank 2] Epoch 1/100, Batch 90/2745, Loss: 5.5389
[Rank 12] Epoch 1/100, Batch 90/2745, Loss: 5.5730
[Rank 7] Epoch 1/100, Batch 90/2745, Loss: 5.4799
[Rank 15] Epoch 1/100, Batch 90/2745, Loss: 5.3930
[Rank 10] Epoch 1/100, Batch 90/2745, Loss: 5.5376
[Rank 9] Epoch 1/100, Batch 100/2745, Loss: 5.4894
[Rank 4] Epoch 1/100, Batch 100/2745, Loss: 5.6844
[Rank 5] Epoch 1/100, Batch 100/2745, Loss: 5.4802
[Rank 11] Epoch 1/100, Batch 100/2745, Loss: 5.5627
[Rank 14] Epoch 1/100, Batch 100/2745, Loss: 5.4491
[Rank 13] Epoch 1/100, Batch 100/2745, Loss: 5.4598
[Rank 0] Epoch 1/100, Batch 100/2745, Loss: 5.4783
[Rank 3] Epoch 1/100, Batch 100/2745, Loss: 5.5785
[Rank 1] Epoch 1/100, Batch 100/2745, Loss: 5.5421
[Rank 6] Epoch 1/100, Batch 100/2745, Loss: 5.4995
[Rank 7] Epoch 1/100, Batch 100/2745, Loss: 5.5609
[Rank 15] Epoch 1/100, Batch 100/2745, Loss: 5.5687
[Rank 12] Epoch 1/100, Batch 100/2745, Loss: 5.5043
[Rank 2] Epoch 1/100, Batch 100/2745, Loss: 5.5202
[Rank 10] Epoch 1/100, Batch 100/2745, Loss: 5.5304
[Rank 8] Epoch 1/100, Batch 110/2745, Loss: 5.5452
[Rank 5] Epoch 1/100, Batch 110/2745, Loss: 5.4552
[Rank 10] Epoch 1/100, Batch 110/2745, Loss: 5.5826
[Rank 3] Epoch 1/100, Batch 110/2745, Loss: 5.4718
[Rank 12] Epoch 1/100, Batch 110/2745, Loss: 5.6326
[Rank 9] Epoch 1/100, Batch 110/2745, Loss: 5.5572
[Rank 15] Epoch 1/100, Batch 110/2745, Loss: 5.5515
[Rank 4] Epoch 1/100, Batch 110/2745, Loss: 5.6083
[Rank 14] Epoch 1/100, Batch 110/2745, Loss: 5.4766
[Rank 0] Epoch 1/100, Batch 110/2745, Loss: 5.5433
[Rank 7] Epoch 1/100, Batch 110/2745, Loss: 5.4962
[Rank 6] Epoch 1/100, Batch 110/2745, Loss: 5.5394
[Rank 11] Epoch 1/100, Batch 110/2745, Loss: 5.6386
[Rank 2] Epoch 1/100, Batch 110/2745, Loss: 5.7088
[Rank 1] Epoch 1/100, Batch 110/2745, Loss: 5.5730
[Rank 13] Epoch 1/100, Batch 110/2745, Loss: 5.4403
[Rank 8] Epoch 1/100, Batch 120/2745, Loss: 5.5704
[Rank 5] Epoch 1/100, Batch 120/2745, Loss: 5.4706
[Rank 8] Epoch 1/100, Batch 130/2745, Loss: 5.6062
[Rank 10] Epoch 1/100, Batch 120/2745, Loss: 5.5156
[Rank 0] Epoch 1/100, Batch 120/2745, Loss: 5.3098
[Rank 3] Epoch 1/100, Batch 120/2745, Loss: 5.4537
[Rank 14] Epoch 1/100, Batch 120/2745, Loss: 5.5262
[Rank 9] Epoch 1/100, Batch 120/2745, Loss: 5.5023
[Rank 2] Epoch 1/100, Batch 120/2745, Loss: 5.6621
[Rank 4] Epoch 1/100, Batch 120/2745, Loss: 5.6258
[Rank 15] Epoch 1/100, Batch 120/2745, Loss: 5.4726
[Rank 6] Epoch 1/100, Batch 120/2745, Loss: 5.3791
[Rank 11] Epoch 1/100, Batch 120/2745, Loss: 5.6146
[Rank 7] Epoch 1/100, Batch 120/2745, Loss: 5.4870
[Rank 13] Epoch 1/100, Batch 120/2745, Loss: 5.3660
[Rank 1] Epoch 1/100, Batch 120/2745, Loss: 5.6180
[Rank 12] Epoch 1/100, Batch 120/2745, Loss: 5.6115
[Rank 8] Epoch 1/100, Batch 140/2745, Loss: 5.6079
[Rank 5] Epoch 1/100, Batch 130/2745, Loss: 5.5029
[Rank 0] Epoch 1/100, Batch 130/2745, Loss: 5.4911
[Rank 10] Epoch 1/100, Batch 130/2745, Loss: 5.5259
[Rank 9] Epoch 1/100, Batch 130/2745, Loss: 5.5562
[Rank 14] Epoch 1/100, Batch 130/2745, Loss: 5.5044
[Rank 4] Epoch 1/100, Batch 130/2745, Loss: 5.5910
[Rank 15] Epoch 1/100, Batch 130/2745, Loss: 5.4555
[Rank 3] Epoch 1/100, Batch 130/2745, Loss: 5.5883
[Rank 2] Epoch 1/100, Batch 130/2745, Loss: 5.6317
[Rank 11] Epoch 1/100, Batch 130/2745, Loss: 5.5951
[Rank 7] Epoch 1/100, Batch 130/2745, Loss: 5.5227
[Rank 13] Epoch 1/100, Batch 130/2745, Loss: 5.4652
[Rank 1] Epoch 1/100, Batch 130/2745, Loss: 5.5246
[Rank 6] Epoch 1/100, Batch 130/2745, Loss: 5.4916
[Rank 12] Epoch 1/100, Batch 130/2745, Loss: 5.3744
[Rank 8] Epoch 1/100, Batch 150/2745, Loss: 5.6366
[Rank 8] Epoch 1/100, Batch 160/2745, Loss: 5.6264
[Rank 9] Epoch 1/100, Batch 140/2745, Loss: 5.4557
[Rank 0] Epoch 1/100, Batch 140/2745, Loss: 5.3982
[Rank 5] Epoch 1/100, Batch 140/2745, Loss: 5.3815
[Rank 10] Epoch 1/100, Batch 140/2745, Loss: 5.4382
[Rank 14] Epoch 1/100, Batch 140/2745, Loss: 5.5136
[Rank 15] Epoch 1/100, Batch 140/2745, Loss: 5.5431
[Rank 11] Epoch 1/100, Batch 140/2745, Loss: 5.6803
[Rank 3] Epoch 1/100, Batch 140/2745, Loss: 5.5955
[Rank 4] Epoch 1/100, Batch 140/2745, Loss: 5.6755
[Rank 2] Epoch 1/100, Batch 140/2745, Loss: 5.6018
[Rank 1] Epoch 1/100, Batch 140/2745, Loss: 5.5207
[Rank 13] Epoch 1/100, Batch 140/2745, Loss: 5.5004
[Rank 7] Epoch 1/100, Batch 140/2745, Loss: 5.5105
[Rank 6] Epoch 1/100, Batch 140/2745, Loss: 5.4685
[Rank 12] Epoch 1/100, Batch 140/2745, Loss: 5.5913
[Rank 8] Epoch 1/100, Batch 170/2745, Loss: 5.5845
[Rank 9] Epoch 1/100, Batch 150/2745, Loss: 5.4739
[Rank 5] Epoch 1/100, Batch 150/2745, Loss: 5.4828
[Rank 0] Epoch 1/100, Batch 150/2745, Loss: 5.2868
[Rank 10] Epoch 1/100, Batch 150/2745, Loss: 5.5182
[Rank 14] Epoch 1/100, Batch 150/2745, Loss: 5.5167
[Rank 15] Epoch 1/100, Batch 150/2745, Loss: 5.5088
[Rank 11] Epoch 1/100, Batch 150/2745, Loss: 5.6065
[Rank 1] Epoch 1/100, Batch 150/2745, Loss: 5.5922
[Rank 13] Epoch 1/100, Batch 150/2745, Loss: 5.3637
[Rank 7] Epoch 1/100, Batch 150/2745, Loss: 5.4081
[Rank 2] Epoch 1/100, Batch 150/2745, Loss: 5.6448
[Rank 3] Epoch 1/100, Batch 150/2745, Loss: 5.4313
[Rank 4] Epoch 1/100, Batch 150/2745, Loss: 5.5646
[Rank 6] Epoch 1/100, Batch 150/2745, Loss: 5.5140
[Rank 8] Epoch 1/100, Batch 180/2745, Loss: 5.6072
[Rank 12] Epoch 1/100, Batch 150/2745, Loss: 5.5726
[Rank 8] Epoch 1/100, Batch 190/2745, Loss: 5.5518
[Rank 5] Epoch 1/100, Batch 160/2745, Loss: 5.4960
[Rank 9] Epoch 1/100, Batch 160/2745, Loss: 5.5415
[Rank 10] Epoch 1/100, Batch 160/2745, Loss: 5.5124
[Rank 0] Epoch 1/100, Batch 160/2745, Loss: 5.3666
[Rank 15] Epoch 1/100, Batch 160/2745, Loss: 5.5331
[Rank 14] Epoch 1/100, Batch 160/2745, Loss: 5.5243
[Rank 13] Epoch 1/100, Batch 160/2745, Loss: 5.3133
[Rank 3] Epoch 1/100, Batch 160/2745, Loss: 5.5499
[Rank 1] Epoch 1/100, Batch 160/2745, Loss: 5.6002
[Rank 11] Epoch 1/100, Batch 160/2745, Loss: 5.5985
[Rank 2] Epoch 1/100, Batch 160/2745, Loss: 5.6907
[Rank 7] Epoch 1/100, Batch 160/2745, Loss: 5.4655
[Rank 4] Epoch 1/100, Batch 160/2745, Loss: 5.5989
[Rank 6] Epoch 1/100, Batch 160/2745, Loss: 5.5440
[Rank 12] Epoch 1/100, Batch 160/2745, Loss: 5.5327
[Rank 8] Epoch 1/100, Batch 200/2745, Loss: 5.3827
[Rank 5] Epoch 1/100, Batch 170/2745, Loss: 5.3780
[Rank 10] Epoch 1/100, Batch 170/2745, Loss: 5.5052
[Rank 9] Epoch 1/100, Batch 170/2745, Loss: 5.5350
[Rank 0] Epoch 1/100, Batch 170/2745, Loss: 5.4086
[Rank 14] Epoch 1/100, Batch 170/2745, Loss: 5.5134
[Rank 15] Epoch 1/100, Batch 170/2745, Loss: 5.5370
[Rank 13] Epoch 1/100, Batch 170/2745, Loss: 5.4845
[Rank 3] Epoch 1/100, Batch 170/2745, Loss: 5.4891
[Rank 1] Epoch 1/100, Batch 170/2745, Loss: 5.5016
[Rank 7] Epoch 1/100, Batch 170/2745, Loss: 5.5523
[Rank 2] Epoch 1/100, Batch 170/2745, Loss: 5.6358
[Rank 11] Epoch 1/100, Batch 170/2745, Loss: 5.6077
[Rank 4] Epoch 1/100, Batch 170/2745, Loss: 5.6131
[Rank 6] Epoch 1/100, Batch 170/2745, Loss: 5.5350
[Rank 12] Epoch 1/100, Batch 170/2745, Loss: 5.5021
[Rank 5] Epoch 1/100, Batch 180/2745, Loss: 5.4917
[Rank 9] Epoch 1/100, Batch 180/2745, Loss: 5.4353
[Rank 10] Epoch 1/100, Batch 180/2745, Loss: 5.4684
[Rank 0] Epoch 1/100, Batch 180/2745, Loss: 5.4891
[Rank 14] Epoch 1/100, Batch 180/2745, Loss: 5.5167
[Rank 13] Epoch 1/100, Batch 180/2745, Loss: 5.4150
[Rank 15] Epoch 1/100, Batch 180/2745, Loss: 5.5781
[Rank 3] Epoch 1/100, Batch 180/2745, Loss: 5.5624
[Rank 2] Epoch 1/100, Batch 180/2745, Loss: 5.4369
[Rank 1] Epoch 1/100, Batch 180/2745, Loss: 5.5540
[Rank 7] Epoch 1/100, Batch 180/2745, Loss: 5.5226
[Rank 11] Epoch 1/100, Batch 180/2745, Loss: 5.5325
[Rank 4] Epoch 1/100, Batch 180/2745, Loss: 5.6792
[Rank 6] Epoch 1/100, Batch 180/2745, Loss: 5.4950
[Rank 12] Epoch 1/100, Batch 180/2745, Loss: 5.5875
[Rank 5] Epoch 1/100, Batch 190/2745, Loss: 5.4767
[Rank 9] Epoch 1/100, Batch 190/2745, Loss: 5.4816
[Rank 10] Epoch 1/100, Batch 190/2745, Loss: 5.5001
[Rank 0] Epoch 1/100, Batch 190/2745, Loss: 5.4676
[Rank 14] Epoch 1/100, Batch 190/2745, Loss: 5.4187
[Rank 15] Epoch 1/100, Batch 190/2745, Loss: 5.5087
[Rank 13] Epoch 1/100, Batch 190/2745, Loss: 5.4582
[Rank 3] Epoch 1/100, Batch 190/2745, Loss: 5.5536
[Rank 2] Epoch 1/100, Batch 190/2745, Loss: 5.5102
[Rank 1] Epoch 1/100, Batch 190/2745, Loss: 5.5212
[Rank 11] Epoch 1/100, Batch 190/2745, Loss: 5.6229
[Rank 4] Epoch 1/100, Batch 190/2745, Loss: 5.6020
[Rank 7] Epoch 1/100, Batch 190/2745, Loss: 5.3609
[Rank 6] Epoch 1/100, Batch 190/2745, Loss: 5.4752
[Rank 12] Epoch 1/100, Batch 190/2745, Loss: 5.5624
[Rank 5] Epoch 1/100, Batch 200/2745, Loss: 5.4711
[Rank 10] Epoch 1/100, Batch 200/2745, Loss: 5.5019
[Rank 9] Epoch 1/100, Batch 200/2745, Loss: 5.3050
[Rank 0] Epoch 1/100, Batch 200/2745, Loss: 5.5125
[Rank 14] Epoch 1/100, Batch 200/2745, Loss: 5.4993
[Rank 15] Epoch 1/100, Batch 200/2745, Loss: 5.4370
[Rank 13] Epoch 1/100, Batch 200/2745, Loss: 5.4378
[Rank 2] Epoch 1/100, Batch 200/2745, Loss: 5.6501
[Rank 3] Epoch 1/100, Batch 200/2745, Loss: 5.5457
[Rank 1] Epoch 1/100, Batch 200/2745, Loss: 5.4659
[Rank 11] Epoch 1/100, Batch 200/2745, Loss: 5.4412
[Rank 7] Epoch 1/100, Batch 200/2745, Loss: 5.5120
[Rank 4] Epoch 1/100, Batch 200/2745, Loss: 5.4991
[Rank 6] Epoch 1/100, Batch 200/2745, Loss: 5.5190
[Rank 12] Epoch 1/100, Batch 200/2745, Loss: 5.6055
[Rank 8] Epoch 1/100, Batch 210/2745, Loss: 5.5640
[Rank 5] Epoch 1/100, Batch 210/2745, Loss: 5.4641
[Rank 9] Epoch 1/100, Batch 210/2745, Loss: 5.4522
[Rank 10] Epoch 1/100, Batch 210/2745, Loss: 5.4892
[Rank 0] Epoch 1/100, Batch 210/2745, Loss: 5.4999
[Rank 6] Epoch 1/100, Batch 210/2745, Loss: 5.3485
[Rank 1] Epoch 1/100, Batch 210/2745, Loss: 5.4059
[Rank 13] Epoch 1/100, Batch 210/2745, Loss: 5.4895
[Rank 2] Epoch 1/100, Batch 210/2745, Loss: 5.6107
[Rank 14] Epoch 1/100, Batch 210/2745, Loss: 5.4564
[Rank 3] Epoch 1/100, Batch 210/2745, Loss: 5.4460
[Rank 7] Epoch 1/100, Batch 210/2745, Loss: 5.5133
[Rank 4] Epoch 1/100, Batch 210/2745, Loss: 5.6202
[Rank 15] Epoch 1/100, Batch 210/2745, Loss: 5.5193
[Rank 11] Epoch 1/100, Batch 210/2745, Loss: 5.5778
[Rank 12] Epoch 1/100, Batch 210/2745, Loss: 5.5905
[Rank 8] Epoch 1/100, Batch 220/2745, Loss: 5.5936
[Rank 8] Epoch 1/100, Batch 230/2745, Loss: 5.4722
[Rank 5] Epoch 1/100, Batch 220/2745, Loss: 5.4096
[Rank 9] Epoch 1/100, Batch 220/2745, Loss: 5.4279
[Rank 0] Epoch 1/100, Batch 220/2745, Loss: 5.4376
[Rank 3] Epoch 1/100, Batch 220/2745, Loss: 5.5636
[Rank 1] Epoch 1/100, Batch 220/2745, Loss: 5.4731
[Rank 13] Epoch 1/100, Batch 220/2745, Loss: 5.3412
[Rank 2] Epoch 1/100, Batch 220/2745, Loss: 5.4408
[Rank 10] Epoch 1/100, Batch 220/2745, Loss: 5.4919
[Rank 6] Epoch 1/100, Batch 220/2745, Loss: 5.5190
[Rank 7] Epoch 1/100, Batch 220/2745, Loss: 5.5107
[Rank 14] Epoch 1/100, Batch 220/2745, Loss: 5.3714
[Rank 15] Epoch 1/100, Batch 220/2745, Loss: 5.5043
[Rank 4] Epoch 1/100, Batch 220/2745, Loss: 5.5826
[Rank 11] Epoch 1/100, Batch 220/2745, Loss: 5.5541
[Rank 12] Epoch 1/100, Batch 220/2745, Loss: 5.4972
[Rank 8] Epoch 1/100, Batch 240/2745, Loss: 5.5126
[Rank 5] Epoch 1/100, Batch 230/2745, Loss: 5.3770
[Rank 9] Epoch 1/100, Batch 230/2745, Loss: 5.5068
[Rank 0] Epoch 1/100, Batch 230/2745, Loss: 5.4944
[Rank 1] Epoch 1/100, Batch 230/2745, Loss: 5.5185
[Rank 3] Epoch 1/100, Batch 230/2745, Loss: 5.5526
[Rank 10] Epoch 1/100, Batch 230/2745, Loss: 5.5344
[Rank 2] Epoch 1/100, Batch 230/2745, Loss: 5.6246
[Rank 7] Epoch 1/100, Batch 230/2745, Loss: 5.4866
[Rank 14] Epoch 1/100, Batch 230/2745, Loss: 5.4571
[Rank 13] Epoch 1/100, Batch 230/2745, Loss: 5.3906
[Rank 15] Epoch 1/100, Batch 230/2745, Loss: 5.3518
[Rank 4] Epoch 1/100, Batch 230/2745, Loss: 5.5923
[Rank 11] Epoch 1/100, Batch 230/2745, Loss: 5.5807
[Rank 6] Epoch 1/100, Batch 230/2745, Loss: 5.5613
[Rank 12] Epoch 1/100, Batch 230/2745, Loss: 5.6128
[Rank 8] Epoch 1/100, Batch 250/2745, Loss: 5.3902
[Rank 8] Epoch 1/100, Batch 260/2745, Loss: 5.4495
[Rank 5] Epoch 1/100, Batch 240/2745, Loss: 5.4249
[Rank 10] Epoch 1/100, Batch 240/2745, Loss: 5.5272
[Rank 9] Epoch 1/100, Batch 240/2745, Loss: 5.4789
[Rank 0] Epoch 1/100, Batch 240/2745, Loss: 5.5076
[Rank 1] Epoch 1/100, Batch 240/2745, Loss: 5.5742
[Rank 13] Epoch 1/100, Batch 240/2745, Loss: 5.3428
[Rank 2] Epoch 1/100, Batch 240/2745, Loss: 5.5944
[Rank 15] Epoch 1/100, Batch 240/2745, Loss: 5.5018
[Rank 3] Epoch 1/100, Batch 240/2745, Loss: 5.5066
[Rank 14] Epoch 1/100, Batch 240/2745, Loss: 5.4059
[Rank 7] Epoch 1/100, Batch 240/2745, Loss: 5.4664
[Rank 11] Epoch 1/100, Batch 240/2745, Loss: 5.5687
[Rank 4] Epoch 1/100, Batch 240/2745, Loss: 5.5920
[Rank 6] Epoch 1/100, Batch 240/2745, Loss: 5.4411
[Rank 12] Epoch 1/100, Batch 240/2745, Loss: 5.4958
[Rank 8] Epoch 1/100, Batch 270/2745, Loss: 5.3942
[Rank 5] Epoch 1/100, Batch 250/2745, Loss: 5.3993
[Rank 0] Epoch 1/100, Batch 250/2745, Loss: 5.5520
[Rank 9] Epoch 1/100, Batch 250/2745, Loss: 5.4820
[Rank 10] Epoch 1/100, Batch 250/2745, Loss: 5.4720
[Rank 1] Epoch 1/100, Batch 250/2745, Loss: 5.4284
[Rank 13] Epoch 1/100, Batch 250/2745, Loss: 5.4175
[Rank 15] Epoch 1/100, Batch 250/2745, Loss: 5.3592
[Rank 2] Epoch 1/100, Batch 250/2745, Loss: 5.5495
[Rank 11] Epoch 1/100, Batch 250/2745, Loss: 5.5155
[Rank 14] Epoch 1/100, Batch 250/2745, Loss: 5.4300
[Rank 3] Epoch 1/100, Batch 250/2745, Loss: 5.5284
[Rank 7] Epoch 1/100, Batch 250/2745, Loss: 5.5078
[Rank 6] Epoch 1/100, Batch 250/2745, Loss: 5.4656
[Rank 4] Epoch 1/100, Batch 250/2745, Loss: 5.5245
[Rank 12] Epoch 1/100, Batch 250/2745, Loss: 5.5958
[Rank 8] Epoch 1/100, Batch 280/2745, Loss: 5.5072
[Rank 8] Epoch 1/100, Batch 290/2745, Loss: 5.5447
[Rank 0] Epoch 1/100, Batch 260/2745, Loss: 5.4777
[Rank 9] Epoch 1/100, Batch 260/2745, Loss: 5.5538
[Rank 5] Epoch 1/100, Batch 260/2745, Loss: 5.4446
[Rank 1] Epoch 1/100, Batch 260/2745, Loss: 5.5509
[Rank 15] Epoch 1/100, Batch 260/2745, Loss: 5.4690
[Rank 2] Epoch 1/100, Batch 260/2745, Loss: 5.5859
[Rank 10] Epoch 1/100, Batch 260/2745, Loss: 5.4790
[Rank 13] Epoch 1/100, Batch 260/2745, Loss: 5.4571
[Rank 11] Epoch 1/100, Batch 260/2745, Loss: 5.5649
[Rank 14] Epoch 1/100, Batch 260/2745, Loss: 5.4259
[Rank 3] Epoch 1/100, Batch 260/2745, Loss: 5.5809
[Rank 7] Epoch 1/100, Batch 260/2745, Loss: 5.2978
[Rank 6] Epoch 1/100, Batch 260/2745, Loss: 5.2863
[Rank 4] Epoch 1/100, Batch 260/2745, Loss: 5.5605
[Rank 12] Epoch 1/100, Batch 260/2745, Loss: 5.5228
[Rank 8] Epoch 1/100, Batch 300/2745, Loss: 5.5606
[Rank 0] Epoch 1/100, Batch 270/2745, Loss: 5.3325
[Rank 5] Epoch 1/100, Batch 270/2745, Loss: 5.4333
[Rank 9] Epoch 1/100, Batch 270/2745, Loss: 5.5034
[Rank 15] Epoch 1/100, Batch 270/2745, Loss: 5.4706
[Rank 1] Epoch 1/100, Batch 270/2745, Loss: 5.5319
[Rank 2] Epoch 1/100, Batch 270/2745, Loss: 5.5290
[Rank 10] Epoch 1/100, Batch 270/2745, Loss: 5.4693
[Rank 13] Epoch 1/100, Batch 270/2745, Loss: 5.3333
[Rank 14] Epoch 1/100, Batch 270/2745, Loss: 5.3883
[Rank 11] Epoch 1/100, Batch 270/2745, Loss: 5.5855
[Rank 3] Epoch 1/100, Batch 270/2745, Loss: 5.4204
[Rank 7] Epoch 1/100, Batch 270/2745, Loss: 5.4650
[Rank 6] Epoch 1/100, Batch 270/2745, Loss: 5.4420
[Rank 4] Epoch 1/100, Batch 270/2745, Loss: 5.5527
[Rank 12] Epoch 1/100, Batch 270/2745, Loss: 5.4683
[Rank 0] Epoch 1/100, Batch 280/2745, Loss: 5.4629
[Rank 5] Epoch 1/100, Batch 280/2745, Loss: 5.4136
[Rank 2] Epoch 1/100, Batch 280/2745, Loss: 5.4340
[Rank 9] Epoch 1/100, Batch 280/2745, Loss: 5.4796
[Rank 15] Epoch 1/100, Batch 280/2745, Loss: 5.4784
[Rank 1] Epoch 1/100, Batch 280/2745, Loss: 5.4821
[Rank 10] Epoch 1/100, Batch 280/2745, Loss: 5.4622
[Rank 14] Epoch 1/100, Batch 280/2745, Loss: 5.4102
[Rank 13] Epoch 1/100, Batch 280/2745, Loss: 5.4206
[Rank 11] Epoch 1/100, Batch 280/2745, Loss: 5.6021
[Rank 3] Epoch 1/100, Batch 280/2745, Loss: 5.4847
[Rank 7] Epoch 1/100, Batch 280/2745, Loss: 5.4623
[Rank 4] Epoch 1/100, Batch 280/2745, Loss: 5.4712
[Rank 6] Epoch 1/100, Batch 280/2745, Loss: 5.3968
[Rank 12] Epoch 1/100, Batch 280/2745, Loss: 5.5198
[Rank 0] Epoch 1/100, Batch 290/2745, Loss: 5.3193
[Rank 5] Epoch 1/100, Batch 290/2745, Loss: 5.2966
[Rank 2] Epoch 1/100, Batch 290/2745, Loss: 5.5847
[Rank 15] Epoch 1/100, Batch 290/2745, Loss: 5.4601
[Rank 9] Epoch 1/100, Batch 290/2745, Loss: 5.3469
[Rank 1] Epoch 1/100, Batch 290/2745, Loss: 5.3783
[Rank 10] Epoch 1/100, Batch 290/2745, Loss: 5.4953
[Rank 14] Epoch 1/100, Batch 290/2745, Loss: 5.4014
[Rank 13] Epoch 1/100, Batch 290/2745, Loss: 5.3699
[Rank 11] Epoch 1/100, Batch 290/2745, Loss: 5.6023
[Rank 3] Epoch 1/100, Batch 290/2745, Loss: 5.4698
[Rank 7] Epoch 1/100, Batch 290/2745, Loss: 5.4350
[Rank 4] Epoch 1/100, Batch 290/2745, Loss: 5.5647
[Rank 6] Epoch 1/100, Batch 290/2745, Loss: 5.4953
[Rank 12] Epoch 1/100, Batch 290/2745, Loss: 5.4947
[Rank 0] Epoch 1/100, Batch 300/2745, Loss: 5.3359
[Rank 5] Epoch 1/100, Batch 300/2745, Loss: 5.4325
[Rank 2] Epoch 1/100, Batch 300/2745, Loss: 5.5696
[Rank 9] Epoch 1/100, Batch 300/2745, Loss: 5.2874
[Rank 1] Epoch 1/100, Batch 300/2745, Loss: 5.4809
[Rank 15] Epoch 1/100, Batch 300/2745, Loss: 5.4539
[Rank 10] Epoch 1/100, Batch 300/2745, Loss: 5.4440
[Rank 13] Epoch 1/100, Batch 300/2745, Loss: 5.3210
[Rank 14] Epoch 1/100, Batch 300/2745, Loss: 5.5025
[Rank 11] Epoch 1/100, Batch 300/2745, Loss: 5.5766
[Rank 7] Epoch 1/100, Batch 300/2745, Loss: 5.2961
[Rank 3] Epoch 1/100, Batch 300/2745, Loss: 5.4978
[Rank 4] Epoch 1/100, Batch 300/2745, Loss: 5.6098
[Rank 6] Epoch 1/100, Batch 300/2745, Loss: 5.4662
[Rank 12] Epoch 1/100, Batch 300/2745, Loss: 5.5654
[Rank 8] Epoch 1/100, Batch 310/2745, Loss: 5.6030
[Rank 9] Epoch 1/100, Batch 310/2745, Loss: 5.4694
[Rank 13] Epoch 1/100, Batch 310/2745, Loss: 5.3821
[Rank 15] Epoch 1/100, Batch 310/2745, Loss: 5.4919
[Rank 5] Epoch 1/100, Batch 310/2745, Loss: 5.4418
[Rank 11] Epoch 1/100, Batch 310/2745, Loss: 5.5547
[Rank 2] Epoch 1/100, Batch 310/2745, Loss: 5.3991
[Rank 14] Epoch 1/100, Batch 310/2745, Loss: 5.4362
[Rank 6] Epoch 1/100, Batch 310/2745, Loss: 5.4896
[Rank 7] Epoch 1/100, Batch 310/2745, Loss: 5.4369
[Rank 3] Epoch 1/100, Batch 310/2745, Loss: 5.5740
[Rank 10] Epoch 1/100, Batch 310/2745, Loss: 5.4413
[Rank 0] Epoch 1/100, Batch 310/2745, Loss: 5.4377
[Rank 1] Epoch 1/100, Batch 310/2745, Loss: 5.5309
[Rank 4] Epoch 1/100, Batch 310/2745, Loss: 5.5253
[Rank 12] Epoch 1/100, Batch 310/2745, Loss: 5.3333
[Rank 8] Epoch 1/100, Batch 320/2745, Loss: 5.4167
[Rank 8] Epoch 1/100, Batch 330/2745, Loss: 5.4020
[Rank 13] Epoch 1/100, Batch 320/2745, Loss: 5.3463
[Rank 9] Epoch 1/100, Batch 320/2745, Loss: 5.4619
[Rank 5] Epoch 1/100, Batch 320/2745, Loss: 5.3010
[Rank 15] Epoch 1/100, Batch 320/2745, Loss: 5.4418
[Rank 11] Epoch 1/100, Batch 320/2745, Loss: 5.5477
[Rank 7] Epoch 1/100, Batch 320/2745, Loss: 5.5615
[Rank 0] Epoch 1/100, Batch 320/2745, Loss: 5.4520
[Rank 14] Epoch 1/100, Batch 320/2745, Loss: 5.4139
[Rank 4] Epoch 1/100, Batch 320/2745, Loss: 5.5297
[Rank 2] Epoch 1/100, Batch 320/2745, Loss: 5.5890
[Rank 6] Epoch 1/100, Batch 320/2745, Loss: 5.4287
[Rank 10] Epoch 1/100, Batch 320/2745, Loss: 5.3753
[Rank 1] Epoch 1/100, Batch 320/2745, Loss: 5.5437
[Rank 3] Epoch 1/100, Batch 320/2745, Loss: 5.3488
[Rank 12] Epoch 1/100, Batch 320/2745, Loss: 5.5108
[Rank 8] Epoch 1/100, Batch 340/2745, Loss: 5.5443
[Rank 13] Epoch 1/100, Batch 330/2745, Loss: 5.1386
[Rank 9] Epoch 1/100, Batch 330/2745, Loss: 5.3867
[Rank 5] Epoch 1/100, Batch 330/2745, Loss: 5.3841
[Rank 0] Epoch 1/100, Batch 330/2745, Loss: 5.4751
[Rank 11] Epoch 1/100, Batch 330/2745, Loss: 5.6006
[Rank 15] Epoch 1/100, Batch 330/2745, Loss: 5.4640
[Rank 7] Epoch 1/100, Batch 330/2745, Loss: 5.3805
[Rank 4] Epoch 1/100, Batch 330/2745, Loss: 5.4464
[Rank 14] Epoch 1/100, Batch 330/2745, Loss: 5.4112
[Rank 10] Epoch 1/100, Batch 330/2745, Loss: 5.4296
[Rank 2] Epoch 1/100, Batch 330/2745, Loss: 5.5563
[Rank 3] Epoch 1/100, Batch 330/2745, Loss: 5.4796
[Rank 1] Epoch 1/100, Batch 330/2745, Loss: 5.4267
[Rank 6] Epoch 1/100, Batch 330/2745, Loss: 5.3413
[Rank 12] Epoch 1/100, Batch 330/2745, Loss: 5.4744
[Rank 8] Epoch 1/100, Batch 350/2745, Loss: 5.5121
[Rank 8] Epoch 1/100, Batch 360/2745, Loss: 5.4144
[Rank 13] Epoch 1/100, Batch 340/2745, Loss: 5.3501
[Rank 9] Epoch 1/100, Batch 340/2745, Loss: 5.4268
[Rank 5] Epoch 1/100, Batch 340/2745, Loss: 5.3414
[Rank 11] Epoch 1/100, Batch 340/2745, Loss: 5.5266
[Rank 15] Epoch 1/100, Batch 340/2745, Loss: 5.4033
[Rank 0] Epoch 1/100, Batch 340/2745, Loss: 5.3951
[Rank 2] Epoch 1/100, Batch 340/2745, Loss: 4.8618
[Rank 4] Epoch 1/100, Batch 340/2745, Loss: 5.5006
[Rank 10] Epoch 1/100, Batch 340/2745, Loss: 5.4205
[Rank 7] Epoch 1/100, Batch 340/2745, Loss: 5.4265
[Rank 14] Epoch 1/100, Batch 340/2745, Loss: 5.4116
[Rank 6] Epoch 1/100, Batch 340/2745, Loss: 5.4844
[Rank 1] Epoch 1/100, Batch 340/2745, Loss: 5.4492
[Rank 3] Epoch 1/100, Batch 340/2745, Loss: 5.4997
[Rank 12] Epoch 1/100, Batch 340/2745, Loss: 5.5201
[Rank 8] Epoch 1/100, Batch 370/2745, Loss: 5.4386
[Rank 13] Epoch 1/100, Batch 350/2745, Loss: 5.4358
[Rank 5] Epoch 1/100, Batch 350/2745, Loss: 5.3030
[Rank 9] Epoch 1/100, Batch 350/2745, Loss: 5.4241
[Rank 11] Epoch 1/100, Batch 350/2745, Loss: 5.4726
[Rank 15] Epoch 1/100, Batch 350/2745, Loss: 5.4617
[Rank 0] Epoch 1/100, Batch 350/2745, Loss: 5.3821
[Rank 2] Epoch 1/100, Batch 350/2745, Loss: 5.5763
[Rank 4] Epoch 1/100, Batch 350/2745, Loss: 5.5239
[Rank 14] Epoch 1/100, Batch 350/2745, Loss: 5.3934
[Rank 10] Epoch 1/100, Batch 350/2745, Loss: 5.5199
[Rank 1] Epoch 1/100, Batch 350/2745, Loss: 5.4434
[Rank 7] Epoch 1/100, Batch 350/2745, Loss: 5.3819
[Rank 6] Epoch 1/100, Batch 350/2745, Loss: 5.3737
[Rank 8] Epoch 1/100, Batch 380/2745, Loss: 5.3537
[Rank 3] Epoch 1/100, Batch 350/2745, Loss: 5.3853
[Rank 12] Epoch 1/100, Batch 350/2745, Loss: 5.5546
[Rank 8] Epoch 1/100, Batch 390/2745, Loss: 5.5237
[Rank 9] Epoch 1/100, Batch 360/2745, Loss: 5.4387
[Rank 5] Epoch 1/100, Batch 360/2745, Loss: 5.4087
[Rank 13] Epoch 1/100, Batch 360/2745, Loss: 5.2577
[Rank 11] Epoch 1/100, Batch 360/2745, Loss: 5.4424
[Rank 15] Epoch 1/100, Batch 360/2745, Loss: 5.4370
[Rank 2] Epoch 1/100, Batch 360/2745, Loss: 5.5086
[Rank 0] Epoch 1/100, Batch 360/2745, Loss: 5.2421
[Rank 4] Epoch 1/100, Batch 360/2745, Loss: 5.4883
[Rank 1] Epoch 1/100, Batch 360/2745, Loss: 5.4322
[Rank 14] Epoch 1/100, Batch 360/2745, Loss: 5.3992
[Rank 10] Epoch 1/100, Batch 360/2745, Loss: 5.4113
[Rank 7] Epoch 1/100, Batch 360/2745, Loss: 5.4657
[Rank 6] Epoch 1/100, Batch 360/2745, Loss: 5.3659
[Rank 3] Epoch 1/100, Batch 360/2745, Loss: 5.4012
[Rank 12] Epoch 1/100, Batch 360/2745, Loss: 5.5036
[Rank 8] Epoch 1/100, Batch 400/2745, Loss: 5.3984
[Rank 5] Epoch 1/100, Batch 370/2745, Loss: 5.2240
[Rank 9] Epoch 1/100, Batch 370/2745, Loss: 5.3676
[Rank 13] Epoch 1/100, Batch 370/2745, Loss: 5.3402
[Rank 11] Epoch 1/100, Batch 370/2745, Loss: 5.5196
[Rank 15] Epoch 1/100, Batch 370/2745, Loss: 5.3673
[Rank 2] Epoch 1/100, Batch 370/2745, Loss: 5.4292
[Rank 0] Epoch 1/100, Batch 370/2745, Loss: 5.4053
[Rank 4] Epoch 1/100, Batch 370/2745, Loss: 5.4466
[Rank 1] Epoch 1/100, Batch 370/2745, Loss: 5.2991
[Rank 10] Epoch 1/100, Batch 370/2745, Loss: 5.4909
[Rank 14] Epoch 1/100, Batch 370/2745, Loss: 5.1850
[Rank 7] Epoch 1/100, Batch 370/2745, Loss: 5.3644
[Rank 3] Epoch 1/100, Batch 370/2745, Loss: 5.4519
[Rank 6] Epoch 1/100, Batch 370/2745, Loss: 5.3261
[Rank 12] Epoch 1/100, Batch 370/2745, Loss: 5.2429
[Rank 5] Epoch 1/100, Batch 380/2745, Loss: 5.3670
[Rank 9] Epoch 1/100, Batch 380/2745, Loss: 5.4145
[Rank 13] Epoch 1/100, Batch 380/2745, Loss: 5.3319
[Rank 11] Epoch 1/100, Batch 380/2745, Loss: 5.4768
[Rank 2] Epoch 1/100, Batch 380/2745, Loss: 5.5318
[Rank 15] Epoch 1/100, Batch 380/2745, Loss: 5.2450
[Rank 0] Epoch 1/100, Batch 380/2745, Loss: 5.3622
[Rank 1] Epoch 1/100, Batch 380/2745, Loss: 5.5129
[Rank 10] Epoch 1/100, Batch 380/2745, Loss: 5.4866
[Rank 14] Epoch 1/100, Batch 380/2745, Loss: 5.3614
[Rank 4] Epoch 1/100, Batch 380/2745, Loss: 5.4823
[Rank 3] Epoch 1/100, Batch 380/2745, Loss: 5.3789
[Rank 7] Epoch 1/100, Batch 380/2745, Loss: 5.3884
[Rank 6] Epoch 1/100, Batch 380/2745, Loss: 5.3936
[Rank 12] Epoch 1/100, Batch 380/2745, Loss: 5.4312
[Rank 5] Epoch 1/100, Batch 390/2745, Loss: 5.3409
[Rank 13] Epoch 1/100, Batch 390/2745, Loss: 5.4145
[Rank 9] Epoch 1/100, Batch 390/2745, Loss: 5.4036
[Rank 11] Epoch 1/100, Batch 390/2745, Loss: 5.3807
[Rank 14] Epoch 1/100, Batch 390/2745, Loss: 5.3440
[Rank 2] Epoch 1/100, Batch 390/2745, Loss: 5.3609
[Rank 1] Epoch 1/100, Batch 390/2745, Loss: 5.2370
[Rank 15] Epoch 1/100, Batch 390/2745, Loss: 5.4261
[Rank 0] Epoch 1/100, Batch 390/2745, Loss: 5.3783
[Rank 4] Epoch 1/100, Batch 390/2745, Loss: 5.4538
[Rank 10] Epoch 1/100, Batch 390/2745, Loss: 5.3902
[Rank 3] Epoch 1/100, Batch 390/2745, Loss: 5.4479
[Rank 7] Epoch 1/100, Batch 390/2745, Loss: 5.4136
[Rank 6] Epoch 1/100, Batch 390/2745, Loss: 5.4336
[Rank 12] Epoch 1/100, Batch 390/2745, Loss: 5.3253
[Rank 5] Epoch 1/100, Batch 400/2745, Loss: 5.3071
[Rank 9] Epoch 1/100, Batch 400/2745, Loss: 4.6901
[Rank 11] Epoch 1/100, Batch 400/2745, Loss: 5.5042
[Rank 13] Epoch 1/100, Batch 400/2745, Loss: 5.2492
[Rank 14] Epoch 1/100, Batch 400/2745, Loss: 5.3935
[Rank 2] Epoch 1/100, Batch 400/2745, Loss: 5.4632
[Rank 15] Epoch 1/100, Batch 400/2745, Loss: 5.4223
[Rank 1] Epoch 1/100, Batch 400/2745, Loss: 5.3646
[Rank 0] Epoch 1/100, Batch 400/2745, Loss: 5.2758
[Rank 10] Epoch 1/100, Batch 400/2745, Loss: 5.3830
[Rank 4] Epoch 1/100, Batch 400/2745, Loss: 5.4728
[Rank 7] Epoch 1/100, Batch 400/2745, Loss: 5.3814
[Rank 3] Epoch 1/100, Batch 400/2745, Loss: 5.4108
[Rank 6] Epoch 1/100, Batch 400/2745, Loss: 5.3881
[Rank 12] Epoch 1/100, Batch 400/2745, Loss: 5.4647
[Rank 8] Epoch 1/100, Batch 410/2745, Loss: 5.4956
[Rank 3] Epoch 1/100, Batch 410/2745, Loss: 5.3633
[Rank 10] Epoch 1/100, Batch 410/2745, Loss: 5.3184
[Rank 1] Epoch 1/100, Batch 410/2745, Loss: 5.3268
[Rank 9] Epoch 1/100, Batch 410/2745, Loss: 5.4786
[Rank 15] Epoch 1/100, Batch 410/2745, Loss: 5.5000
[Rank 4] Epoch 1/100, Batch 410/2745, Loss: 5.3307
[Rank 6] Epoch 1/100, Batch 410/2745, Loss: 5.3765
[Rank 0] Epoch 1/100, Batch 410/2745, Loss: 5.4294
[Rank 14] Epoch 1/100, Batch 410/2745, Loss: 5.3523
[Rank 5] Epoch 1/100, Batch 410/2745, Loss: 5.3273
[Rank 2] Epoch 1/100, Batch 410/2745, Loss: 5.3680
[Rank 13] Epoch 1/100, Batch 410/2745, Loss: 5.2931
[Rank 7] Epoch 1/100, Batch 410/2745, Loss: 5.2573
[Rank 11] Epoch 1/100, Batch 410/2745, Loss: 5.4453
[Rank 12] Epoch 1/100, Batch 410/2745, Loss: 5.4389
[Rank 8] Epoch 1/100, Batch 420/2745, Loss: 5.2576
