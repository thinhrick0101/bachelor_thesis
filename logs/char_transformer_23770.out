Loading data...
Loading data from data/enwik8
Data loaded: 99621832 characters
Limiting data to first 15000000 characters for training
Loading BPE tokenizer...
Vocabulary size: 30000
Encoding text with BPE tokenizer...
Creating batches...
Created 414 training batches and 46 validation batches
Model Parameters: 213,206,865 trainable out of 213,206,865 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda
Using mixed precision training (FP16)
Using gradient accumulation with 16 steps
Effective batch size: 256
Epoch 1/100, Batch 10/414, Loss: 10.4548
Epoch 1/100, Batch 20/414, Loss: 10.4580
Epoch 1/100, Batch 30/414, Loss: 10.4545
Epoch 1/100, Batch 40/414, Loss: 10.4429
Epoch 1/100, Batch 50/414, Loss: 10.4409
Epoch 1/100, Batch 60/414, Loss: 10.4255
Epoch 1/100, Batch 70/414, Loss: 10.4287
Epoch 1/100, Batch 80/414, Loss: 10.4251
Epoch 1/100, Batch 90/414, Loss: 10.4074
Epoch 1/100, Batch 100/414, Loss: 10.3753
Epoch 1/100, Batch 110/414, Loss: 10.3762
Epoch 1/100, Batch 120/414, Loss: 10.3508
Epoch 1/100, Batch 130/414, Loss: 10.3399
Epoch 1/100, Batch 140/414, Loss: 10.3034
Epoch 1/100, Batch 150/414, Loss: 10.2895
Epoch 1/100, Batch 160/414, Loss: 10.2846
Epoch 1/100, Batch 170/414, Loss: 10.2100
Epoch 1/100, Batch 180/414, Loss: 10.1650
Epoch 1/100, Batch 190/414, Loss: 10.1660
Epoch 1/100, Batch 200/414, Loss: 10.1202
Epoch 1/100, Batch 210/414, Loss: 10.0539
Epoch 1/100, Batch 220/414, Loss: 10.0790
Epoch 1/100, Batch 230/414, Loss: 10.0307
Epoch 1/100, Batch 240/414, Loss: 10.0095
Epoch 1/100, Batch 250/414, Loss: 10.0011
Epoch 1/100, Batch 260/414, Loss: 9.8863
Epoch 1/100, Batch 270/414, Loss: 9.9266
Epoch 1/100, Batch 280/414, Loss: 9.8504
Epoch 1/100, Batch 290/414, Loss: 9.8114
Epoch 1/100, Batch 300/414, Loss: 9.7953
Epoch 1/100, Batch 310/414, Loss: 9.7498
Epoch 1/100, Batch 320/414, Loss: 9.7595
Epoch 1/100, Batch 330/414, Loss: 9.6574
Epoch 1/100, Batch 340/414, Loss: 9.5998
Epoch 1/100, Batch 350/414, Loss: 9.6582
Epoch 1/100, Batch 360/414, Loss: 9.6161
Epoch 1/100, Batch 370/414, Loss: 9.5844
Epoch 1/100, Batch 380/414, Loss: 9.5336
Epoch 1/100, Batch 390/414, Loss: 9.5697
Epoch 1/100, Batch 400/414, Loss: 9.5801
Epoch 1/100, Batch 410/414, Loss: 9.5345
New best model with validation loss: 9.3572, perplexity: 11582.20
Epoch 1/100, Loss: 10.0574, Perplexity: 23328.77, Val Loss: 9.3572, Val Perplexity: 11582.20, Time: 259.94s
Epoch 2/100, Batch 10/414, Loss: 9.4496
Epoch 2/100, Batch 20/414, Loss: 9.4298
Epoch 2/100, Batch 30/414, Loss: 9.4827
Epoch 2/100, Batch 40/414, Loss: 9.4563
Epoch 2/100, Batch 50/414, Loss: 9.4047
Epoch 2/100, Batch 60/414, Loss: 9.3770
Epoch 2/100, Batch 70/414, Loss: 9.3604
Epoch 2/100, Batch 80/414, Loss: 9.4038
Epoch 2/100, Batch 90/414, Loss: 9.2345
Epoch 2/100, Batch 100/414, Loss: 9.3818
Epoch 2/100, Batch 110/414, Loss: 9.3242
Epoch 2/100, Batch 120/414, Loss: 9.2813
Epoch 2/100, Batch 130/414, Loss: 9.3633
Epoch 2/100, Batch 140/414, Loss: 9.2910
Epoch 2/100, Batch 150/414, Loss: 9.3686
Epoch 2/100, Batch 160/414, Loss: 9.3013
Epoch 2/100, Batch 170/414, Loss: 9.2564
Epoch 2/100, Batch 180/414, Loss: 9.2645
Epoch 2/100, Batch 190/414, Loss: 9.2590
Epoch 2/100, Batch 200/414, Loss: 9.2324
Epoch 2/100, Batch 210/414, Loss: 9.1975
Epoch 2/100, Batch 220/414, Loss: 9.2328
Epoch 2/100, Batch 230/414, Loss: 9.1796
Epoch 2/100, Batch 240/414, Loss: 9.1619
Epoch 2/100, Batch 250/414, Loss: 9.1465
Epoch 2/100, Batch 260/414, Loss: 9.1311
Epoch 2/100, Batch 270/414, Loss: 9.0634
Epoch 2/100, Batch 280/414, Loss: 9.0515
Epoch 2/100, Batch 290/414, Loss: 9.1008
Epoch 2/100, Batch 300/414, Loss: 9.0428
Epoch 2/100, Batch 310/414, Loss: 9.0900
Epoch 2/100, Batch 320/414, Loss: 9.0218
Epoch 2/100, Batch 330/414, Loss: 9.0078
Epoch 2/100, Batch 340/414, Loss: 8.9409
Epoch 2/100, Batch 350/414, Loss: 9.0302
Epoch 2/100, Batch 360/414, Loss: 8.9559
Epoch 2/100, Batch 370/414, Loss: 8.9417
Epoch 2/100, Batch 380/414, Loss: 8.9394
Epoch 2/100, Batch 390/414, Loss: 8.9878
Epoch 2/100, Batch 400/414, Loss: 9.0103
Epoch 2/100, Batch 410/414, Loss: 8.9497
New best model with validation loss: 8.8281, perplexity: 6823.37
Epoch 2/100, Loss: 9.1981, Perplexity: 9878.82, Val Loss: 8.8281, Val Perplexity: 6823.37, Time: 263.15s
Epoch 3/100, Batch 10/414, Loss: 8.8730
Epoch 3/100, Batch 20/414, Loss: 8.8473
Epoch 3/100, Batch 30/414, Loss: 8.8730
Epoch 3/100, Batch 40/414, Loss: 8.8654
Epoch 3/100, Batch 50/414, Loss: 8.8541
Epoch 3/100, Batch 60/414, Loss: 8.8171
Epoch 3/100, Batch 70/414, Loss: 8.7778
Epoch 3/100, Batch 80/414, Loss: 8.8131
Epoch 3/100, Batch 90/414, Loss: 8.6463
Epoch 3/100, Batch 100/414, Loss: 8.8133
Epoch 3/100, Batch 110/414, Loss: 8.7647
Epoch 3/100, Batch 120/414, Loss: 8.7057
Epoch 3/100, Batch 130/414, Loss: 8.7814
Epoch 3/100, Batch 140/414, Loss: 8.7259
Epoch 3/100, Batch 150/414, Loss: 8.7760
Epoch 3/100, Batch 160/414, Loss: 8.7149
Epoch 3/100, Batch 170/414, Loss: 8.6518
Epoch 3/100, Batch 180/414, Loss: 8.6598
Epoch 3/100, Batch 190/414, Loss: 8.6672
Epoch 3/100, Batch 200/414, Loss: 8.6175
Epoch 3/100, Batch 210/414, Loss: 8.5953
Epoch 3/100, Batch 220/414, Loss: 8.5937
Epoch 3/100, Batch 230/414, Loss: 8.5582
Epoch 3/100, Batch 240/414, Loss: 8.5472
Epoch 3/100, Batch 250/414, Loss: 8.5268
Epoch 3/100, Batch 260/414, Loss: 8.5312
Epoch 3/100, Batch 270/414, Loss: 8.4591
Epoch 3/100, Batch 280/414, Loss: 8.4523
Epoch 3/100, Batch 290/414, Loss: 8.4770
Epoch 3/100, Batch 300/414, Loss: 8.4094
Epoch 3/100, Batch 310/414, Loss: 8.4789
Epoch 3/100, Batch 320/414, Loss: 8.3717
Epoch 3/100, Batch 330/414, Loss: 8.3692
Epoch 3/100, Batch 340/414, Loss: 8.2958
Epoch 3/100, Batch 350/414, Loss: 8.4134
Epoch 3/100, Batch 360/414, Loss: 8.2811
Epoch 3/100, Batch 370/414, Loss: 8.3053
Epoch 3/100, Batch 380/414, Loss: 8.2835
Epoch 3/100, Batch 390/414, Loss: 8.3327
Epoch 3/100, Batch 400/414, Loss: 8.3586
Epoch 3/100, Batch 410/414, Loss: 8.3163
New best model with validation loss: 8.1911, perplexity: 3608.60
Epoch 3/100, Loss: 8.5904, Perplexity: 5379.68, Val Loss: 8.1911, Val Perplexity: 3608.60, Time: 259.80s
Epoch 4/100, Batch 10/414, Loss: 8.2363
Epoch 4/100, Batch 20/414, Loss: 8.1641
Epoch 4/100, Batch 30/414, Loss: 8.1852
Epoch 4/100, Batch 40/414, Loss: 8.2146
Epoch 4/100, Batch 50/414, Loss: 8.2326
Epoch 4/100, Batch 60/414, Loss: 8.1711
Epoch 4/100, Batch 70/414, Loss: 8.1129
Epoch 4/100, Batch 80/414, Loss: 8.1245
Epoch 4/100, Batch 90/414, Loss: 7.9553
Epoch 4/100, Batch 100/414, Loss: 8.1798
Epoch 4/100, Batch 110/414, Loss: 8.1349
Epoch 4/100, Batch 120/414, Loss: 7.9801
Epoch 4/100, Batch 130/414, Loss: 8.0753
Epoch 4/100, Batch 140/414, Loss: 8.0991
Epoch 4/100, Batch 150/414, Loss: 8.1031
Epoch 4/100, Batch 160/414, Loss: 8.0369
Epoch 4/100, Batch 170/414, Loss: 8.0081
Epoch 4/100, Batch 180/414, Loss: 7.9802
Epoch 4/100, Batch 190/414, Loss: 8.0080
Epoch 4/100, Batch 200/414, Loss: 7.9171
Epoch 4/100, Batch 210/414, Loss: 7.9264
Epoch 4/100, Batch 220/414, Loss: 7.8788
Epoch 4/100, Batch 230/414, Loss: 7.9122
Epoch 4/100, Batch 240/414, Loss: 7.9181
Epoch 4/100, Batch 250/414, Loss: 7.8348
Epoch 4/100, Batch 260/414, Loss: 7.9202
Epoch 4/100, Batch 270/414, Loss: 7.8701
Epoch 4/100, Batch 280/414, Loss: 7.8563
Epoch 4/100, Batch 290/414, Loss: 7.8527
Epoch 4/100, Batch 300/414, Loss: 7.7491
Epoch 4/100, Batch 310/414, Loss: 7.8692
Epoch 4/100, Batch 320/414, Loss: 7.7512
Epoch 4/100, Batch 330/414, Loss: 7.7016
Epoch 4/100, Batch 340/414, Loss: 7.6969
Epoch 4/100, Batch 350/414, Loss: 7.8283
Epoch 4/100, Batch 360/414, Loss: 7.5279
Epoch 4/100, Batch 370/414, Loss: 7.7484
Epoch 4/100, Batch 380/414, Loss: 7.6573
Epoch 4/100, Batch 390/414, Loss: 7.7548
Epoch 4/100, Batch 400/414, Loss: 7.7417
Epoch 4/100, Batch 410/414, Loss: 7.7356
New best model with validation loss: 7.5981, perplexity: 1994.43
Epoch 4/100, Loss: 7.9398, Perplexity: 2806.66, Val Loss: 7.5981, Val Perplexity: 1994.43, Time: 261.07s
Epoch 5/100, Batch 10/414, Loss: 7.7050
Epoch 5/100, Batch 20/414, Loss: 7.5305
Epoch 5/100, Batch 30/414, Loss: 7.5370
Epoch 5/100, Batch 40/414, Loss: 7.7017
Epoch 5/100, Batch 50/414, Loss: 7.7832
Epoch 5/100, Batch 60/414, Loss: 7.6727
Epoch 5/100, Batch 70/414, Loss: 7.5067
Epoch 5/100, Batch 80/414, Loss: 7.5072
Epoch 5/100, Batch 90/414, Loss: 7.4092
Epoch 5/100, Batch 100/414, Loss: 7.7203
Epoch 5/100, Batch 110/414, Loss: 7.6720
Epoch 5/100, Batch 120/414, Loss: 7.4317
Epoch 5/100, Batch 130/414, Loss: 7.5592
Epoch 5/100, Batch 140/414, Loss: 7.6805
Epoch 5/100, Batch 150/414, Loss: 7.6642
Epoch 5/100, Batch 160/414, Loss: 7.5782
Epoch 5/100, Batch 170/414, Loss: 7.6041
Epoch 5/100, Batch 180/414, Loss: 7.5327
Epoch 5/100, Batch 190/414, Loss: 7.6143
Epoch 5/100, Batch 200/414, Loss: 7.4658
Epoch 5/100, Batch 210/414, Loss: 7.5258
Epoch 5/100, Batch 220/414, Loss: 7.4016
Epoch 5/100, Batch 230/414, Loss: 7.5403
Epoch 5/100, Batch 240/414, Loss: 7.5381
Epoch 5/100, Batch 250/414, Loss: 7.4193
Epoch 5/100, Batch 260/414, Loss: 7.5986
Epoch 5/100, Batch 270/414, Loss: 7.5960
Epoch 5/100, Batch 280/414, Loss: 7.5027
Epoch 5/100, Batch 290/414, Loss: 7.5138
Epoch 5/100, Batch 300/414, Loss: 7.4216
Epoch 5/100, Batch 310/414, Loss: 7.5494
Epoch 5/100, Batch 320/414, Loss: 7.4459
Epoch 5/100, Batch 330/414, Loss: 7.3277
Epoch 5/100, Batch 340/414, Loss: 7.3920
Epoch 5/100, Batch 350/414, Loss: 7.5486
Epoch 5/100, Batch 360/414, Loss: 7.1129
Epoch 5/100, Batch 370/414, Loss: 7.4648
Epoch 5/100, Batch 380/414, Loss: 7.3216
Epoch 5/100, Batch 390/414, Loss: 7.4421
Epoch 5/100, Batch 400/414, Loss: 7.4276
Epoch 5/100, Batch 410/414, Loss: 7.4241
New best model with validation loss: 7.2641, perplexity: 1428.07
Epoch 5/100, Loss: 7.5154, Perplexity: 1836.14, Val Loss: 7.2641, Val Perplexity: 1428.07, Time: 261.04s
Epoch 6/100, Batch 10/414, Loss: 7.4332
Epoch 6/100, Batch 20/414, Loss: 7.2336
Epoch 6/100, Batch 30/414, Loss: 7.2104
Epoch 6/100, Batch 40/414, Loss: 7.4589
Epoch 6/100, Batch 50/414, Loss: 7.5310
Epoch 6/100, Batch 60/414, Loss: 7.3854
Epoch 6/100, Batch 70/414, Loss: 7.1883
Epoch 6/100, Batch 80/414, Loss: 7.2058
Epoch 6/100, Batch 90/414, Loss: 7.1251
Epoch 6/100, Batch 100/414, Loss: 7.4660
Epoch 6/100, Batch 110/414, Loss: 7.4179
Epoch 6/100, Batch 120/414, Loss: 7.1349
Epoch 6/100, Batch 130/414, Loss: 7.2927
Epoch 6/100, Batch 140/414, Loss: 7.4363
Epoch 6/100, Batch 150/414, Loss: 7.4467
Epoch 6/100, Batch 160/414, Loss: 7.3575
Epoch 6/100, Batch 170/414, Loss: 7.3868
Epoch 6/100, Batch 180/414, Loss: 7.2483
Epoch 6/100, Batch 190/414, Loss: 7.3785
Epoch 6/100, Batch 200/414, Loss: 7.1756
Epoch 6/100, Batch 210/414, Loss: 7.2336
Epoch 6/100, Batch 220/414, Loss: 7.1399
Epoch 6/100, Batch 230/414, Loss: 7.3077
Epoch 6/100, Batch 240/414, Loss: 7.2448
Epoch 6/100, Batch 250/414, Loss: 7.1415
Epoch 6/100, Batch 260/414, Loss: 7.3731
Epoch 6/100, Batch 270/414, Loss: 7.4244
Epoch 6/100, Batch 280/414, Loss: 7.2478
Epoch 6/100, Batch 290/414, Loss: 7.2737
Epoch 6/100, Batch 300/414, Loss: 7.1849
Epoch 6/100, Batch 310/414, Loss: 7.3113
Epoch 6/100, Batch 320/414, Loss: 7.2166
Epoch 6/100, Batch 330/414, Loss: 7.0689
Epoch 6/100, Batch 340/414, Loss: 7.1363
Epoch 6/100, Batch 350/414, Loss: 7.3248
Epoch 6/100, Batch 360/414, Loss: 6.8251
Epoch 6/100, Batch 370/414, Loss: 7.2458
Epoch 6/100, Batch 380/414, Loss: 7.0831
Epoch 6/100, Batch 390/414, Loss: 7.1907
Epoch 6/100, Batch 400/414, Loss: 7.1710
Epoch 6/100, Batch 410/414, Loss: 7.1872
New best model with validation loss: 7.0147, perplexity: 1112.89
Epoch 6/100, Loss: 7.2565, Perplexity: 1417.23, Val Loss: 7.0147, Val Perplexity: 1112.89, Time: 260.22s
Epoch 7/100, Batch 10/414, Loss: 7.2224
Epoch 7/100, Batch 20/414, Loss: 6.9881
Epoch 7/100, Batch 30/414, Loss: 6.9416
Epoch 7/100, Batch 40/414, Loss: 7.2630
Epoch 7/100, Batch 50/414, Loss: 7.3075
Epoch 7/100, Batch 60/414, Loss: 7.1333
Epoch 7/100, Batch 70/414, Loss: 6.9170
Epoch 7/100, Batch 80/414, Loss: 6.9874
Epoch 7/100, Batch 90/414, Loss: 6.8743
Epoch 7/100, Batch 100/414, Loss: 7.2247
Epoch 7/100, Batch 110/414, Loss: 7.2112
Epoch 7/100, Batch 120/414, Loss: 6.8863
Epoch 7/100, Batch 130/414, Loss: 7.0529
Epoch 7/100, Batch 140/414, Loss: 7.2086
Epoch 7/100, Batch 150/414, Loss: 7.2294
Epoch 7/100, Batch 160/414, Loss: 7.0826
Epoch 7/100, Batch 170/414, Loss: 7.1885
Epoch 7/100, Batch 180/414, Loss: 6.9906
Epoch 7/100, Batch 190/414, Loss: 7.1736
Epoch 7/100, Batch 200/414, Loss: 6.9372
Epoch 7/100, Batch 210/414, Loss: 7.0109
Epoch 7/100, Batch 220/414, Loss: 6.9187
Epoch 7/100, Batch 230/414, Loss: 7.1076
Epoch 7/100, Batch 240/414, Loss: 7.0442
Epoch 7/100, Batch 250/414, Loss: 6.9068
Epoch 7/100, Batch 260/414, Loss: 7.1723
Epoch 7/100, Batch 270/414, Loss: 7.2443
Epoch 7/100, Batch 280/414, Loss: 7.0138
Epoch 7/100, Batch 290/414, Loss: 7.0577
Epoch 7/100, Batch 300/414, Loss: 6.9746
Epoch 7/100, Batch 310/414, Loss: 7.0984
Epoch 7/100, Batch 320/414, Loss: 7.0194
Epoch 7/100, Batch 330/414, Loss: 6.8523
Epoch 7/100, Batch 340/414, Loss: 6.9318
Epoch 7/100, Batch 350/414, Loss: 7.1159
Epoch 7/100, Batch 360/414, Loss: 6.5853
Epoch 7/100, Batch 370/414, Loss: 7.0156
Epoch 7/100, Batch 380/414, Loss: 6.8773
Epoch 7/100, Batch 390/414, Loss: 6.9700
Epoch 7/100, Batch 400/414, Loss: 6.9423
Epoch 7/100, Batch 410/414, Loss: 6.9797
New best model with validation loss: 6.8009, perplexity: 898.68
Epoch 7/100, Loss: 7.0360, Perplexity: 1136.83, Val Loss: 6.8009, Val Perplexity: 898.68, Time: 260.23s
Epoch 8/100, Batch 10/414, Loss: 7.0251
Epoch 8/100, Batch 20/414, Loss: 6.7723
Epoch 8/100, Batch 30/414, Loss: 6.7239
Epoch 8/100, Batch 40/414, Loss: 7.1020
Epoch 8/100, Batch 50/414, Loss: 7.1196
Epoch 8/100, Batch 60/414, Loss: 6.9223
Epoch 8/100, Batch 70/414, Loss: 6.6967
Epoch 8/100, Batch 80/414, Loss: 6.7726
Epoch 8/100, Batch 90/414, Loss: 6.6762
Epoch 8/100, Batch 100/414, Loss: 7.0222
Epoch 8/100, Batch 110/414, Loss: 7.0315
Epoch 8/100, Batch 120/414, Loss: 6.6647
Epoch 8/100, Batch 130/414, Loss: 6.8541
Epoch 8/100, Batch 140/414, Loss: 7.0275
Epoch 8/100, Batch 150/414, Loss: 7.0492
Epoch 8/100, Batch 160/414, Loss: 6.9102
Epoch 8/100, Batch 170/414, Loss: 7.0394
Epoch 8/100, Batch 180/414, Loss: 6.7971
Epoch 8/100, Batch 190/414, Loss: 6.9697
Epoch 8/100, Batch 200/414, Loss: 6.7611
Epoch 8/100, Batch 210/414, Loss: 6.8247
Epoch 8/100, Batch 220/414, Loss: 6.7494
Epoch 8/100, Batch 230/414, Loss: 6.9239
Epoch 8/100, Batch 240/414, Loss: 6.8548
Epoch 8/100, Batch 250/414, Loss: 6.7082
Epoch 8/100, Batch 260/414, Loss: 7.0160
Epoch 8/100, Batch 270/414, Loss: 7.0974
Epoch 8/100, Batch 280/414, Loss: 6.8240
Epoch 8/100, Batch 290/414, Loss: 6.8734
Epoch 8/100, Batch 300/414, Loss: 6.8007
Epoch 8/100, Batch 310/414, Loss: 6.9424
Epoch 8/100, Batch 320/414, Loss: 6.8376
Epoch 8/100, Batch 330/414, Loss: 6.6679
Epoch 8/100, Batch 340/414, Loss: 6.7538
Epoch 8/100, Batch 350/414, Loss: 6.9565
Epoch 8/100, Batch 360/414, Loss: 6.4124
Epoch 8/100, Batch 370/414, Loss: 6.8343
Epoch 8/100, Batch 380/414, Loss: 6.7139
Epoch 8/100, Batch 390/414, Loss: 6.7895
Epoch 8/100, Batch 400/414, Loss: 6.7767
Epoch 8/100, Batch 410/414, Loss: 6.8293
New best model with validation loss: 6.6394, perplexity: 764.60
Epoch 8/100, Loss: 6.8539, Perplexity: 947.58, Val Loss: 6.6394, Val Perplexity: 764.60, Time: 260.16s
Epoch 9/100, Batch 10/414, Loss: 6.8810
Epoch 9/100, Batch 20/414, Loss: 6.5991
Epoch 9/100, Batch 30/414, Loss: 6.5349
Epoch 9/100, Batch 40/414, Loss: 6.9618
Epoch 9/100, Batch 50/414, Loss: 6.9708
Epoch 9/100, Batch 60/414, Loss: 6.7711
Epoch 9/100, Batch 70/414, Loss: 6.5172
Epoch 9/100, Batch 80/414, Loss: 6.6393
Epoch 9/100, Batch 90/414, Loss: 6.5105
Epoch 9/100, Batch 100/414, Loss: 6.8509
Epoch 9/100, Batch 110/414, Loss: 6.8817
Epoch 9/100, Batch 120/414, Loss: 6.4982
Epoch 9/100, Batch 130/414, Loss: 6.6893
Epoch 9/100, Batch 140/414, Loss: 6.8977
Epoch 9/100, Batch 150/414, Loss: 6.8883
Epoch 9/100, Batch 160/414, Loss: 6.7383
Epoch 9/100, Batch 170/414, Loss: 6.9166
Epoch 9/100, Batch 180/414, Loss: 6.6303
Epoch 9/100, Batch 190/414, Loss: 6.8419
Epoch 9/100, Batch 200/414, Loss: 6.5950
Epoch 9/100, Batch 210/414, Loss: 6.6674
Epoch 9/100, Batch 220/414, Loss: 6.6040
Epoch 9/100, Batch 230/414, Loss: 6.7856
Epoch 9/100, Batch 240/414, Loss: 6.6938
Epoch 9/100, Batch 250/414, Loss: 6.5239
Epoch 9/100, Batch 260/414, Loss: 6.8797
Epoch 9/100, Batch 270/414, Loss: 6.9687
Epoch 9/100, Batch 280/414, Loss: 6.6942
Epoch 9/100, Batch 290/414, Loss: 6.7401
Epoch 9/100, Batch 300/414, Loss: 6.6649
Epoch 9/100, Batch 310/414, Loss: 6.7932
Epoch 9/100, Batch 320/414, Loss: 6.6869
Epoch 9/100, Batch 330/414, Loss: 6.5125
Epoch 9/100, Batch 340/414, Loss: 6.6108
Epoch 9/100, Batch 350/414, Loss: 6.8099
Epoch 9/100, Batch 360/414, Loss: 6.2744
Epoch 9/100, Batch 370/414, Loss: 6.6802
Epoch 9/100, Batch 380/414, Loss: 6.5770
Epoch 9/100, Batch 390/414, Loss: 6.6280
Epoch 9/100, Batch 400/414, Loss: 6.6083
Epoch 9/100, Batch 410/414, Loss: 6.6870
New best model with validation loss: 6.4958, perplexity: 662.37
Epoch 9/100, Loss: 6.7005, Perplexity: 812.84, Val Loss: 6.4958, Val Perplexity: 662.37, Time: 260.41s
Epoch 10/100, Batch 10/414, Loss: 6.7401
Epoch 10/100, Batch 20/414, Loss: 6.4506
Epoch 10/100, Batch 30/414, Loss: 6.3989
Epoch 10/100, Batch 40/414, Loss: 6.8270
Epoch 10/100, Batch 50/414, Loss: 6.7898
Epoch 10/100, Batch 60/414, Loss: 6.6396
Epoch 10/100, Batch 70/414, Loss: 6.3586
Epoch 10/100, Batch 80/414, Loss: 6.4886
Epoch 10/100, Batch 90/414, Loss: 6.3595
Epoch 10/100, Batch 100/414, Loss: 6.6936
Epoch 10/100, Batch 110/414, Loss: 6.7417
Epoch 10/100, Batch 120/414, Loss: 6.3352
Epoch 10/100, Batch 130/414, Loss: 6.5471
Epoch 10/100, Batch 140/414, Loss: 6.7546
Epoch 10/100, Batch 150/414, Loss: 6.7490
Epoch 10/100, Batch 160/414, Loss: 6.5933
Epoch 10/100, Batch 170/414, Loss: 6.8139
Epoch 10/100, Batch 180/414, Loss: 6.5004
Epoch 10/100, Batch 190/414, Loss: 6.6861
Epoch 10/100, Batch 200/414, Loss: 6.4790
Epoch 10/100, Batch 210/414, Loss: 6.5332
Epoch 10/100, Batch 220/414, Loss: 6.4696
Epoch 10/100, Batch 230/414, Loss: 6.6714
Epoch 10/100, Batch 240/414, Loss: 6.5764
Epoch 10/100, Batch 250/414, Loss: 6.3772
Epoch 10/100, Batch 260/414, Loss: 6.7562
Epoch 10/100, Batch 270/414, Loss: 6.8631
Epoch 10/100, Batch 280/414, Loss: 6.5543
Epoch 10/100, Batch 290/414, Loss: 6.6094
Epoch 10/100, Batch 300/414, Loss: 6.5505
Epoch 10/100, Batch 310/414, Loss: 6.6736
Epoch 10/100, Batch 320/414, Loss: 6.5620
Epoch 10/100, Batch 330/414, Loss: 6.3749
Epoch 10/100, Batch 340/414, Loss: 6.4749
Epoch 10/100, Batch 350/414, Loss: 6.6765
Epoch 10/100, Batch 360/414, Loss: 6.1396
Epoch 10/100, Batch 370/414, Loss: 6.5246
Epoch 10/100, Batch 380/414, Loss: 6.4359
Epoch 10/100, Batch 390/414, Loss: 6.4961
Epoch 10/100, Batch 400/414, Loss: 6.4803
Epoch 10/100, Batch 410/414, Loss: 6.5582
New best model with validation loss: 6.3773, perplexity: 588.35
Epoch 10/100, Loss: 6.5670, Perplexity: 711.27, Val Loss: 6.3773, Val Perplexity: 588.35, Time: 261.41s
Epoch 11/100, Batch 10/414, Loss: 6.6318
Epoch 11/100, Batch 20/414, Loss: 6.3397
Epoch 11/100, Batch 30/414, Loss: 6.2518
Epoch 11/100, Batch 40/414, Loss: 6.7014
Epoch 11/100, Batch 50/414, Loss: 6.7045
Epoch 11/100, Batch 60/414, Loss: 6.5067
Epoch 11/100, Batch 70/414, Loss: 6.2140
Epoch 11/100, Batch 80/414, Loss: 6.3534
Epoch 11/100, Batch 90/414, Loss: 6.2249
Epoch 11/100, Batch 100/414, Loss: 6.5610
Epoch 11/100, Batch 110/414, Loss: 6.6181
Epoch 11/100, Batch 120/414, Loss: 6.2083
Epoch 11/100, Batch 130/414, Loss: 6.4130
Epoch 11/100, Batch 140/414, Loss: 6.6228
Epoch 11/100, Batch 150/414, Loss: 6.6319
Epoch 11/100, Batch 160/414, Loss: 6.4760
Epoch 11/100, Batch 170/414, Loss: 6.6720
Epoch 11/100, Batch 180/414, Loss: 6.3676
Epoch 11/100, Batch 190/414, Loss: 6.5631
Epoch 11/100, Batch 200/414, Loss: 6.3453
Epoch 11/100, Batch 210/414, Loss: 6.3865
Epoch 11/100, Batch 220/414, Loss: 6.3528
Epoch 11/100, Batch 230/414, Loss: 6.5371
Epoch 11/100, Batch 240/414, Loss: 6.4494
Epoch 11/100, Batch 250/414, Loss: 6.2580
Epoch 11/100, Batch 260/414, Loss: 6.6590
Epoch 11/100, Batch 270/414, Loss: 6.7468
Epoch 11/100, Batch 280/414, Loss: 6.4375
Epoch 11/100, Batch 290/414, Loss: 6.4612
Epoch 11/100, Batch 300/414, Loss: 6.4459
Epoch 11/100, Batch 310/414, Loss: 6.5597
Epoch 11/100, Batch 320/414, Loss: 6.4463
Epoch 11/100, Batch 330/414, Loss: 6.2665
Epoch 11/100, Batch 340/414, Loss: 6.3530
Epoch 11/100, Batch 350/414, Loss: 6.5593
Epoch 11/100, Batch 360/414, Loss: 6.0185
Epoch 11/100, Batch 370/414, Loss: 6.3808
Epoch 11/100, Batch 380/414, Loss: 6.3305
Epoch 11/100, Batch 390/414, Loss: 6.3645
Epoch 11/100, Batch 400/414, Loss: 6.3454
Epoch 11/100, Batch 410/414, Loss: 6.4433
New best model with validation loss: 6.2678, perplexity: 527.34
Epoch 11/100, Loss: 6.4411, Perplexity: 627.10, Val Loss: 6.2678, Val Perplexity: 527.34, Time: 260.12s
Epoch 12/100, Batch 10/414, Loss: 6.5010
Epoch 12/100, Batch 20/414, Loss: 6.2005
Epoch 12/100, Batch 30/414, Loss: 6.1253
Epoch 12/100, Batch 40/414, Loss: 6.5840
Epoch 12/100, Batch 50/414, Loss: 6.5528
Epoch 12/100, Batch 60/414, Loss: 6.3750
Epoch 12/100, Batch 70/414, Loss: 6.0788
Epoch 12/100, Batch 80/414, Loss: 6.2241
Epoch 12/100, Batch 90/414, Loss: 6.1141
Epoch 12/100, Batch 100/414, Loss: 6.4369
Epoch 12/100, Batch 110/414, Loss: 6.5133
Epoch 12/100, Batch 120/414, Loss: 6.1010
Epoch 12/100, Batch 130/414, Loss: 6.3179
Epoch 12/100, Batch 140/414, Loss: 6.5221
Epoch 12/100, Batch 150/414, Loss: 6.5073
Epoch 12/100, Batch 160/414, Loss: 6.3681
Epoch 12/100, Batch 170/414, Loss: 6.5780
Epoch 12/100, Batch 180/414, Loss: 6.2595
Epoch 12/100, Batch 190/414, Loss: 6.4754
Epoch 12/100, Batch 200/414, Loss: 6.2425
Epoch 12/100, Batch 210/414, Loss: 6.2930
Epoch 12/100, Batch 220/414, Loss: 6.2781
Epoch 12/100, Batch 230/414, Loss: 6.4269
Epoch 12/100, Batch 240/414, Loss: 6.3404
Epoch 12/100, Batch 250/414, Loss: 6.1336
Epoch 12/100, Batch 260/414, Loss: 6.5429
Epoch 12/100, Batch 270/414, Loss: 6.6545
Epoch 12/100, Batch 280/414, Loss: 6.3259
Epoch 12/100, Batch 290/414, Loss: 6.3361
Epoch 12/100, Batch 300/414, Loss: 6.3390
Epoch 12/100, Batch 310/414, Loss: 6.4506
Epoch 12/100, Batch 320/414, Loss: 6.3463
Epoch 12/100, Batch 330/414, Loss: 6.1524
Epoch 12/100, Batch 340/414, Loss: 6.2504
Epoch 12/100, Batch 350/414, Loss: 6.4488
Epoch 12/100, Batch 360/414, Loss: 5.8998
Epoch 12/100, Batch 370/414, Loss: 6.2643
Epoch 12/100, Batch 380/414, Loss: 6.2258
Epoch 12/100, Batch 390/414, Loss: 6.2555
Epoch 12/100, Batch 400/414, Loss: 6.2317
Epoch 12/100, Batch 410/414, Loss: 6.3566
New best model with validation loss: 6.1733, perplexity: 479.78
Epoch 12/100, Loss: 6.3308, Perplexity: 561.59, Val Loss: 6.1733, Val Perplexity: 479.78, Time: 260.39s
Epoch 13/100, Batch 10/414, Loss: 6.4187
Epoch 13/100, Batch 20/414, Loss: 6.0973
Epoch 13/100, Batch 30/414, Loss: 6.0086
Epoch 13/100, Batch 40/414, Loss: 6.4950
Epoch 13/100, Batch 50/414, Loss: 6.4612
Epoch 13/100, Batch 60/414, Loss: 6.2597
Epoch 13/100, Batch 70/414, Loss: 5.9954
Epoch 13/100, Batch 80/414, Loss: 6.1134
Epoch 13/100, Batch 90/414, Loss: 5.9902
Epoch 13/100, Batch 100/414, Loss: 6.3290
Epoch 13/100, Batch 110/414, Loss: 6.4069
Epoch 13/100, Batch 120/414, Loss: 6.0079
Epoch 13/100, Batch 130/414, Loss: 6.2103
Epoch 13/100, Batch 140/414, Loss: 6.4098
Epoch 13/100, Batch 150/414, Loss: 6.4252
Epoch 13/100, Batch 160/414, Loss: 6.2867
Epoch 13/100, Batch 170/414, Loss: 6.4891
Epoch 13/100, Batch 180/414, Loss: 6.1325
Epoch 13/100, Batch 190/414, Loss: 6.3782
Epoch 13/100, Batch 200/414, Loss: 6.1248
Epoch 13/100, Batch 210/414, Loss: 6.1930
Epoch 13/100, Batch 220/414, Loss: 6.1740
Epoch 13/100, Batch 230/414, Loss: 6.3508
Epoch 13/100, Batch 240/414, Loss: 6.2459
Epoch 13/100, Batch 250/414, Loss: 6.0312
Epoch 13/100, Batch 260/414, Loss: 6.4653
Epoch 13/100, Batch 270/414, Loss: 6.5730
Epoch 13/100, Batch 280/414, Loss: 6.2234
Epoch 13/100, Batch 290/414, Loss: 6.2478
Epoch 13/100, Batch 300/414, Loss: 6.2462
Epoch 13/100, Batch 310/414, Loss: 6.3431
Epoch 13/100, Batch 320/414, Loss: 6.2564
Epoch 13/100, Batch 330/414, Loss: 6.0604
Epoch 13/100, Batch 340/414, Loss: 6.1449
Epoch 13/100, Batch 350/414, Loss: 6.3405
Epoch 13/100, Batch 360/414, Loss: 5.8053
Epoch 13/100, Batch 370/414, Loss: 6.1665
Epoch 13/100, Batch 380/414, Loss: 6.1439
Epoch 13/100, Batch 390/414, Loss: 6.1526
Epoch 13/100, Batch 400/414, Loss: 6.1267
Epoch 13/100, Batch 410/414, Loss: 6.2570
New best model with validation loss: 6.0955, perplexity: 443.88
Epoch 13/100, Loss: 6.2354, Perplexity: 510.53, Val Loss: 6.0955, Val Perplexity: 443.88, Time: 261.71s
Epoch 14/100, Batch 10/414, Loss: 6.3291
Epoch 14/100, Batch 20/414, Loss: 5.9914
Epoch 14/100, Batch 30/414, Loss: 5.9095
Epoch 14/100, Batch 40/414, Loss: 6.3989
Epoch 14/100, Batch 50/414, Loss: 6.3471
Epoch 14/100, Batch 60/414, Loss: 6.1669
Epoch 14/100, Batch 70/414, Loss: 5.8656
Epoch 14/100, Batch 80/414, Loss: 6.0040
Epoch 14/100, Batch 90/414, Loss: 5.9004
Epoch 14/100, Batch 100/414, Loss: 6.2398
Epoch 14/100, Batch 110/414, Loss: 6.3155
Epoch 14/100, Batch 120/414, Loss: 5.8892
Epoch 14/100, Batch 130/414, Loss: 6.1271
Epoch 14/100, Batch 140/414, Loss: 6.3060
Epoch 14/100, Batch 150/414, Loss: 6.3493
Epoch 14/100, Batch 160/414, Loss: 6.1883
Epoch 14/100, Batch 170/414, Loss: 6.3942
Epoch 14/100, Batch 180/414, Loss: 6.0805
Epoch 14/100, Batch 190/414, Loss: 6.2853
Epoch 14/100, Batch 200/414, Loss: 6.0365
Epoch 14/100, Batch 210/414, Loss: 6.0941
Epoch 14/100, Batch 220/414, Loss: 6.0989
Epoch 14/100, Batch 230/414, Loss: 6.2503
Epoch 14/100, Batch 240/414, Loss: 6.1530
Epoch 14/100, Batch 250/414, Loss: 5.9218
Epoch 14/100, Batch 260/414, Loss: 6.3714
Epoch 14/100, Batch 270/414, Loss: 6.4804
Epoch 14/100, Batch 280/414, Loss: 6.1432
Epoch 14/100, Batch 290/414, Loss: 6.1524
Epoch 14/100, Batch 300/414, Loss: 6.1744
Epoch 14/100, Batch 310/414, Loss: 6.2640
Epoch 14/100, Batch 320/414, Loss: 6.1820
Epoch 14/100, Batch 330/414, Loss: 5.9568
Epoch 14/100, Batch 340/414, Loss: 6.0673
Epoch 14/100, Batch 350/414, Loss: 6.2651
Epoch 14/100, Batch 360/414, Loss: 5.7030
Epoch 14/100, Batch 370/414, Loss: 6.0691
Epoch 14/100, Batch 380/414, Loss: 6.0461
Epoch 14/100, Batch 390/414, Loss: 6.1059
Epoch 14/100, Batch 400/414, Loss: 6.0210
Epoch 14/100, Batch 410/414, Loss: 6.1815
New best model with validation loss: 6.0263, perplexity: 414.19
Epoch 14/100, Loss: 6.1411, Perplexity: 464.57, Val Loss: 6.0263, Val Perplexity: 414.19, Time: 260.51s
Epoch 15/100, Batch 10/414, Loss: 6.2441
Epoch 15/100, Batch 20/414, Loss: 5.9118
Epoch 15/100, Batch 30/414, Loss: 5.8126
Epoch 15/100, Batch 40/414, Loss: 6.3253
Epoch 15/100, Batch 50/414, Loss: 6.2575
Epoch 15/100, Batch 60/414, Loss: 6.0754
Epoch 15/100, Batch 70/414, Loss: 5.7647
Epoch 15/100, Batch 80/414, Loss: 5.9050
Epoch 15/100, Batch 90/414, Loss: 5.8017
Epoch 15/100, Batch 100/414, Loss: 6.1494
Epoch 15/100, Batch 110/414, Loss: 6.2264
Epoch 15/100, Batch 120/414, Loss: 5.8094
Epoch 15/100, Batch 130/414, Loss: 6.0582
Epoch 15/100, Batch 140/414, Loss: 6.2228
Epoch 15/100, Batch 150/414, Loss: 6.2503
Epoch 15/100, Batch 160/414, Loss: 6.1012
Epoch 15/100, Batch 170/414, Loss: 6.3227
Epoch 15/100, Batch 180/414, Loss: 5.9835
Epoch 15/100, Batch 190/414, Loss: 6.2069
Epoch 15/100, Batch 200/414, Loss: 5.9566
Epoch 15/100, Batch 210/414, Loss: 6.0001
Epoch 15/100, Batch 220/414, Loss: 6.0274
Epoch 15/100, Batch 230/414, Loss: 6.1751
Epoch 15/100, Batch 240/414, Loss: 6.0810
Epoch 15/100, Batch 250/414, Loss: 5.8303
Epoch 15/100, Batch 260/414, Loss: 6.2893
Epoch 15/100, Batch 270/414, Loss: 6.4126
Epoch 15/100, Batch 280/414, Loss: 6.0510
Epoch 15/100, Batch 290/414, Loss: 6.0834
Epoch 15/100, Batch 300/414, Loss: 6.0973
Epoch 15/100, Batch 310/414, Loss: 6.1942
Epoch 15/100, Batch 320/414, Loss: 6.0987
Epoch 15/100, Batch 330/414, Loss: 5.8931
Epoch 15/100, Batch 340/414, Loss: 5.9872
Epoch 15/100, Batch 350/414, Loss: 6.2023
Epoch 15/100, Batch 360/414, Loss: 5.6365
Epoch 15/100, Batch 370/414, Loss: 5.9795
Epoch 15/100, Batch 380/414, Loss: 5.9913
Epoch 15/100, Batch 390/414, Loss: 5.9777
Epoch 15/100, Batch 400/414, Loss: 5.9401
Epoch 15/100, Batch 410/414, Loss: 6.0876
New best model with validation loss: 5.9643, perplexity: 389.28
Epoch 15/100, Loss: 6.0580, Perplexity: 427.51, Val Loss: 5.9643, Val Perplexity: 389.28, Time: 259.73s
Epoch 16/100, Batch 10/414, Loss: 6.1614
Epoch 16/100, Batch 20/414, Loss: 5.8492
Epoch 16/100, Batch 30/414, Loss: 5.7303
Epoch 16/100, Batch 40/414, Loss: 6.2486
Epoch 16/100, Batch 50/414, Loss: 6.1805
Epoch 16/100, Batch 60/414, Loss: 5.9977
Epoch 16/100, Batch 70/414, Loss: 5.6877
Epoch 16/100, Batch 80/414, Loss: 5.8205
Epoch 16/100, Batch 90/414, Loss: 5.7310
Epoch 16/100, Batch 100/414, Loss: 6.0744
Epoch 16/100, Batch 110/414, Loss: 6.1433
Epoch 16/100, Batch 120/414, Loss: 5.7123
Epoch 16/100, Batch 130/414, Loss: 5.9480
Epoch 16/100, Batch 140/414, Loss: 6.1213
Epoch 16/100, Batch 150/414, Loss: 6.1936
Epoch 16/100, Batch 160/414, Loss: 6.0041
Epoch 16/100, Batch 170/414, Loss: 6.2451
Epoch 16/100, Batch 180/414, Loss: 5.9080
Epoch 16/100, Batch 190/414, Loss: 6.1371
Epoch 16/100, Batch 200/414, Loss: 5.8790
Epoch 16/100, Batch 210/414, Loss: 5.9149
Epoch 16/100, Batch 220/414, Loss: 5.9548
Epoch 16/100, Batch 230/414, Loss: 6.1227
Epoch 16/100, Batch 240/414, Loss: 6.0079
Epoch 16/100, Batch 250/414, Loss: 5.7892
Epoch 16/100, Batch 260/414, Loss: 6.2209
Epoch 16/100, Batch 270/414, Loss: 6.3619
Epoch 16/100, Batch 280/414, Loss: 5.9901
Epoch 16/100, Batch 290/414, Loss: 6.0146
Epoch 16/100, Batch 300/414, Loss: 6.0394
Epoch 16/100, Batch 310/414, Loss: 6.1269
Epoch 16/100, Batch 320/414, Loss: 6.0295
Epoch 16/100, Batch 330/414, Loss: 5.8090
Epoch 16/100, Batch 340/414, Loss: 5.9124
Epoch 16/100, Batch 350/414, Loss: 6.0959
Epoch 16/100, Batch 360/414, Loss: 5.5663
Epoch 16/100, Batch 370/414, Loss: 5.8829
Epoch 16/100, Batch 380/414, Loss: 5.9236
Epoch 16/100, Batch 390/414, Loss: 5.8842
Epoch 16/100, Batch 400/414, Loss: 5.8544
Epoch 16/100, Batch 410/414, Loss: 6.0247
New best model with validation loss: 5.9099, perplexity: 368.67
Epoch 16/100, Loss: 5.9818, Perplexity: 396.15, Val Loss: 5.9099, Val Perplexity: 368.67, Time: 260.78s
Epoch 17/100, Batch 10/414, Loss: 6.0921
Epoch 17/100, Batch 20/414, Loss: 5.7527
Epoch 17/100, Batch 30/414, Loss: 5.6507
Epoch 17/100, Batch 40/414, Loss: 6.1521
Epoch 17/100, Batch 50/414, Loss: 6.0916
Epoch 17/100, Batch 60/414, Loss: 5.9194
Epoch 17/100, Batch 70/414, Loss: 5.6188
Epoch 17/100, Batch 80/414, Loss: 5.7302
Epoch 17/100, Batch 90/414, Loss: 5.6306
Epoch 17/100, Batch 100/414, Loss: 6.0047
Epoch 17/100, Batch 110/414, Loss: 6.0837
Epoch 17/100, Batch 120/414, Loss: 5.6394
Epoch 17/100, Batch 130/414, Loss: 5.8711
Epoch 17/100, Batch 140/414, Loss: 6.0558
Epoch 17/100, Batch 150/414, Loss: 6.1130
Epoch 17/100, Batch 160/414, Loss: 5.9439
Epoch 17/100, Batch 170/414, Loss: 6.1791
Epoch 17/100, Batch 180/414, Loss: 5.8301
Epoch 17/100, Batch 190/414, Loss: 6.0728
Epoch 17/100, Batch 200/414, Loss: 5.8272
Epoch 17/100, Batch 210/414, Loss: 5.8309
Epoch 17/100, Batch 220/414, Loss: 5.8912
Epoch 17/100, Batch 230/414, Loss: 6.0300
Epoch 17/100, Batch 240/414, Loss: 5.9414
Epoch 17/100, Batch 250/414, Loss: 5.6767
Epoch 17/100, Batch 260/414, Loss: 6.1447
Epoch 17/100, Batch 270/414, Loss: 6.2817
Epoch 17/100, Batch 280/414, Loss: 5.9148
Epoch 17/100, Batch 290/414, Loss: 5.9251
Epoch 17/100, Batch 300/414, Loss: 5.9457
Epoch 17/100, Batch 310/414, Loss: 6.0453
Epoch 17/100, Batch 320/414, Loss: 5.9647
Epoch 17/100, Batch 330/414, Loss: 5.7328
Epoch 17/100, Batch 340/414, Loss: 5.8181
Epoch 17/100, Batch 350/414, Loss: 6.0281
Epoch 17/100, Batch 360/414, Loss: 5.5039
Epoch 17/100, Batch 370/414, Loss: 5.8298
Epoch 17/100, Batch 380/414, Loss: 5.8467
Epoch 17/100, Batch 390/414, Loss: 5.8296
Epoch 17/100, Batch 400/414, Loss: 5.8015
Epoch 17/100, Batch 410/414, Loss: 5.9432
New best model with validation loss: 5.8553, perplexity: 349.10
Epoch 17/100, Loss: 5.9044, Perplexity: 366.66, Val Loss: 5.8553, Val Perplexity: 349.10, Time: 260.26s
Epoch 18/100, Batch 10/414, Loss: 6.0062
Epoch 18/100, Batch 20/414, Loss: 5.6956
Epoch 18/100, Batch 30/414, Loss: 5.5561
Epoch 18/100, Batch 40/414, Loss: 6.0807
Epoch 18/100, Batch 50/414, Loss: 6.0048
Epoch 18/100, Batch 60/414, Loss: 5.8212
Epoch 18/100, Batch 70/414, Loss: 5.5331
Epoch 18/100, Batch 80/414, Loss: 5.6332
Epoch 18/100, Batch 90/414, Loss: 5.5633
Epoch 18/100, Batch 100/414, Loss: 5.9176
Epoch 18/100, Batch 110/414, Loss: 5.9933
Epoch 18/100, Batch 120/414, Loss: 5.5581
Epoch 18/100, Batch 130/414, Loss: 5.8004
Epoch 18/100, Batch 140/414, Loss: 5.9460
Epoch 18/100, Batch 150/414, Loss: 6.0604
Epoch 18/100, Batch 160/414, Loss: 5.8551
Epoch 18/100, Batch 170/414, Loss: 6.0957
Epoch 18/100, Batch 180/414, Loss: 5.7615
Epoch 18/100, Batch 190/414, Loss: 5.9933
Epoch 18/100, Batch 200/414, Loss: 5.7353
Epoch 18/100, Batch 210/414, Loss: 5.7624
Epoch 18/100, Batch 220/414, Loss: 5.8328
Epoch 18/100, Batch 230/414, Loss: 5.9566
Epoch 18/100, Batch 240/414, Loss: 5.8500
Epoch 18/100, Batch 250/414, Loss: 5.6057
Epoch 18/100, Batch 260/414, Loss: 6.0795
Epoch 18/100, Batch 270/414, Loss: 6.2142
Epoch 18/100, Batch 280/414, Loss: 5.8347
Epoch 18/100, Batch 290/414, Loss: 5.8471
Epoch 18/100, Batch 300/414, Loss: 5.8751
Epoch 18/100, Batch 310/414, Loss: 6.0054
Epoch 18/100, Batch 320/414, Loss: 5.9050
Epoch 18/100, Batch 330/414, Loss: 5.6740
Epoch 18/100, Batch 340/414, Loss: 5.7683
Epoch 18/100, Batch 350/414, Loss: 5.9454
Epoch 18/100, Batch 360/414, Loss: 5.4271
Epoch 18/100, Batch 370/414, Loss: 5.7438
Epoch 18/100, Batch 380/414, Loss: 5.7757
Epoch 18/100, Batch 390/414, Loss: 5.7516
Epoch 18/100, Batch 400/414, Loss: 5.6768
Epoch 18/100, Batch 410/414, Loss: 5.8939
New best model with validation loss: 5.8053, perplexity: 332.04
Epoch 18/100, Loss: 5.8331, Perplexity: 341.42, Val Loss: 5.8053, Val Perplexity: 332.04, Time: 260.77s
Epoch 19/100, Batch 10/414, Loss: 5.9436
Epoch 19/100, Batch 20/414, Loss: 5.6057
Epoch 19/100, Batch 30/414, Loss: 5.5095
Epoch 19/100, Batch 40/414, Loss: 6.0039
Epoch 19/100, Batch 50/414, Loss: 5.9353
Epoch 19/100, Batch 60/414, Loss: 5.7562
Epoch 19/100, Batch 70/414, Loss: 5.4710
Epoch 19/100, Batch 80/414, Loss: 5.5587
Epoch 19/100, Batch 90/414, Loss: 5.4995
Epoch 19/100, Batch 100/414, Loss: 5.8610
Epoch 19/100, Batch 110/414, Loss: 5.9369
Epoch 19/100, Batch 120/414, Loss: 5.4917
Epoch 19/100, Batch 130/414, Loss: 5.7379
Epoch 19/100, Batch 140/414, Loss: 5.8681
Epoch 19/100, Batch 150/414, Loss: 5.9511
Epoch 19/100, Batch 160/414, Loss: 5.7786
Epoch 19/100, Batch 170/414, Loss: 6.0283
Epoch 19/100, Batch 180/414, Loss: 5.6935
Epoch 19/100, Batch 190/414, Loss: 5.9240
Epoch 19/100, Batch 200/414, Loss: 5.6534
Epoch 19/100, Batch 210/414, Loss: 5.7103
Epoch 19/100, Batch 220/414, Loss: 5.7699
Epoch 19/100, Batch 230/414, Loss: 5.9213
Epoch 19/100, Batch 240/414, Loss: 5.7920
Epoch 19/100, Batch 250/414, Loss: 5.5746
Epoch 19/100, Batch 260/414, Loss: 5.9965
Epoch 19/100, Batch 270/414, Loss: 6.1407
Epoch 19/100, Batch 280/414, Loss: 5.7712
Epoch 19/100, Batch 290/414, Loss: 5.7702
Epoch 19/100, Batch 300/414, Loss: 5.8164
Epoch 19/100, Batch 310/414, Loss: 5.9296
Epoch 19/100, Batch 320/414, Loss: 5.8015
Epoch 19/100, Batch 330/414, Loss: 5.5978
Epoch 19/100, Batch 340/414, Loss: 5.6813
Epoch 19/100, Batch 350/414, Loss: 5.8720
Epoch 19/100, Batch 360/414, Loss: 5.3355
Epoch 19/100, Batch 370/414, Loss: 5.6776
Epoch 19/100, Batch 380/414, Loss: 5.7144
Epoch 19/100, Batch 390/414, Loss: 5.6864
Epoch 19/100, Batch 400/414, Loss: 5.6068
Epoch 19/100, Batch 410/414, Loss: 5.8125
New best model with validation loss: 5.7620, perplexity: 317.98
Epoch 19/100, Loss: 5.7628, Perplexity: 318.23, Val Loss: 5.7620, Val Perplexity: 317.98, Time: 259.11s
Epoch 20/100, Batch 10/414, Loss: 5.8764
Epoch 20/100, Batch 20/414, Loss: 5.5419
Epoch 20/100, Batch 30/414, Loss: 5.4331
Epoch 20/100, Batch 40/414, Loss: 5.9285
Epoch 20/100, Batch 50/414, Loss: 5.8750
Epoch 20/100, Batch 60/414, Loss: 5.6655
Epoch 20/100, Batch 70/414, Loss: 5.3703
Epoch 20/100, Batch 80/414, Loss: 5.4708
Epoch 20/100, Batch 90/414, Loss: 5.4149
Epoch 20/100, Batch 100/414, Loss: 5.7726
Epoch 20/100, Batch 110/414, Loss: 5.8532
Epoch 20/100, Batch 120/414, Loss: 5.4163
Epoch 20/100, Batch 130/414, Loss: 5.6794
Epoch 20/100, Batch 140/414, Loss: 5.8022
Epoch 20/100, Batch 150/414, Loss: 5.8936
Epoch 20/100, Batch 160/414, Loss: 5.6818
Epoch 20/100, Batch 170/414, Loss: 5.9433
Epoch 20/100, Batch 180/414, Loss: 5.6132
Epoch 20/100, Batch 190/414, Loss: 5.8452
Epoch 20/100, Batch 200/414, Loss: 5.5976
Epoch 20/100, Batch 210/414, Loss: 5.6264
Epoch 20/100, Batch 220/414, Loss: 5.7024
Epoch 20/100, Batch 230/414, Loss: 5.8343
Epoch 20/100, Batch 240/414, Loss: 5.7279
Epoch 20/100, Batch 250/414, Loss: 5.4728
Epoch 20/100, Batch 260/414, Loss: 5.9468
Epoch 20/100, Batch 270/414, Loss: 6.0835
Epoch 20/100, Batch 280/414, Loss: 5.6926
Epoch 20/100, Batch 290/414, Loss: 5.7172
Epoch 20/100, Batch 300/414, Loss: 5.7398
Epoch 20/100, Batch 310/414, Loss: 5.8751
Epoch 20/100, Batch 320/414, Loss: 5.7516
Epoch 20/100, Batch 330/414, Loss: 5.5430
Epoch 20/100, Batch 340/414, Loss: 5.6186
Epoch 20/100, Batch 350/414, Loss: 5.8193
Epoch 20/100, Batch 360/414, Loss: 5.2947
Epoch 20/100, Batch 370/414, Loss: 5.5969
Epoch 20/100, Batch 380/414, Loss: 5.6544
Epoch 20/100, Batch 390/414, Loss: 5.5949
Epoch 20/100, Batch 400/414, Loss: 5.5257
Epoch 20/100, Batch 410/414, Loss: 5.7580
New best model with validation loss: 5.7202, perplexity: 304.98
Epoch 20/100, Loss: 5.6905, Perplexity: 296.05, Val Loss: 5.7202, Val Perplexity: 304.98, Time: 261.05s
Epoch 21/100, Batch 10/414, Loss: 5.8254
Epoch 21/100, Batch 20/414, Loss: 5.4700
Epoch 21/100, Batch 30/414, Loss: 5.3451
Epoch 21/100, Batch 40/414, Loss: 5.8826
Epoch 21/100, Batch 50/414, Loss: 5.7815
Epoch 21/100, Batch 60/414, Loss: 5.5931
Epoch 21/100, Batch 70/414, Loss: 5.3034
Epoch 21/100, Batch 80/414, Loss: 5.3923
Epoch 21/100, Batch 90/414, Loss: 5.3236
Epoch 21/100, Batch 100/414, Loss: 5.7234
Epoch 21/100, Batch 110/414, Loss: 5.7841
Epoch 21/100, Batch 120/414, Loss: 5.3387
Epoch 21/100, Batch 130/414, Loss: 5.5941
Epoch 21/100, Batch 140/414, Loss: 5.7455
Epoch 21/100, Batch 150/414, Loss: 5.8427
Epoch 21/100, Batch 160/414, Loss: 5.6296
Epoch 21/100, Batch 170/414, Loss: 5.8758
Epoch 21/100, Batch 180/414, Loss: 5.5701
Epoch 21/100, Batch 190/414, Loss: 5.7824
Epoch 21/100, Batch 200/414, Loss: 5.5391
Epoch 21/100, Batch 210/414, Loss: 5.5479
Epoch 21/100, Batch 220/414, Loss: 5.6356
Epoch 21/100, Batch 230/414, Loss: 5.7846
Epoch 21/100, Batch 240/414, Loss: 5.6666
Epoch 21/100, Batch 250/414, Loss: 5.3894
Epoch 21/100, Batch 260/414, Loss: 5.8688
Epoch 21/100, Batch 270/414, Loss: 6.0067
Epoch 21/100, Batch 280/414, Loss: 5.6222
Epoch 21/100, Batch 290/414, Loss: 5.7284
Epoch 21/100, Batch 300/414, Loss: 5.7012
Epoch 21/100, Batch 310/414, Loss: 5.8109
Epoch 21/100, Batch 320/414, Loss: 5.6909
Epoch 21/100, Batch 330/414, Loss: 5.4753
Epoch 21/100, Batch 340/414, Loss: 5.5586
Epoch 21/100, Batch 350/414, Loss: 5.7334
Epoch 21/100, Batch 360/414, Loss: 5.2266
Epoch 21/100, Batch 370/414, Loss: 5.5333
Epoch 21/100, Batch 380/414, Loss: 5.5793
Epoch 21/100, Batch 390/414, Loss: 5.5592
Epoch 21/100, Batch 400/414, Loss: 5.4634
Epoch 21/100, Batch 410/414, Loss: 5.6918
New best model with validation loss: 5.6759, perplexity: 291.74
Epoch 21/100, Loss: 5.6234, Perplexity: 276.82, Val Loss: 5.6759, Val Perplexity: 291.74, Time: 260.33s
Epoch 22/100, Batch 10/414, Loss: 5.7757
Epoch 22/100, Batch 20/414, Loss: 5.4055
Epoch 22/100, Batch 30/414, Loss: 5.2957
Epoch 22/100, Batch 40/414, Loss: 5.8044
Epoch 22/100, Batch 50/414, Loss: 5.7245
Epoch 22/100, Batch 60/414, Loss: 5.5285
Epoch 22/100, Batch 70/414, Loss: 5.2323
Epoch 22/100, Batch 80/414, Loss: 5.3398
Epoch 22/100, Batch 90/414, Loss: 5.2674
Epoch 22/100, Batch 100/414, Loss: 5.6357
Epoch 22/100, Batch 110/414, Loss: 5.7102
Epoch 22/100, Batch 120/414, Loss: 5.2633
Epoch 22/100, Batch 130/414, Loss: 5.5361
Epoch 22/100, Batch 140/414, Loss: 5.6633
Epoch 22/100, Batch 150/414, Loss: 5.7660
Epoch 22/100, Batch 160/414, Loss: 5.5586
Epoch 22/100, Batch 170/414, Loss: 5.8025
Epoch 22/100, Batch 180/414, Loss: 5.5062
Epoch 22/100, Batch 190/414, Loss: 5.7156
Epoch 22/100, Batch 200/414, Loss: 5.4892
Epoch 22/100, Batch 210/414, Loss: 5.4946
Epoch 22/100, Batch 220/414, Loss: 5.5644
Epoch 22/100, Batch 230/414, Loss: 5.7264
Epoch 22/100, Batch 240/414, Loss: 5.6175
Epoch 22/100, Batch 250/414, Loss: 5.3274
Epoch 22/100, Batch 260/414, Loss: 5.7959
Epoch 22/100, Batch 270/414, Loss: 5.9382
Epoch 22/100, Batch 280/414, Loss: 5.5653
Epoch 22/100, Batch 290/414, Loss: 5.5839
Epoch 22/100, Batch 300/414, Loss: 5.6250
Epoch 22/100, Batch 310/414, Loss: 5.7533
Epoch 22/100, Batch 320/414, Loss: 5.6462
Epoch 22/100, Batch 330/414, Loss: 5.3987
Epoch 22/100, Batch 340/414, Loss: 5.4900
Epoch 22/100, Batch 350/414, Loss: 5.6980
Epoch 22/100, Batch 360/414, Loss: 5.1638
Epoch 22/100, Batch 370/414, Loss: 5.4642
Epoch 22/100, Batch 380/414, Loss: 5.5212
Epoch 22/100, Batch 390/414, Loss: 5.4821
Epoch 22/100, Batch 400/414, Loss: 5.3665
Epoch 22/100, Batch 410/414, Loss: 5.6248
New best model with validation loss: 5.6419, perplexity: 281.99
Epoch 22/100, Loss: 5.5621, Perplexity: 260.38, Val Loss: 5.6419, Val Perplexity: 281.99, Time: 260.46s
Epoch 23/100, Batch 10/414, Loss: 5.6881
Epoch 23/100, Batch 20/414, Loss: 5.3346
Epoch 23/100, Batch 30/414, Loss: 5.2315
Epoch 23/100, Batch 40/414, Loss: 5.7539
Epoch 23/100, Batch 50/414, Loss: 5.6776
Epoch 23/100, Batch 60/414, Loss: 5.4600
Epoch 23/100, Batch 70/414, Loss: 5.1676
Epoch 23/100, Batch 80/414, Loss: 5.2751
Epoch 23/100, Batch 90/414, Loss: 5.2243
Epoch 23/100, Batch 100/414, Loss: 5.6027
Epoch 23/100, Batch 110/414, Loss: 5.6641
Epoch 23/100, Batch 120/414, Loss: 5.2226
Epoch 23/100, Batch 130/414, Loss: 5.4871
Epoch 23/100, Batch 140/414, Loss: 5.5961
Epoch 23/100, Batch 150/414, Loss: 5.7039
Epoch 23/100, Batch 160/414, Loss: 5.4964
Epoch 23/100, Batch 170/414, Loss: 5.7419
Epoch 23/100, Batch 180/414, Loss: 5.4530
Epoch 23/100, Batch 190/414, Loss: 5.6672
Epoch 23/100, Batch 200/414, Loss: 5.4125
Epoch 23/100, Batch 210/414, Loss: 5.4259
Epoch 23/100, Batch 220/414, Loss: 5.5171
Epoch 23/100, Batch 230/414, Loss: 5.6556
Epoch 23/100, Batch 240/414, Loss: 5.5765
Epoch 23/100, Batch 250/414, Loss: 5.2943
Epoch 23/100, Batch 260/414, Loss: 5.7342
Epoch 23/100, Batch 270/414, Loss: 5.9107
Epoch 23/100, Batch 280/414, Loss: 5.5038
Epoch 23/100, Batch 290/414, Loss: 5.5128
Epoch 23/100, Batch 300/414, Loss: 5.5580
Epoch 23/100, Batch 310/414, Loss: 5.6742
Epoch 23/100, Batch 320/414, Loss: 5.5971
Epoch 23/100, Batch 330/414, Loss: 5.3616
Epoch 23/100, Batch 340/414, Loss: 5.4426
Epoch 23/100, Batch 350/414, Loss: 5.6483
Epoch 23/100, Batch 360/414, Loss: 5.0821
Epoch 23/100, Batch 370/414, Loss: 5.5297
Epoch 23/100, Batch 380/414, Loss: 5.4748
Epoch 23/100, Batch 390/414, Loss: 5.4129
Epoch 23/100, Batch 400/414, Loss: 5.2845
Epoch 23/100, Batch 410/414, Loss: 5.5710
New best model with validation loss: 5.6122, perplexity: 273.75
Epoch 23/100, Loss: 5.5037, Perplexity: 245.61, Val Loss: 5.6122, Val Perplexity: 273.75, Time: 260.73s
Epoch 24/100, Batch 10/414, Loss: 5.6194
Epoch 24/100, Batch 20/414, Loss: 5.2950
Epoch 24/100, Batch 30/414, Loss: 5.2000
Epoch 24/100, Batch 40/414, Loss: 5.6876
Epoch 24/100, Batch 50/414, Loss: 5.5935
Epoch 24/100, Batch 60/414, Loss: 5.3948
Epoch 24/100, Batch 70/414, Loss: 5.0975
Epoch 24/100, Batch 80/414, Loss: 5.1899
Epoch 24/100, Batch 90/414, Loss: 5.1466
Epoch 24/100, Batch 100/414, Loss: 5.5381
Epoch 24/100, Batch 110/414, Loss: 5.6463
Epoch 24/100, Batch 120/414, Loss: 5.1484
Epoch 24/100, Batch 130/414, Loss: 5.4532
Epoch 24/100, Batch 140/414, Loss: 5.5283
Epoch 24/100, Batch 150/414, Loss: 5.6675
Epoch 24/100, Batch 160/414, Loss: 5.4532
Epoch 24/100, Batch 170/414, Loss: 5.7001
Epoch 24/100, Batch 180/414, Loss: 5.3891
Epoch 24/100, Batch 190/414, Loss: 5.6019
Epoch 24/100, Batch 200/414, Loss: 5.3461
Epoch 24/100, Batch 210/414, Loss: 5.3502
Epoch 24/100, Batch 220/414, Loss: 5.4700
Epoch 24/100, Batch 230/414, Loss: 5.6378
Epoch 24/100, Batch 240/414, Loss: 5.5131
Epoch 24/100, Batch 250/414, Loss: 5.2229
Epoch 24/100, Batch 260/414, Loss: 5.6648
Epoch 24/100, Batch 270/414, Loss: 5.8263
Epoch 24/100, Batch 280/414, Loss: 5.4710
Epoch 24/100, Batch 290/414, Loss: 5.4655
Epoch 24/100, Batch 300/414, Loss: 5.5267
Epoch 24/100, Batch 310/414, Loss: 5.6291
Epoch 24/100, Batch 320/414, Loss: 5.5425
Epoch 24/100, Batch 330/414, Loss: 5.2908
Epoch 24/100, Batch 340/414, Loss: 5.3981
Epoch 24/100, Batch 350/414, Loss: 5.5849
Epoch 24/100, Batch 360/414, Loss: 5.0579
Epoch 24/100, Batch 370/414, Loss: 5.3531
Epoch 24/100, Batch 380/414, Loss: 5.4227
Epoch 24/100, Batch 390/414, Loss: 5.3550
Epoch 24/100, Batch 400/414, Loss: 5.2344
Epoch 24/100, Batch 410/414, Loss: 5.5276
New best model with validation loss: 5.5834, perplexity: 265.98
Epoch 24/100, Loss: 5.4471, Perplexity: 232.08, Val Loss: 5.5834, Val Perplexity: 265.98, Time: 260.17s
Epoch 25/100, Batch 10/414, Loss: 5.5765
Epoch 25/100, Batch 20/414, Loss: 5.2329
Epoch 25/100, Batch 30/414, Loss: 5.1412
Epoch 25/100, Batch 40/414, Loss: 5.6413
Epoch 25/100, Batch 50/414, Loss: 5.5131
Epoch 25/100, Batch 60/414, Loss: 5.3316
Epoch 25/100, Batch 70/414, Loss: 5.0227
Epoch 25/100, Batch 80/414, Loss: 5.1611
Epoch 25/100, Batch 90/414, Loss: 5.0881
Epoch 25/100, Batch 100/414, Loss: 5.4969
Epoch 25/100, Batch 110/414, Loss: 5.5678
Epoch 25/100, Batch 120/414, Loss: 5.0922
Epoch 25/100, Batch 130/414, Loss: 5.3876
Epoch 25/100, Batch 140/414, Loss: 5.4704
Epoch 25/100, Batch 150/414, Loss: 5.5957
Epoch 25/100, Batch 160/414, Loss: 5.3756
Epoch 25/100, Batch 170/414, Loss: 5.6525
Epoch 25/100, Batch 180/414, Loss: 5.3298
Epoch 25/100, Batch 190/414, Loss: 5.5658
Epoch 25/100, Batch 200/414, Loss: 5.3025
Epoch 25/100, Batch 210/414, Loss: 5.3006
Epoch 25/100, Batch 220/414, Loss: 5.4080
Epoch 25/100, Batch 230/414, Loss: 5.5754
Epoch 25/100, Batch 240/414, Loss: 5.4610
Epoch 25/100, Batch 250/414, Loss: 5.1565
Epoch 25/100, Batch 260/414, Loss: 5.5892
Epoch 25/100, Batch 270/414, Loss: 5.7969
Epoch 25/100, Batch 280/414, Loss: 5.3905
Epoch 25/100, Batch 290/414, Loss: 5.3893
Epoch 25/100, Batch 300/414, Loss: 5.4906
Epoch 25/100, Batch 310/414, Loss: 5.5829
Epoch 25/100, Batch 320/414, Loss: 5.4673
Epoch 25/100, Batch 330/414, Loss: 5.2299
Epoch 25/100, Batch 340/414, Loss: 5.3341
Epoch 25/100, Batch 350/414, Loss: 5.5384
Epoch 25/100, Batch 360/414, Loss: 4.9940
Epoch 25/100, Batch 370/414, Loss: 5.2865
Epoch 25/100, Batch 380/414, Loss: 5.3593
Epoch 25/100, Batch 390/414, Loss: 5.2857
Epoch 25/100, Batch 400/414, Loss: 5.1562
Epoch 25/100, Batch 410/414, Loss: 5.5055
New best model with validation loss: 5.5498, perplexity: 257.19
Epoch 25/100, Loss: 5.3881, Perplexity: 218.78, Val Loss: 5.5498, Val Perplexity: 257.19, Time: 260.31s
Epoch 26/100, Batch 10/414, Loss: 5.5044
Epoch 26/100, Batch 20/414, Loss: 5.1842
Epoch 26/100, Batch 30/414, Loss: 5.0630
Epoch 26/100, Batch 40/414, Loss: 5.5790
Epoch 26/100, Batch 50/414, Loss: 5.4724
Epoch 26/100, Batch 60/414, Loss: 5.2841
Epoch 26/100, Batch 70/414, Loss: 4.9548
Epoch 26/100, Batch 80/414, Loss: 5.0999
Epoch 26/100, Batch 90/414, Loss: 5.0124
Epoch 26/100, Batch 100/414, Loss: 5.4204
Epoch 26/100, Batch 110/414, Loss: 5.4860
Epoch 26/100, Batch 120/414, Loss: 5.0798
Epoch 26/100, Batch 130/414, Loss: 5.3251
Epoch 26/100, Batch 140/414, Loss: 5.4228
Epoch 26/100, Batch 150/414, Loss: 5.5523
Epoch 26/100, Batch 160/414, Loss: 5.3169
Epoch 26/100, Batch 170/414, Loss: 5.5646
Epoch 26/100, Batch 180/414, Loss: 5.2687
Epoch 26/100, Batch 190/414, Loss: 5.5065
Epoch 26/100, Batch 200/414, Loss: 5.2357
Epoch 26/100, Batch 210/414, Loss: 5.2725
Epoch 26/100, Batch 220/414, Loss: 5.3617
Epoch 26/100, Batch 230/414, Loss: 5.5091
Epoch 26/100, Batch 240/414, Loss: 5.3951
Epoch 26/100, Batch 250/414, Loss: 5.0955
Epoch 26/100, Batch 260/414, Loss: 5.5449
Epoch 26/100, Batch 270/414, Loss: 5.7216
Epoch 26/100, Batch 280/414, Loss: 5.3490
Epoch 26/100, Batch 290/414, Loss: 5.3239
Epoch 26/100, Batch 300/414, Loss: 5.4187
Epoch 26/100, Batch 310/414, Loss: 5.5366
Epoch 26/100, Batch 320/414, Loss: 5.4346
Epoch 26/100, Batch 330/414, Loss: 5.1751
Epoch 26/100, Batch 340/414, Loss: 5.2712
Epoch 26/100, Batch 350/414, Loss: 5.4618
Epoch 26/100, Batch 360/414, Loss: 4.9545
Epoch 26/100, Batch 370/414, Loss: 5.2477
Epoch 26/100, Batch 380/414, Loss: 5.2897
Epoch 26/100, Batch 390/414, Loss: 5.2298
Epoch 26/100, Batch 400/414, Loss: 5.1225
Epoch 26/100, Batch 410/414, Loss: 5.4082
New best model with validation loss: 5.5257, perplexity: 251.06
Epoch 26/100, Loss: 5.3312, Perplexity: 206.68, Val Loss: 5.5257, Val Perplexity: 251.06, Time: 259.67s
Epoch 27/100, Batch 10/414, Loss: 5.4746
Epoch 27/100, Batch 20/414, Loss: 5.1386
Epoch 27/100, Batch 30/414, Loss: 5.0036
Epoch 27/100, Batch 40/414, Loss: 5.5200
Epoch 27/100, Batch 50/414, Loss: 5.4139
Epoch 27/100, Batch 60/414, Loss: 5.2237
Epoch 27/100, Batch 70/414, Loss: 4.9080
Epoch 27/100, Batch 80/414, Loss: 5.0279
Epoch 27/100, Batch 90/414, Loss: 4.9418
Epoch 27/100, Batch 100/414, Loss: 5.3687
Epoch 27/100, Batch 110/414, Loss: 5.4575
Epoch 27/100, Batch 120/414, Loss: 4.9983
Epoch 27/100, Batch 130/414, Loss: 5.2848
Epoch 27/100, Batch 140/414, Loss: 5.3461
Epoch 27/100, Batch 150/414, Loss: 5.5071
Epoch 27/100, Batch 160/414, Loss: 5.2638
Epoch 27/100, Batch 170/414, Loss: 5.5526
Epoch 27/100, Batch 180/414, Loss: 5.2474
Epoch 27/100, Batch 190/414, Loss: 5.4932
Epoch 27/100, Batch 200/414, Loss: 5.1869
Epoch 27/100, Batch 210/414, Loss: 5.1983
Epoch 27/100, Batch 220/414, Loss: 5.3006
Epoch 27/100, Batch 230/414, Loss: 5.4533
Epoch 27/100, Batch 240/414, Loss: 5.3639
Epoch 27/100, Batch 250/414, Loss: 5.0488
Epoch 27/100, Batch 260/414, Loss: 5.4789
Epoch 27/100, Batch 270/414, Loss: 5.6769
Epoch 27/100, Batch 280/414, Loss: 5.3082
Epoch 27/100, Batch 290/414, Loss: 5.2874
Epoch 27/100, Batch 300/414, Loss: 5.3742
Epoch 27/100, Batch 310/414, Loss: 5.4751
Epoch 27/100, Batch 320/414, Loss: 5.3693
Epoch 27/100, Batch 330/414, Loss: 5.0940
Epoch 27/100, Batch 340/414, Loss: 5.2183
Epoch 27/100, Batch 350/414, Loss: 5.4288
Epoch 27/100, Batch 360/414, Loss: 4.8825
Epoch 27/100, Batch 370/414, Loss: 5.1627
Epoch 27/100, Batch 380/414, Loss: 5.2631
Epoch 27/100, Batch 390/414, Loss: 5.1827
Epoch 27/100, Batch 400/414, Loss: 5.0363
Epoch 27/100, Batch 410/414, Loss: 5.3568
New best model with validation loss: 5.4912, perplexity: 242.55
Epoch 27/100, Loss: 5.2788, Perplexity: 196.14, Val Loss: 5.4912, Val Perplexity: 242.55, Time: 260.01s
Epoch 28/100, Batch 10/414, Loss: 5.4212
Epoch 28/100, Batch 20/414, Loss: 5.0912
Epoch 28/100, Batch 30/414, Loss: 4.9661
Epoch 28/100, Batch 40/414, Loss: 5.4877
Epoch 28/100, Batch 50/414, Loss: 5.3694
Epoch 28/100, Batch 60/414, Loss: 5.1590
Epoch 28/100, Batch 70/414, Loss: 4.8745
Epoch 28/100, Batch 80/414, Loss: 4.9685
Epoch 28/100, Batch 90/414, Loss: 4.8992
Epoch 28/100, Batch 100/414, Loss: 5.3304
Epoch 28/100, Batch 110/414, Loss: 5.3966
Epoch 28/100, Batch 120/414, Loss: 4.9429
Epoch 28/100, Batch 130/414, Loss: 5.2345
Epoch 28/100, Batch 140/414, Loss: 5.3180
Epoch 28/100, Batch 150/414, Loss: 5.4317
Epoch 28/100, Batch 160/414, Loss: 5.2144
Epoch 28/100, Batch 170/414, Loss: 5.4553
Epoch 28/100, Batch 180/414, Loss: 5.1837
Epoch 28/100, Batch 190/414, Loss: 5.4212
Epoch 28/100, Batch 200/414, Loss: 5.1513
Epoch 28/100, Batch 210/414, Loss: 5.1301
Epoch 28/100, Batch 220/414, Loss: 5.2487
Epoch 28/100, Batch 230/414, Loss: 5.4016
Epoch 28/100, Batch 240/414, Loss: 5.2966
Epoch 28/100, Batch 250/414, Loss: 5.0196
Epoch 28/100, Batch 260/414, Loss: 5.4163
Epoch 28/100, Batch 270/414, Loss: 5.6034
Epoch 28/100, Batch 280/414, Loss: 5.2349
Epoch 28/100, Batch 290/414, Loss: 5.2071
Epoch 28/100, Batch 300/414, Loss: 5.3228
Epoch 28/100, Batch 310/414, Loss: 5.4134
Epoch 28/100, Batch 320/414, Loss: 5.3320
Epoch 28/100, Batch 330/414, Loss: 5.0607
Epoch 28/100, Batch 340/414, Loss: 5.1665
Epoch 28/100, Batch 350/414, Loss: 5.3522
Epoch 28/100, Batch 360/414, Loss: 4.8427
Epoch 28/100, Batch 370/414, Loss: 5.1318
Epoch 28/100, Batch 380/414, Loss: 5.2149
Epoch 28/100, Batch 390/414, Loss: 5.1272
Epoch 28/100, Batch 400/414, Loss: 5.0040
Epoch 28/100, Batch 410/414, Loss: 5.3121
New best model with validation loss: 5.4681, perplexity: 237.02
Epoch 28/100, Loss: 5.2271, Perplexity: 186.25, Val Loss: 5.4681, Val Perplexity: 237.02, Time: 260.05s
Epoch 29/100, Batch 10/414, Loss: 5.3662
Epoch 29/100, Batch 20/414, Loss: 5.0191
Epoch 29/100, Batch 30/414, Loss: 4.9027
Epoch 29/100, Batch 40/414, Loss: 5.4326
Epoch 29/100, Batch 50/414, Loss: 5.2988
Epoch 29/100, Batch 60/414, Loss: 5.0937
Epoch 29/100, Batch 70/414, Loss: 4.7931
Epoch 29/100, Batch 80/414, Loss: 4.9170
Epoch 29/100, Batch 90/414, Loss: 4.8635
Epoch 29/100, Batch 100/414, Loss: 5.2706
Epoch 29/100, Batch 110/414, Loss: 5.3345
Epoch 29/100, Batch 120/414, Loss: 4.8994
Epoch 29/100, Batch 130/414, Loss: 5.1938
Epoch 29/100, Batch 140/414, Loss: 5.2438
Epoch 29/100, Batch 150/414, Loss: 5.3984
Epoch 29/100, Batch 160/414, Loss: 5.1398
Epoch 29/100, Batch 170/414, Loss: 5.4047
Epoch 29/100, Batch 180/414, Loss: 5.1455
Epoch 29/100, Batch 190/414, Loss: 5.3799
Epoch 29/100, Batch 200/414, Loss: 5.0952
Epoch 29/100, Batch 210/414, Loss: 5.0943
Epoch 29/100, Batch 220/414, Loss: 5.2061
Epoch 29/100, Batch 230/414, Loss: 5.3510
Epoch 29/100, Batch 240/414, Loss: 5.2898
Epoch 29/100, Batch 250/414, Loss: 4.9544
Epoch 29/100, Batch 260/414, Loss: 5.4448
Epoch 29/100, Batch 270/414, Loss: 5.5741
Epoch 29/100, Batch 280/414, Loss: 5.1757
Epoch 29/100, Batch 290/414, Loss: 5.1794
Epoch 29/100, Batch 300/414, Loss: 5.2723
Epoch 29/100, Batch 310/414, Loss: 5.3914
Epoch 29/100, Batch 320/414, Loss: 5.3008
Epoch 29/100, Batch 330/414, Loss: 5.0078
Epoch 29/100, Batch 340/414, Loss: 5.1154
Epoch 29/100, Batch 350/414, Loss: 5.3409
Epoch 29/100, Batch 360/414, Loss: 4.7896
Epoch 29/100, Batch 370/414, Loss: 5.0988
Epoch 29/100, Batch 380/414, Loss: 5.1557
Epoch 29/100, Batch 390/414, Loss: 5.0648
Epoch 29/100, Batch 400/414, Loss: 4.9297
Epoch 29/100, Batch 410/414, Loss: 5.2500
New best model with validation loss: 5.4516, perplexity: 233.13
Epoch 29/100, Loss: 5.1776, Perplexity: 177.25, Val Loss: 5.4516, Val Perplexity: 233.13, Time: 261.17s
Epoch 30/100, Batch 10/414, Loss: 5.3057
Epoch 30/100, Batch 20/414, Loss: 5.0239
Epoch 30/100, Batch 30/414, Loss: 4.8681
Epoch 30/100, Batch 40/414, Loss: 5.3901
Epoch 30/100, Batch 50/414, Loss: 5.2627
Epoch 30/100, Batch 60/414, Loss: 5.0550
Epoch 30/100, Batch 70/414, Loss: 4.7528
Epoch 30/100, Batch 80/414, Loss: 4.8797
Epoch 30/100, Batch 90/414, Loss: 4.7870
Epoch 30/100, Batch 100/414, Loss: 5.2264
Epoch 30/100, Batch 110/414, Loss: 5.2992
Epoch 30/100, Batch 120/414, Loss: 4.8533
Epoch 30/100, Batch 130/414, Loss: 5.1589
Epoch 30/100, Batch 140/414, Loss: 5.2060
Epoch 30/100, Batch 150/414, Loss: 5.3707
Epoch 30/100, Batch 160/414, Loss: 5.1030
Epoch 30/100, Batch 170/414, Loss: 5.3695
Epoch 30/100, Batch 180/414, Loss: 5.0593
Epoch 30/100, Batch 190/414, Loss: 5.3019
Epoch 30/100, Batch 200/414, Loss: 5.0525
Epoch 30/100, Batch 210/414, Loss: 5.0238
Epoch 30/100, Batch 220/414, Loss: 5.1600
Epoch 30/100, Batch 230/414, Loss: 5.3297
Epoch 30/100, Batch 240/414, Loss: 5.2162
Epoch 30/100, Batch 250/414, Loss: 4.9270
Epoch 30/100, Batch 260/414, Loss: 5.3493
Epoch 30/100, Batch 270/414, Loss: 5.5089
Epoch 30/100, Batch 280/414, Loss: 5.1877
Epoch 30/100, Batch 290/414, Loss: 5.1062
Epoch 30/100, Batch 300/414, Loss: 5.2109
Epoch 30/100, Batch 310/414, Loss: 5.3514
Epoch 30/100, Batch 320/414, Loss: 5.2612
Epoch 30/100, Batch 330/414, Loss: 4.9711
Epoch 30/100, Batch 340/414, Loss: 5.0829
Epoch 30/100, Batch 350/414, Loss: 5.2801
Epoch 30/100, Batch 360/414, Loss: 4.7639
Epoch 30/100, Batch 370/414, Loss: 5.0328
Epoch 30/100, Batch 380/414, Loss: 5.0905
Epoch 30/100, Batch 390/414, Loss: 5.0169
Epoch 30/100, Batch 400/414, Loss: 4.9069
Epoch 30/100, Batch 410/414, Loss: 5.2116
New best model with validation loss: 5.4374, perplexity: 229.85
Epoch 30/100, Loss: 5.1360, Perplexity: 170.04, Val Loss: 5.4374, Val Perplexity: 229.85, Time: 260.54s
Epoch 31/100, Batch 10/414, Loss: 5.2920
Epoch 31/100, Batch 20/414, Loss: 4.9798
Epoch 31/100, Batch 30/414, Loss: 4.8334
Epoch 31/100, Batch 40/414, Loss: 5.3463
Epoch 31/100, Batch 50/414, Loss: 5.2051
Epoch 31/100, Batch 60/414, Loss: 5.0374
Epoch 31/100, Batch 70/414, Loss: 4.7355
Epoch 31/100, Batch 80/414, Loss: 4.8342
Epoch 31/100, Batch 90/414, Loss: 4.7605
Epoch 31/100, Batch 100/414, Loss: 5.2008
Epoch 31/100, Batch 110/414, Loss: 5.2179
Epoch 31/100, Batch 120/414, Loss: 4.8130
Epoch 31/100, Batch 130/414, Loss: 5.1169
Epoch 31/100, Batch 140/414, Loss: 5.1938
Epoch 31/100, Batch 150/414, Loss: 5.3211
Epoch 31/100, Batch 160/414, Loss: 5.0713
Epoch 31/100, Batch 170/414, Loss: 5.3227
Epoch 31/100, Batch 180/414, Loss: 5.0430
Epoch 31/100, Batch 190/414, Loss: 5.2737
Epoch 31/100, Batch 200/414, Loss: 5.0218
Epoch 31/100, Batch 210/414, Loss: 4.9729
Epoch 31/100, Batch 220/414, Loss: 5.1256
Epoch 31/100, Batch 230/414, Loss: 5.2876
Epoch 31/100, Batch 240/414, Loss: 5.1814
Epoch 31/100, Batch 250/414, Loss: 4.8816
Epoch 31/100, Batch 260/414, Loss: 5.3009
Epoch 31/100, Batch 270/414, Loss: 5.4760
Epoch 31/100, Batch 280/414, Loss: 5.1203
Epoch 31/100, Batch 290/414, Loss: 5.1049
Epoch 31/100, Batch 300/414, Loss: 5.2229
Epoch 31/100, Batch 310/414, Loss: 5.3403
Epoch 31/100, Batch 320/414, Loss: 5.2326
Epoch 31/100, Batch 330/414, Loss: 4.9128
Epoch 31/100, Batch 340/414, Loss: 5.0356
Epoch 31/100, Batch 350/414, Loss: 5.2563
Epoch 31/100, Batch 360/414, Loss: 4.7177
Epoch 31/100, Batch 370/414, Loss: 5.0252
Epoch 31/100, Batch 380/414, Loss: 5.1285
Epoch 31/100, Batch 390/414, Loss: 4.9821
Epoch 31/100, Batch 400/414, Loss: 4.8734
Epoch 31/100, Batch 410/414, Loss: 5.1719
New best model with validation loss: 5.4204, perplexity: 225.97
Epoch 31/100, Loss: 5.0975, Perplexity: 163.61, Val Loss: 5.4204, Val Perplexity: 225.97, Time: 260.07s
Epoch 32/100, Batch 10/414, Loss: 5.2402
Epoch 32/100, Batch 20/414, Loss: 4.9020
Epoch 32/100, Batch 30/414, Loss: 4.7816
Epoch 32/100, Batch 40/414, Loss: 5.3021
Epoch 32/100, Batch 50/414, Loss: 5.1860
Epoch 32/100, Batch 60/414, Loss: 4.9761
Epoch 32/100, Batch 70/414, Loss: 4.6528
Epoch 32/100, Batch 80/414, Loss: 4.8088
Epoch 32/100, Batch 90/414, Loss: 4.7038
Epoch 32/100, Batch 100/414, Loss: 5.1197
Epoch 32/100, Batch 110/414, Loss: 5.1863
Epoch 32/100, Batch 120/414, Loss: 4.7680
Epoch 32/100, Batch 130/414, Loss: 5.0712
Epoch 32/100, Batch 140/414, Loss: 5.1274
Epoch 32/100, Batch 150/414, Loss: 5.3255
Epoch 32/100, Batch 160/414, Loss: 5.0068
Epoch 32/100, Batch 170/414, Loss: 5.2820
Epoch 32/100, Batch 180/414, Loss: 4.9876
Epoch 32/100, Batch 190/414, Loss: 5.2331
Epoch 32/100, Batch 200/414, Loss: 4.9648
Epoch 32/100, Batch 210/414, Loss: 4.9451
Epoch 32/100, Batch 220/414, Loss: 5.0766
Epoch 32/100, Batch 230/414, Loss: 5.2341
Epoch 32/100, Batch 240/414, Loss: 5.1469
Epoch 32/100, Batch 250/414, Loss: 4.8357
Epoch 32/100, Batch 260/414, Loss: 5.2242
Epoch 32/100, Batch 270/414, Loss: 5.4242
Epoch 32/100, Batch 280/414, Loss: 5.0685
Epoch 32/100, Batch 290/414, Loss: 5.0424
Epoch 32/100, Batch 300/414, Loss: 5.1406
Epoch 32/100, Batch 310/414, Loss: 5.2561
Epoch 32/100, Batch 320/414, Loss: 5.1586
Epoch 32/100, Batch 330/414, Loss: 4.8607
Epoch 32/100, Batch 340/414, Loss: 5.0023
Epoch 32/100, Batch 350/414, Loss: 5.1874
Epoch 32/100, Batch 360/414, Loss: 4.6617
Epoch 32/100, Batch 370/414, Loss: 4.9419
Epoch 32/100, Batch 380/414, Loss: 5.0355
Epoch 32/100, Batch 390/414, Loss: 5.0696
Epoch 32/100, Batch 400/414, Loss: 4.8131
Epoch 32/100, Batch 410/414, Loss: 5.1328
New best model with validation loss: 5.3997, perplexity: 221.33
Epoch 32/100, Loss: 5.0481, Perplexity: 155.73, Val Loss: 5.3997, Val Perplexity: 221.33, Time: 259.56s
Epoch 33/100, Batch 10/414, Loss: 5.2097
Epoch 33/100, Batch 20/414, Loss: 4.8910
Epoch 33/100, Batch 30/414, Loss: 4.7436
Epoch 33/100, Batch 40/414, Loss: 5.2425
Epoch 33/100, Batch 50/414, Loss: 5.1430
Epoch 33/100, Batch 60/414, Loss: 4.9216
Epoch 33/100, Batch 70/414, Loss: 4.6203
Epoch 33/100, Batch 80/414, Loss: 4.7708
Epoch 33/100, Batch 90/414, Loss: 4.6495
Epoch 33/100, Batch 100/414, Loss: 5.0740
Epoch 33/100, Batch 110/414, Loss: 5.1346
Epoch 33/100, Batch 120/414, Loss: 4.7210
Epoch 33/100, Batch 130/414, Loss: 5.0320
Epoch 33/100, Batch 140/414, Loss: 5.0679
Epoch 33/100, Batch 150/414, Loss: 5.2263
Epoch 33/100, Batch 160/414, Loss: 4.9803
Epoch 33/100, Batch 170/414, Loss: 5.2379
Epoch 33/100, Batch 180/414, Loss: 4.9532
Epoch 33/100, Batch 190/414, Loss: 5.1728
Epoch 33/100, Batch 200/414, Loss: 4.9106
Epoch 33/100, Batch 210/414, Loss: 4.8910
Epoch 33/100, Batch 220/414, Loss: 5.0430
Epoch 33/100, Batch 230/414, Loss: 5.2024
Epoch 33/100, Batch 240/414, Loss: 5.1099
Epoch 33/100, Batch 250/414, Loss: 4.8063
Epoch 33/100, Batch 260/414, Loss: 5.1877
Epoch 33/100, Batch 270/414, Loss: 5.3392
Epoch 33/100, Batch 280/414, Loss: 5.0590
Epoch 33/100, Batch 290/414, Loss: 4.9888
Epoch 33/100, Batch 300/414, Loss: 5.0972
Epoch 33/100, Batch 310/414, Loss: 5.2089
Epoch 33/100, Batch 320/414, Loss: 5.1117
Epoch 33/100, Batch 330/414, Loss: 4.8081
Epoch 33/100, Batch 340/414, Loss: 4.9568
Epoch 33/100, Batch 350/414, Loss: 5.1743
Epoch 33/100, Batch 360/414, Loss: 4.6329
Epoch 33/100, Batch 370/414, Loss: 4.9142
Epoch 33/100, Batch 380/414, Loss: 4.9917
Epoch 33/100, Batch 390/414, Loss: 4.8847
Epoch 33/100, Batch 400/414, Loss: 4.7372
Epoch 33/100, Batch 410/414, Loss: 5.0928
New best model with validation loss: 5.3734, perplexity: 215.60
Epoch 33/100, Loss: 5.0024, Perplexity: 148.77, Val Loss: 5.3734, Val Perplexity: 215.60, Time: 260.36s
Epoch 34/100, Batch 10/414, Loss: 5.1351
Epoch 34/100, Batch 20/414, Loss: 4.8453
Epoch 34/100, Batch 30/414, Loss: 4.7189
Epoch 34/100, Batch 40/414, Loss: 5.1924
Epoch 34/100, Batch 50/414, Loss: 5.0880
Epoch 34/100, Batch 60/414, Loss: 4.8924
Epoch 34/100, Batch 70/414, Loss: 4.6029
Epoch 34/100, Batch 80/414, Loss: 4.7402
Epoch 34/100, Batch 90/414, Loss: 4.6137
Epoch 34/100, Batch 100/414, Loss: 5.0686
Epoch 34/100, Batch 110/414, Loss: 5.0814
Epoch 34/100, Batch 120/414, Loss: 4.6909
Epoch 34/100, Batch 130/414, Loss: 4.9775
Epoch 34/100, Batch 140/414, Loss: 5.0216
Epoch 34/100, Batch 150/414, Loss: 5.1912
Epoch 34/100, Batch 160/414, Loss: 4.9148
Epoch 34/100, Batch 170/414, Loss: 5.1983
Epoch 34/100, Batch 180/414, Loss: 4.9091
Epoch 34/100, Batch 190/414, Loss: 5.1462
Epoch 34/100, Batch 200/414, Loss: 4.8578
Epoch 34/100, Batch 210/414, Loss: 4.8518
Epoch 34/100, Batch 220/414, Loss: 4.9800
Epoch 34/100, Batch 230/414, Loss: 5.1556
Epoch 34/100, Batch 240/414, Loss: 5.0738
Epoch 34/100, Batch 250/414, Loss: 4.7505
Epoch 34/100, Batch 260/414, Loss: 5.1374
Epoch 34/100, Batch 270/414, Loss: 5.3447
Epoch 34/100, Batch 280/414, Loss: 5.0007
Epoch 34/100, Batch 290/414, Loss: 4.9543
Epoch 34/100, Batch 300/414, Loss: 5.0725
Epoch 34/100, Batch 310/414, Loss: 5.1942
Epoch 34/100, Batch 320/414, Loss: 5.0894
Epoch 34/100, Batch 330/414, Loss: 4.7629
Epoch 34/100, Batch 340/414, Loss: 4.8722
Epoch 34/100, Batch 350/414, Loss: 5.1280
Epoch 34/100, Batch 360/414, Loss: 4.5719
Epoch 34/100, Batch 370/414, Loss: 4.8668
Epoch 34/100, Batch 380/414, Loss: 4.9557
Epoch 34/100, Batch 390/414, Loss: 4.8274
Epoch 34/100, Batch 400/414, Loss: 4.7043
Epoch 34/100, Batch 410/414, Loss: 5.0887
New best model with validation loss: 5.3714, perplexity: 215.17
Epoch 34/100, Loss: 4.9598, Perplexity: 142.57, Val Loss: 5.3714, Val Perplexity: 215.17, Time: 260.14s
Epoch 35/100, Batch 10/414, Loss: 5.1173
Epoch 35/100, Batch 20/414, Loss: 4.8147
Epoch 35/100, Batch 30/414, Loss: 4.6644
Epoch 35/100, Batch 40/414, Loss: 5.1774
Epoch 35/100, Batch 50/414, Loss: 5.0406
Epoch 35/100, Batch 60/414, Loss: 4.8446
Epoch 35/100, Batch 70/414, Loss: 4.6888
Epoch 35/100, Batch 80/414, Loss: 4.6934
Epoch 35/100, Batch 90/414, Loss: 4.5921
Epoch 35/100, Batch 100/414, Loss: 5.0202
Epoch 35/100, Batch 110/414, Loss: 5.0427
Epoch 35/100, Batch 120/414, Loss: 4.6529
Epoch 35/100, Batch 130/414, Loss: 4.9675
Epoch 35/100, Batch 140/414, Loss: 4.9493
Epoch 35/100, Batch 150/414, Loss: 5.1449
Epoch 35/100, Batch 160/414, Loss: 4.8772
Epoch 35/100, Batch 170/414, Loss: 5.1288
Epoch 35/100, Batch 180/414, Loss: 4.8532
Epoch 35/100, Batch 190/414, Loss: 5.1574
Epoch 35/100, Batch 200/414, Loss: 4.8444
Epoch 35/100, Batch 210/414, Loss: 4.8151
Epoch 35/100, Batch 220/414, Loss: 4.9273
Epoch 35/100, Batch 230/414, Loss: 5.0627
Epoch 35/100, Batch 240/414, Loss: 5.0137
Epoch 35/100, Batch 250/414, Loss: 4.7129
Epoch 35/100, Batch 260/414, Loss: 5.0940
Epoch 35/100, Batch 270/414, Loss: 5.2783
Epoch 35/100, Batch 280/414, Loss: 4.9496
Epoch 35/100, Batch 290/414, Loss: 4.8767
Epoch 35/100, Batch 300/414, Loss: 5.0231
Epoch 35/100, Batch 310/414, Loss: 5.1538
Epoch 35/100, Batch 320/414, Loss: 5.0286
Epoch 35/100, Batch 330/414, Loss: 4.7641
Epoch 35/100, Batch 340/414, Loss: 4.8615
Epoch 35/100, Batch 350/414, Loss: 5.0896
Epoch 35/100, Batch 360/414, Loss: 4.5446
Epoch 35/100, Batch 370/414, Loss: 4.8149
Epoch 35/100, Batch 380/414, Loss: 4.8996
Epoch 35/100, Batch 390/414, Loss: 4.7807
Epoch 35/100, Batch 400/414, Loss: 4.6661
Epoch 35/100, Batch 410/414, Loss: 5.0101
New best model with validation loss: 5.3511, perplexity: 210.84
Epoch 35/100, Loss: 4.9155, Perplexity: 136.39, Val Loss: 5.3511, Val Perplexity: 210.84, Time: 259.85s
Epoch 36/100, Batch 10/414, Loss: 5.0470
Epoch 36/100, Batch 20/414, Loss: 4.7519
Epoch 36/100, Batch 30/414, Loss: 4.6248
Epoch 36/100, Batch 40/414, Loss: 5.1142
Epoch 36/100, Batch 50/414, Loss: 5.0081
Epoch 36/100, Batch 60/414, Loss: 4.7926
Epoch 36/100, Batch 70/414, Loss: 4.5282
Epoch 36/100, Batch 80/414, Loss: 4.6547
Epoch 36/100, Batch 90/414, Loss: 4.5212
Epoch 36/100, Batch 100/414, Loss: 4.9699
Epoch 36/100, Batch 110/414, Loss: 4.9911
Epoch 36/100, Batch 120/414, Loss: 4.6402
Epoch 36/100, Batch 130/414, Loss: 4.8985
Epoch 36/100, Batch 140/414, Loss: 4.9062
Epoch 36/100, Batch 150/414, Loss: 5.1091
Epoch 36/100, Batch 160/414, Loss: 4.8378
Epoch 36/100, Batch 170/414, Loss: 5.0752
Epoch 36/100, Batch 180/414, Loss: 4.8171
Epoch 36/100, Batch 190/414, Loss: 5.0488
Epoch 36/100, Batch 200/414, Loss: 4.7925
Epoch 36/100, Batch 210/414, Loss: 4.7840
Epoch 36/100, Batch 220/414, Loss: 4.8984
Epoch 36/100, Batch 230/414, Loss: 5.0438
Epoch 36/100, Batch 240/414, Loss: 5.0134
Epoch 36/100, Batch 250/414, Loss: 4.6672
Epoch 36/100, Batch 260/414, Loss: 5.0490
Epoch 36/100, Batch 270/414, Loss: 5.2540
Epoch 36/100, Batch 280/414, Loss: 4.8856
Epoch 36/100, Batch 290/414, Loss: 4.8781
Epoch 36/100, Batch 300/414, Loss: 4.9755
Epoch 36/100, Batch 310/414, Loss: 5.0722
Epoch 36/100, Batch 320/414, Loss: 4.9797
Epoch 36/100, Batch 330/414, Loss: 4.7114
Epoch 36/100, Batch 340/414, Loss: 4.8102
Epoch 36/100, Batch 350/414, Loss: 5.0514
Epoch 36/100, Batch 360/414, Loss: 4.5279
Epoch 36/100, Batch 370/414, Loss: 4.7825
Epoch 36/100, Batch 380/414, Loss: 4.8899
Epoch 36/100, Batch 390/414, Loss: 4.7556
Epoch 36/100, Batch 400/414, Loss: 4.6696
Epoch 36/100, Batch 410/414, Loss: 5.0069
New best model with validation loss: 5.3393, perplexity: 208.37
Epoch 36/100, Loss: 4.8724, Perplexity: 130.63, Val Loss: 5.3393, Val Perplexity: 208.37, Time: 261.04s
Epoch 37/100, Batch 10/414, Loss: 4.9998
Epoch 37/100, Batch 20/414, Loss: 4.7334
Epoch 37/100, Batch 30/414, Loss: 4.5892
Epoch 37/100, Batch 40/414, Loss: 5.1293
Epoch 37/100, Batch 50/414, Loss: 4.9393
Epoch 37/100, Batch 60/414, Loss: 4.7493
Epoch 37/100, Batch 70/414, Loss: 4.4624
Epoch 37/100, Batch 80/414, Loss: 4.6030
Epoch 37/100, Batch 90/414, Loss: 4.5168
Epoch 37/100, Batch 100/414, Loss: 4.9623
Epoch 37/100, Batch 110/414, Loss: 4.9915
Epoch 37/100, Batch 120/414, Loss: 4.5770
Epoch 37/100, Batch 130/414, Loss: 4.8659
Epoch 37/100, Batch 140/414, Loss: 4.8494
Epoch 37/100, Batch 150/414, Loss: 5.0443
Epoch 37/100, Batch 160/414, Loss: 4.8814
