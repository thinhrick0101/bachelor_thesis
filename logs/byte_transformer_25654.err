+ module load cuda11.3/toolkit
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_sh_dbg=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output
Shell debugging restarted
+ unset __lmod_sh_dbg
+ return 0
+ source /var/scratch/tng204/anaconda3/etc/profile.d/conda.sh
++ export CONDA_EXE=/var/scratch/tng204/anaconda3/bin/conda
++ CONDA_EXE=/var/scratch/tng204/anaconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/var/scratch/tng204/anaconda3/bin/python
++ CONDA_PYTHON_EXE=/var/scratch/tng204/anaconda3/bin/python
++ '[' -z x ']'
+ conda activate mltrain
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate mltrain
+ '[' -n '' ']'
+ local ask_conda
++ PS1=
++ __conda_exe shell.posix activate mltrain
++ '[' -n '' ']'
++ /var/scratch/tng204/anaconda3/bin/conda shell.posix activate mltrain
+ ask_conda='unset _CE_M
unset _CE_CONDA
PS1='\''(mltrain) '\''
export PATH='\''/cm/local/apps/cuda-driver/libs/current/bin:/cm/shared/apps/cuda11.3/toolkit/11.3.1/bin:/var/scratch/tng204/anaconda3/envs/mltrain/bin:/var/scratch/tng204/anaconda3/condabin:/home/tng204/.local/bin:/home/tng204/bin:/opt/ohpc/pub/mpi/libfabric/1.19.0/bin:/opt/ohpc/pub/mpi/ucx-ohpc/1.15.0/bin:/opt/ohpc/pub/libs/hwloc/bin:/opt/ohpc/pub/mpi/openmpi4-gnu12/4.1.6/bin:/opt/ohpc/pub/compiler/gcc/12.4.0/bin:/opt/ohpc/pub/utils/autotools/bin:/opt/ohpc/pub/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/cm/shared/package/reserve.slurm/bin'\''
export CONDA_SHLVL='\''2'\''
export CONDA_PROMPT_MODIFIER='\''(mltrain) '\''
export CONDA_EXE='\''/var/scratch/tng204/anaconda3/bin/conda'\''
export CONDA_PYTHON_EXE='\''/var/scratch/tng204/anaconda3/bin/python'\'''
+ eval 'unset _CE_M
unset _CE_CONDA
PS1='\''(mltrain) '\''
export PATH='\''/cm/local/apps/cuda-driver/libs/current/bin:/cm/shared/apps/cuda11.3/toolkit/11.3.1/bin:/var/scratch/tng204/anaconda3/envs/mltrain/bin:/var/scratch/tng204/anaconda3/condabin:/home/tng204/.local/bin:/home/tng204/bin:/opt/ohpc/pub/mpi/libfabric/1.19.0/bin:/opt/ohpc/pub/mpi/ucx-ohpc/1.15.0/bin:/opt/ohpc/pub/libs/hwloc/bin:/opt/ohpc/pub/mpi/openmpi4-gnu12/4.1.6/bin:/opt/ohpc/pub/compiler/gcc/12.4.0/bin:/opt/ohpc/pub/utils/autotools/bin:/opt/ohpc/pub/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/cm/shared/package/reserve.slurm/bin'\''
export CONDA_SHLVL='\''2'\''
export CONDA_PROMPT_MODIFIER='\''(mltrain) '\''
export CONDA_EXE='\''/var/scratch/tng204/anaconda3/bin/conda'\''
export CONDA_PYTHON_EXE='\''/var/scratch/tng204/anaconda3/bin/python'\'''
++ unset _CE_M
++ unset _CE_CONDA
++ PS1='(mltrain) '
++ export PATH=/cm/local/apps/cuda-driver/libs/current/bin:/cm/shared/apps/cuda11.3/toolkit/11.3.1/bin:/var/scratch/tng204/anaconda3/envs/mltrain/bin:/var/scratch/tng204/anaconda3/condabin:/home/tng204/.local/bin:/home/tng204/bin:/opt/ohpc/pub/mpi/libfabric/1.19.0/bin:/opt/ohpc/pub/mpi/ucx-ohpc/1.15.0/bin:/opt/ohpc/pub/libs/hwloc/bin:/opt/ohpc/pub/mpi/openmpi4-gnu12/4.1.6/bin:/opt/ohpc/pub/compiler/gcc/12.4.0/bin:/opt/ohpc/pub/utils/autotools/bin:/opt/ohpc/pub/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/cm/shared/package/reserve.slurm/bin
++ PATH=/cm/local/apps/cuda-driver/libs/current/bin:/cm/shared/apps/cuda11.3/toolkit/11.3.1/bin:/var/scratch/tng204/anaconda3/envs/mltrain/bin:/var/scratch/tng204/anaconda3/condabin:/home/tng204/.local/bin:/home/tng204/bin:/opt/ohpc/pub/mpi/libfabric/1.19.0/bin:/opt/ohpc/pub/mpi/ucx-ohpc/1.15.0/bin:/opt/ohpc/pub/libs/hwloc/bin:/opt/ohpc/pub/mpi/openmpi4-gnu12/4.1.6/bin:/opt/ohpc/pub/compiler/gcc/12.4.0/bin:/opt/ohpc/pub/utils/autotools/bin:/opt/ohpc/pub/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/cm/shared/package/reserve.slurm/bin
++ export CONDA_SHLVL=2
++ CONDA_SHLVL=2
++ export 'CONDA_PROMPT_MODIFIER=(mltrain) '
++ CONDA_PROMPT_MODIFIER='(mltrain) '
++ export CONDA_EXE=/var/scratch/tng204/anaconda3/bin/conda
++ CONDA_EXE=/var/scratch/tng204/anaconda3/bin/conda
++ export CONDA_PYTHON_EXE=/var/scratch/tng204/anaconda3/bin/python
++ CONDA_PYTHON_EXE=/var/scratch/tng204/anaconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ cd /var/scratch/tng204/thesis/bachelor_thesis
+ python -c 'import torch; torch.cuda.empty_cache()'
++ scontrol show hostnames 'node[002-007,024-026,046-052]'
++ head -n 1
+ export MASTER_ADDR=node002
+ MASTER_ADDR=node002
+ export MASTER_PORT=29500
+ MASTER_PORT=29500
+ export WORLD_SIZE=16
+ WORLD_SIZE=16
+ export TORCH_DISTRIBUTED_TIMEOUT=1800
+ TORCH_DISTRIBUTED_TIMEOUT=1800
+ echo '=== Distributed Training Configuration ==='
+ echo 'Master node: node002'
+ echo 'Master port: 29500'
+ echo 'World size: 16'
+ echo 'Job nodes: node[002-007,024-026,046-052]'
+ echo ========================================
+ mkdir -p logs
+ srun --kill-on-bad-exit=1 torchrun --nnodes=16 --nproc_per_node=1 --rdzv_id=25654 --rdzv_backend=c10d --rdzv_endpoint=node002:29500 --max_restarts=3 '--metrics_cfg={"time_to_live": "30m"}' stable_char_transformer.py
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 836449) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 722773) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 704148) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 695397) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 671650) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 803386) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 813967) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 701174) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 781948) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 684346) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 702647) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 3577757) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 684140) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 715578) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 1005924) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 699874) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 836451) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 671652) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 702649) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 722777) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 813969) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 684348) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 803388) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 704151) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 699876) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 695399) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 1005926) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 701176) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 3577759) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 781950) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 684142) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 715580) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 699878) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 836454) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 671654) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 813971) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 1005928) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 715582) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 781952) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 3577761) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 722779) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 695401) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 684350) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 684144) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 701178) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 702651) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 803390) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 704153) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
unknown option --metrics_cfg={"time_to_live": "30m"}
usage: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 684146) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 836456) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 671656) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 701180) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 702653) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 803392) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 695403) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 715584) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 684353) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 704155) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 781954) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 722781) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 699880) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 1005930) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 3577763) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 813973) of binary: /var/scratch/tng204/anaconda3/envs/mltrain/bin/python3.10
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    sys.exit(main())
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    return f(*args, **kwargs)
    return f(*args, **kwargs)
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    sys.exit(main())
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    sys.exit(main())
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    return f(*args, **kwargs)
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    run(args)
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    raise ChildFailedError(
    raise ChildFailedError(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node006.localdomain
  rank      : 4 (local_rank: 0)
  exitcode  : 2 (pid: 715584)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node051.localdomain
  rank      : 14 (local_rank: 0)
  exitcode  : 2 (pid: 701180)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    sys.exit(main())
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    sys.exit(main())
Traceback (most recent call last):
  File "/var/scratch/tng204/anaconda3/envs/mltrain/bin/torchrun", line 8, in <module>
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    raise ChildFailedError(
    return launch_agent(self._config, self._entrypoint, list(args))
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node004.localdomain
  rank      : 2 (local_rank: 0)
  exitcode  : 2 (pid: 781954)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    return f(*args, **kwargs)
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    raise ChildFailedError(
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node005.localdomain
  rank      : 3 (local_rank: 0)
  exitcode  : 2 (pid: 813973)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    sys.exit(main())
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 345, in wrapper
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node025.localdomain
  rank      : 7 (local_rank: 0)
  exitcode  : 2 (pid: 1005930)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node024.localdomain
  rank      : 6 (local_rank: 0)
  exitcode  : 2 (pid: 3577763)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
============================================================
    return f(*args, **kwargs)
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    raise ChildFailedError(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node026.localdomain
  rank      : 8 (local_rank: 0)
  exitcode  : 2 (pid: 699880)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    run(args)
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return f(*args, **kwargs)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 761, in main
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    raise ChildFailedError(
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node003.localdomain
  rank      : 1 (local_rank: 0)
  exitcode  : 2 (pid: 803392)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node052.localdomain
  rank      : 15 (local_rank: 0)
  exitcode  : 2 (pid: 695403)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    run(args)
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/run.py", line 752, in run
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node049.localdomain
  rank      : 12 (local_rank: 0)
  exitcode  : 2 (pid: 671656)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node007.localdomain
  rank      : 5 (local_rank: 0)
  exitcode  : 2 (pid: 684146)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node050.localdomain
  rank      : 13 (local_rank: 0)
  exitcode  : 2 (pid: 702653)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    elastic_launch(
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    raise ChildFailedError(
    raise ChildFailedError(
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node002.localdomain
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 836456)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node046.localdomain
  rank      : 9 (local_rank: 0)
  exitcode  : 2 (pid: 722781)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node047.localdomain
  rank      : 10 (local_rank: 0)
  exitcode  : 2 (pid: 704155)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/var/scratch/tng204/anaconda3/envs/mltrain/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
stable_char_transformer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-20_09:13:21
  host      : node048.localdomain
  rank      : 11 (local_rank: 0)
  exitcode  : 2 (pid: 684353)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: node052: task 15: Exited with exit code 1
srun: Terminating StepId=25654.0
srun: error: node046: task 9: Exited with exit code 1
slurmstepd-node002: error: *** STEP 25654.0 ON node002 CANCELLED AT 2025-05-20T09:13:21 ***
srun: error: node050: task 13: Exited with exit code 1
srun: error: node049: task 12: Exited with exit code 1
srun: error: node026: task 8: Terminated
srun: error: node051: task 14: Terminated
srun: error: node007: task 5: Exited with exit code 1
srun: error: node005: task 3: Terminated
srun: error: node002: task 0: Terminated
srun: error: node048: task 11: Terminated
srun: error: node025: task 7: Terminated
srun: error: node006: task 4: Terminated
srun: error: node024: task 6: Terminated
srun: error: node047: task 10: Terminated
srun: error: node003: task 1: Terminated
srun: error: node004: task 2: Terminated
srun: Force Terminated StepId=25654.0
