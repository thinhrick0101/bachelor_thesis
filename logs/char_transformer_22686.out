Loading data...
Loading data from data/enwik8
Data loaded: 99621832 characters
Limiting data to first 15000000 characters for training
Vocabulary size: 2451 characters
Creating batches...
Created 549 training batches and 61 validation batches
Model Parameters: 192,021,684 trainable out of 192,021,684 total

=== Training Enhanced Character Transformer Model ===
Training on device: cuda
Using mixed precision training (FP16)
Using gradient accumulation with 8 steps
Effective batch size: 256
Epoch 1/100, Batch 10/549, Loss: 7.8555
Epoch 1/100, Batch 20/549, Loss: 7.8476
Epoch 1/100, Batch 30/549, Loss: 7.8359
Epoch 1/100, Batch 40/549, Loss: 7.7863
Epoch 1/100, Batch 50/549, Loss: 7.6479
Epoch 1/100, Batch 60/549, Loss: 7.6041
Epoch 1/100, Batch 70/549, Loss: 7.5548
Epoch 1/100, Batch 80/549, Loss: 7.4267
Epoch 1/100, Batch 90/549, Loss: 7.2129
Epoch 1/100, Batch 100/549, Loss: 7.1492
Epoch 1/100, Batch 110/549, Loss: 6.9620
Epoch 1/100, Batch 120/549, Loss: 6.8840
Epoch 1/100, Batch 130/549, Loss: 6.5973
Epoch 1/100, Batch 140/549, Loss: 6.5693
Epoch 1/100, Batch 150/549, Loss: 6.3235
Epoch 1/100, Batch 160/549, Loss: 6.3130
Epoch 1/100, Batch 170/549, Loss: 6.1179
Epoch 1/100, Batch 180/549, Loss: 5.9600
Epoch 1/100, Batch 190/549, Loss: 5.8521
Epoch 1/100, Batch 200/549, Loss: 5.7927
Epoch 1/100, Batch 210/549, Loss: 5.6393
Epoch 1/100, Batch 220/549, Loss: 5.6278
Epoch 1/100, Batch 230/549, Loss: 5.5662
Epoch 1/100, Batch 240/549, Loss: 5.6278
Epoch 1/100, Batch 250/549, Loss: 5.4876
Epoch 1/100, Batch 260/549, Loss: 5.4500
Epoch 1/100, Batch 270/549, Loss: 5.3485
Epoch 1/100, Batch 280/549, Loss: 5.3067
Epoch 1/100, Batch 290/549, Loss: 5.3475
Epoch 1/100, Batch 300/549, Loss: 5.2526
Epoch 1/100, Batch 310/549, Loss: 5.2059
Epoch 1/100, Batch 320/549, Loss: 5.1730
Epoch 1/100, Batch 330/549, Loss: 5.1864
Epoch 1/100, Batch 340/549, Loss: 5.1595
Epoch 1/100, Batch 350/549, Loss: 4.9939
Epoch 1/100, Batch 360/549, Loss: 4.9716
Epoch 1/100, Batch 370/549, Loss: 5.1259
Epoch 1/100, Batch 380/549, Loss: 4.9861
Epoch 1/100, Batch 390/549, Loss: 5.0301
Epoch 1/100, Batch 400/549, Loss: 4.9121
Epoch 1/100, Batch 410/549, Loss: 4.9195
Epoch 1/100, Batch 420/549, Loss: 4.8089
Epoch 1/100, Batch 430/549, Loss: 4.7123
Epoch 1/100, Batch 440/549, Loss: 4.7892
Epoch 1/100, Batch 450/549, Loss: 4.7680
Epoch 1/100, Batch 460/549, Loss: 4.7744
Epoch 1/100, Batch 470/549, Loss: 4.8502
Epoch 1/100, Batch 480/549, Loss: 4.7292
Epoch 1/100, Batch 490/549, Loss: 4.5512
Epoch 1/100, Batch 500/549, Loss: 4.6218
Epoch 1/100, Batch 510/549, Loss: 4.5368
Epoch 1/100, Batch 520/549, Loss: 4.6665
Epoch 1/100, Batch 530/549, Loss: 4.5649
Epoch 1/100, Batch 540/549, Loss: 4.5670
New best model with validation loss: 4.3248, perplexity: 75.55
Epoch 1/100, Loss: 5.7542, Perplexity: 315.53, Val Loss: 4.3248, Val Perplexity: 75.55, Time: 1089.37s
Epoch 2/100, Batch 10/549, Loss: 4.4388
Epoch 2/100, Batch 20/549, Loss: 4.4369
Epoch 2/100, Batch 30/549, Loss: 4.3461
Epoch 2/100, Batch 40/549, Loss: 4.3217
Epoch 2/100, Batch 50/549, Loss: 4.3364
Epoch 2/100, Batch 60/549, Loss: 4.3435
Epoch 2/100, Batch 70/549, Loss: 4.2037
Epoch 2/100, Batch 80/549, Loss: 4.1642
Epoch 2/100, Batch 90/549, Loss: 4.1602
Epoch 2/100, Batch 100/549, Loss: 4.0905
Epoch 2/100, Batch 110/549, Loss: 4.0107
Epoch 2/100, Batch 120/549, Loss: 3.9809
Epoch 2/100, Batch 130/549, Loss: 3.9546
Epoch 2/100, Batch 140/549, Loss: 4.0210
Epoch 2/100, Batch 150/549, Loss: 3.9524
Epoch 2/100, Batch 160/549, Loss: 4.0165
Epoch 2/100, Batch 170/549, Loss: 3.9629
Epoch 2/100, Batch 180/549, Loss: 3.9133
Epoch 2/100, Batch 190/549, Loss: 3.9188
Epoch 2/100, Batch 200/549, Loss: 3.9096
Epoch 2/100, Batch 210/549, Loss: 3.8823
Epoch 2/100, Batch 220/549, Loss: 3.8696
Epoch 2/100, Batch 230/549, Loss: 3.8562
Epoch 2/100, Batch 240/549, Loss: 3.9394
Epoch 2/100, Batch 250/549, Loss: 3.8644
Epoch 2/100, Batch 260/549, Loss: 3.8648
Epoch 2/100, Batch 270/549, Loss: 3.7862
Epoch 2/100, Batch 280/549, Loss: 3.7677
Epoch 2/100, Batch 290/549, Loss: 3.8131
Epoch 2/100, Batch 300/549, Loss: 3.8328
Epoch 2/100, Batch 310/549, Loss: 3.7566
Epoch 2/100, Batch 320/549, Loss: 3.7336
Epoch 2/100, Batch 330/549, Loss: 3.7945
Epoch 2/100, Batch 340/549, Loss: 3.7618
Epoch 2/100, Batch 350/549, Loss: 3.6853
Epoch 2/100, Batch 360/549, Loss: 3.6938
Epoch 2/100, Batch 370/549, Loss: 3.8033
Epoch 2/100, Batch 380/549, Loss: 3.7236
Epoch 2/100, Batch 390/549, Loss: 3.7647
Epoch 2/100, Batch 400/549, Loss: 3.6783
Epoch 2/100, Batch 410/549, Loss: 3.7072
Epoch 2/100, Batch 420/549, Loss: 3.6409
Epoch 2/100, Batch 430/549, Loss: 3.6260
Epoch 2/100, Batch 440/549, Loss: 3.6689
Epoch 2/100, Batch 450/549, Loss: 3.7128
Epoch 2/100, Batch 460/549, Loss: 3.6960
Epoch 2/100, Batch 470/549, Loss: 3.7484
Epoch 2/100, Batch 480/549, Loss: 3.6852
Epoch 2/100, Batch 490/549, Loss: 3.6133
Epoch 2/100, Batch 500/549, Loss: 3.6453
Epoch 2/100, Batch 510/549, Loss: 3.6377
Epoch 2/100, Batch 520/549, Loss: 3.7309
Epoch 2/100, Batch 530/549, Loss: 3.6837
Epoch 2/100, Batch 540/549, Loss: 3.7091
New best model with validation loss: 3.5452, perplexity: 34.65
Epoch 2/100, Loss: 3.8853, Perplexity: 48.68, Val Loss: 3.5452, Val Perplexity: 34.65, Time: 1086.86s
Epoch 3/100, Batch 10/549, Loss: 3.6878
Epoch 3/100, Batch 20/549, Loss: 3.6941
Epoch 3/100, Batch 30/549, Loss: 3.6505
Epoch 3/100, Batch 40/549, Loss: 3.6473
Epoch 3/100, Batch 50/549, Loss: 3.6617
Epoch 3/100, Batch 60/549, Loss: 3.6754
Epoch 3/100, Batch 70/549, Loss: 3.6577
Epoch 3/100, Batch 80/549, Loss: 3.6117
Epoch 3/100, Batch 90/549, Loss: 3.6408
Epoch 3/100, Batch 100/549, Loss: 3.6496
Epoch 3/100, Batch 110/549, Loss: 3.5963
Epoch 3/100, Batch 120/549, Loss: 3.5866
Epoch 3/100, Batch 130/549, Loss: 3.5777
Epoch 3/100, Batch 140/549, Loss: 3.6479
Epoch 3/100, Batch 150/549, Loss: 3.6193
Epoch 3/100, Batch 160/549, Loss: 3.6469
Epoch 3/100, Batch 170/549, Loss: 3.6438
Epoch 3/100, Batch 180/549, Loss: 3.6439
Epoch 3/100, Batch 190/549, Loss: 3.5909
Epoch 3/100, Batch 200/549, Loss: 3.5968
Epoch 3/100, Batch 210/549, Loss: 3.5611
Epoch 3/100, Batch 220/549, Loss: 3.5887
Epoch 3/100, Batch 230/549, Loss: 3.6163
Epoch 3/100, Batch 240/549, Loss: 3.6320
Epoch 3/100, Batch 250/549, Loss: 3.5860
Epoch 3/100, Batch 260/549, Loss: 3.6121
Epoch 3/100, Batch 270/549, Loss: 3.5562
Epoch 3/100, Batch 280/549, Loss: 3.5719
Epoch 3/100, Batch 290/549, Loss: 3.6121
Epoch 3/100, Batch 300/549, Loss: 3.6297
Epoch 3/100, Batch 310/549, Loss: 3.5655
Epoch 3/100, Batch 320/549, Loss: 3.5617
Epoch 3/100, Batch 330/549, Loss: 3.5836
Epoch 3/100, Batch 340/549, Loss: 3.5891
Epoch 3/100, Batch 350/549, Loss: 3.5543
Epoch 3/100, Batch 360/549, Loss: 3.5677
Epoch 3/100, Batch 370/549, Loss: 3.6192
Epoch 3/100, Batch 380/549, Loss: 3.5929
Epoch 3/100, Batch 390/549, Loss: 3.6162
Epoch 3/100, Batch 400/549, Loss: 3.5666
Epoch 3/100, Batch 410/549, Loss: 3.6009
Epoch 3/100, Batch 420/549, Loss: 3.5179
Epoch 3/100, Batch 430/549, Loss: 3.5455
Epoch 3/100, Batch 440/549, Loss: 3.5396
Epoch 3/100, Batch 450/549, Loss: 3.5849
Epoch 3/100, Batch 460/549, Loss: 3.5628
Epoch 3/100, Batch 470/549, Loss: 3.6228
Epoch 3/100, Batch 480/549, Loss: 3.5602
Epoch 3/100, Batch 490/549, Loss: 3.5274
Epoch 3/100, Batch 500/549, Loss: 3.5497
Epoch 3/100, Batch 510/549, Loss: 3.5490
Epoch 3/100, Batch 520/549, Loss: 3.5925
Epoch 3/100, Batch 530/549, Loss: 3.5691
Epoch 3/100, Batch 540/549, Loss: 3.5972
New best model with validation loss: 3.4462, perplexity: 31.38
Epoch 3/100, Loss: 3.6009, Perplexity: 36.63, Val Loss: 3.4462, Val Perplexity: 31.38, Time: 1091.35s
Epoch 4/100, Batch 10/549, Loss: 3.5822
Epoch 4/100, Batch 20/549, Loss: 3.6025
Epoch 4/100, Batch 30/549, Loss: 3.5741
Epoch 4/100, Batch 40/549, Loss: 3.5543
Epoch 4/100, Batch 50/549, Loss: 3.5561
Epoch 4/100, Batch 60/549, Loss: 3.5615
Epoch 4/100, Batch 70/549, Loss: 3.5596
Epoch 4/100, Batch 80/549, Loss: 3.5382
Epoch 4/100, Batch 90/549, Loss: 3.5450
Epoch 4/100, Batch 100/549, Loss: 3.5753
Epoch 4/100, Batch 110/549, Loss: 3.5208
Epoch 4/100, Batch 120/549, Loss: 3.5100
Epoch 4/100, Batch 130/549, Loss: 3.4994
Epoch 4/100, Batch 140/549, Loss: 3.5633
Epoch 4/100, Batch 150/549, Loss: 3.5523
Epoch 4/100, Batch 160/549, Loss: 3.5560
Epoch 4/100, Batch 170/549, Loss: 3.5543
Epoch 4/100, Batch 180/549, Loss: 3.5808
Epoch 4/100, Batch 190/549, Loss: 3.5097
Epoch 4/100, Batch 200/549, Loss: 3.5065
Epoch 4/100, Batch 210/549, Loss: 3.4774
Epoch 4/100, Batch 220/549, Loss: 3.5014
Epoch 4/100, Batch 230/549, Loss: 3.5471
Epoch 4/100, Batch 240/549, Loss: 3.5293
Epoch 4/100, Batch 250/549, Loss: 3.4973
Epoch 4/100, Batch 260/549, Loss: 3.5136
Epoch 4/100, Batch 270/549, Loss: 3.4821
Epoch 4/100, Batch 280/549, Loss: 3.4947
Epoch 4/100, Batch 290/549, Loss: 3.5382
Epoch 4/100, Batch 300/549, Loss: 3.5527
Epoch 4/100, Batch 310/549, Loss: 3.4976
Epoch 4/100, Batch 320/549, Loss: 3.4832
Epoch 4/100, Batch 330/549, Loss: 3.5041
Epoch 4/100, Batch 340/549, Loss: 3.5103
Epoch 4/100, Batch 350/549, Loss: 3.4924
Epoch 4/100, Batch 360/549, Loss: 3.5096
Epoch 4/100, Batch 370/549, Loss: 3.5359
Epoch 4/100, Batch 380/549, Loss: 3.5356
Epoch 4/100, Batch 390/549, Loss: 3.5284
Epoch 4/100, Batch 400/549, Loss: 3.5099
Epoch 4/100, Batch 410/549, Loss: 3.5239
Epoch 4/100, Batch 420/549, Loss: 3.4540
Epoch 4/100, Batch 430/549, Loss: 3.4830
Epoch 4/100, Batch 440/549, Loss: 3.4664
Epoch 4/100, Batch 450/549, Loss: 3.5109
Epoch 4/100, Batch 460/549, Loss: 3.4882
Epoch 4/100, Batch 470/549, Loss: 3.5361
Epoch 4/100, Batch 480/549, Loss: 3.4908
Epoch 4/100, Batch 490/549, Loss: 3.4533
Epoch 4/100, Batch 500/549, Loss: 3.4760
Epoch 4/100, Batch 510/549, Loss: 3.4927
Epoch 4/100, Batch 520/549, Loss: 3.5102
Epoch 4/100, Batch 530/549, Loss: 3.5009
Epoch 4/100, Batch 540/549, Loss: 3.5265
New best model with validation loss: 3.3667, perplexity: 28.98
Epoch 4/100, Loss: 3.5223, Perplexity: 33.86, Val Loss: 3.3667, Val Perplexity: 28.98, Time: 1088.41s
Epoch 5/100, Batch 10/549, Loss: 3.5079
Epoch 5/100, Batch 20/549, Loss: 3.5343
Epoch 5/100, Batch 30/549, Loss: 3.5007
Epoch 5/100, Batch 40/549, Loss: 3.4729
Epoch 5/100, Batch 50/549, Loss: 3.4607
Epoch 5/100, Batch 60/549, Loss: 3.4693
Epoch 5/100, Batch 70/549, Loss: 3.4784
Epoch 5/100, Batch 80/549, Loss: 3.4634
Epoch 5/100, Batch 90/549, Loss: 3.4629
Epoch 5/100, Batch 100/549, Loss: 3.5134
Epoch 5/100, Batch 110/549, Loss: 3.4794
Epoch 5/100, Batch 120/549, Loss: 3.4521
Epoch 5/100, Batch 130/549, Loss: 3.4401
Epoch 5/100, Batch 140/549, Loss: 3.4858
Epoch 5/100, Batch 150/549, Loss: 3.4871
Epoch 5/100, Batch 160/549, Loss: 3.4708
Epoch 5/100, Batch 170/549, Loss: 3.4772
Epoch 5/100, Batch 180/549, Loss: 3.5060
Epoch 5/100, Batch 190/549, Loss: 3.4146
Epoch 5/100, Batch 200/549, Loss: 3.4419
Epoch 5/100, Batch 210/549, Loss: 3.4071
Epoch 5/100, Batch 220/549, Loss: 3.4304
Epoch 5/100, Batch 230/549, Loss: 3.4942
Epoch 5/100, Batch 240/549, Loss: 3.4500
Epoch 5/100, Batch 250/549, Loss: 3.4182
Epoch 5/100, Batch 260/549, Loss: 3.4319
Epoch 5/100, Batch 270/549, Loss: 3.4209
Epoch 5/100, Batch 280/549, Loss: 3.4271
Epoch 5/100, Batch 290/549, Loss: 3.4603
Epoch 5/100, Batch 300/549, Loss: 3.4891
Epoch 5/100, Batch 310/549, Loss: 3.4457
Epoch 5/100, Batch 320/549, Loss: 3.4184
Epoch 5/100, Batch 330/549, Loss: 3.4216
Epoch 5/100, Batch 340/549, Loss: 3.4576
Epoch 5/100, Batch 350/549, Loss: 3.4303
Epoch 5/100, Batch 360/549, Loss: 3.4574
Epoch 5/100, Batch 370/549, Loss: 3.4608
Epoch 5/100, Batch 380/549, Loss: 3.4712
Epoch 5/100, Batch 390/549, Loss: 3.4587
Epoch 5/100, Batch 400/549, Loss: 3.4513
Epoch 5/100, Batch 410/549, Loss: 3.4734
Epoch 5/100, Batch 420/549, Loss: 3.4243
Epoch 5/100, Batch 430/549, Loss: 3.4291
Epoch 5/100, Batch 440/549, Loss: 3.4084
Epoch 5/100, Batch 450/549, Loss: 3.4536
Epoch 5/100, Batch 460/549, Loss: 3.4371
Epoch 5/100, Batch 470/549, Loss: 3.4593
Epoch 5/100, Batch 480/549, Loss: 3.4188
Epoch 5/100, Batch 490/549, Loss: 3.4077
Epoch 5/100, Batch 500/549, Loss: 3.4130
Epoch 5/100, Batch 510/549, Loss: 3.4460
Epoch 5/100, Batch 520/549, Loss: 3.4436
Epoch 5/100, Batch 530/549, Loss: 3.4299
Epoch 5/100, Batch 540/549, Loss: 3.4532
New best model with validation loss: 3.2884, perplexity: 26.80
Epoch 5/100, Loss: 3.4546, Perplexity: 31.65, Val Loss: 3.2884, Val Perplexity: 26.80, Time: 1086.83s
Epoch 6/100, Batch 10/549, Loss: 3.4492
Epoch 6/100, Batch 20/549, Loss: 3.4756
Epoch 6/100, Batch 30/549, Loss: 3.4426
Epoch 6/100, Batch 40/549, Loss: 3.4150
Epoch 6/100, Batch 50/549, Loss: 3.3980
Epoch 6/100, Batch 60/549, Loss: 3.3781
Epoch 6/100, Batch 70/549, Loss: 3.4183
Epoch 6/100, Batch 80/549, Loss: 3.3942
Epoch 6/100, Batch 90/549, Loss: 3.3990
Epoch 6/100, Batch 100/549, Loss: 3.4657
Epoch 6/100, Batch 110/549, Loss: 3.4074
Epoch 6/100, Batch 120/549, Loss: 3.4027
Epoch 6/100, Batch 130/549, Loss: 3.3728
Epoch 6/100, Batch 140/549, Loss: 3.4040
Epoch 6/100, Batch 150/549, Loss: 3.4370
Epoch 6/100, Batch 160/549, Loss: 3.4018
Epoch 6/100, Batch 170/549, Loss: 3.4484
Epoch 6/100, Batch 180/549, Loss: 3.4530
Epoch 6/100, Batch 190/549, Loss: 3.3594
Epoch 6/100, Batch 200/549, Loss: 3.3750
Epoch 6/100, Batch 210/549, Loss: 3.3264
Epoch 6/100, Batch 220/549, Loss: 3.3524
Epoch 6/100, Batch 230/549, Loss: 3.4184
Epoch 6/100, Batch 240/549, Loss: 3.3812
Epoch 6/100, Batch 250/549, Loss: 3.3324
Epoch 6/100, Batch 260/549, Loss: 3.3601
Epoch 6/100, Batch 270/549, Loss: 3.3475
Epoch 6/100, Batch 280/549, Loss: 3.3601
Epoch 6/100, Batch 290/549, Loss: 3.3971
Epoch 6/100, Batch 300/549, Loss: 3.4205
Epoch 6/100, Batch 310/549, Loss: 3.3785
Epoch 6/100, Batch 320/549, Loss: 3.3580
Epoch 6/100, Batch 330/549, Loss: 3.3418
Epoch 6/100, Batch 340/549, Loss: 3.3791
Epoch 6/100, Batch 350/549, Loss: 3.3666
Epoch 6/100, Batch 360/549, Loss: 3.3996
Epoch 6/100, Batch 370/549, Loss: 3.3871
Epoch 6/100, Batch 380/549, Loss: 3.4117
Epoch 6/100, Batch 390/549, Loss: 3.3855
Epoch 6/100, Batch 400/549, Loss: 3.3891
Epoch 6/100, Batch 410/549, Loss: 3.4039
Epoch 6/100, Batch 420/549, Loss: 3.3394
Epoch 6/100, Batch 430/549, Loss: 3.3776
Epoch 6/100, Batch 440/549, Loss: 3.3445
Epoch 6/100, Batch 450/549, Loss: 3.3856
Epoch 6/100, Batch 460/549, Loss: 3.3618
Epoch 6/100, Batch 470/549, Loss: 3.3845
Epoch 6/100, Batch 480/549, Loss: 3.3397
Epoch 6/100, Batch 490/549, Loss: 3.3448
Epoch 6/100, Batch 500/549, Loss: 3.3564
Epoch 6/100, Batch 510/549, Loss: 3.3785
Epoch 6/100, Batch 520/549, Loss: 3.3615
Epoch 6/100, Batch 530/549, Loss: 3.3538
Epoch 6/100, Batch 540/549, Loss: 3.3885
New best model with validation loss: 3.1954, perplexity: 24.42
Epoch 6/100, Loss: 3.3905, Perplexity: 29.68, Val Loss: 3.1954, Val Perplexity: 24.42, Time: 1090.90s
Epoch 7/100, Batch 10/549, Loss: 3.3767
Epoch 7/100, Batch 20/549, Loss: 3.4023
Epoch 7/100, Batch 30/549, Loss: 3.3829
Epoch 7/100, Batch 40/549, Loss: 3.3494
Epoch 7/100, Batch 50/549, Loss: 3.3152
Epoch 7/100, Batch 60/549, Loss: 3.3106
Epoch 7/100, Batch 70/549, Loss: 3.3698
Epoch 7/100, Batch 80/549, Loss: 3.3288
Epoch 7/100, Batch 90/549, Loss: 3.3317
Epoch 7/100, Batch 100/549, Loss: 3.4033
Epoch 7/100, Batch 110/549, Loss: 3.3570
Epoch 7/100, Batch 120/549, Loss: 3.3384
Epoch 7/100, Batch 130/549, Loss: 3.3084
Epoch 7/100, Batch 140/549, Loss: 3.3271
Epoch 7/100, Batch 150/549, Loss: 3.3884
Epoch 7/100, Batch 160/549, Loss: 3.3279
Epoch 7/100, Batch 170/549, Loss: 3.3464
Epoch 7/100, Batch 180/549, Loss: 3.3839
Epoch 7/100, Batch 190/549, Loss: 3.2766
Epoch 7/100, Batch 200/549, Loss: 3.2889
Epoch 7/100, Batch 210/549, Loss: 3.2425
Epoch 7/100, Batch 220/549, Loss: 3.2759
Epoch 7/100, Batch 230/549, Loss: 3.3928
Epoch 7/100, Batch 240/549, Loss: 3.2674
Epoch 7/100, Batch 250/549, Loss: 3.2465
Epoch 7/100, Batch 260/549, Loss: 3.2823
Epoch 7/100, Batch 270/549, Loss: 3.2633
Epoch 7/100, Batch 280/549, Loss: 3.2873
Epoch 7/100, Batch 290/549, Loss: 3.3027
Epoch 7/100, Batch 300/549, Loss: 3.3505
Epoch 7/100, Batch 310/549, Loss: 3.3040
Epoch 7/100, Batch 320/549, Loss: 3.2750
Epoch 7/100, Batch 330/549, Loss: 3.2570
Epoch 7/100, Batch 340/549, Loss: 3.3047
Epoch 7/100, Batch 350/549, Loss: 3.2935
Epoch 7/100, Batch 360/549, Loss: 3.3315
Epoch 7/100, Batch 370/549, Loss: 3.2990
Epoch 7/100, Batch 380/549, Loss: 3.3494
Epoch 7/100, Batch 390/549, Loss: 3.3028
Epoch 7/100, Batch 400/549, Loss: 3.3191
Epoch 7/100, Batch 410/549, Loss: 3.3297
Epoch 7/100, Batch 420/549, Loss: 3.2627
Epoch 7/100, Batch 430/549, Loss: 3.3153
Epoch 7/100, Batch 440/549, Loss: 3.2675
Epoch 7/100, Batch 450/549, Loss: 3.3076
Epoch 7/100, Batch 460/549, Loss: 3.2948
Epoch 7/100, Batch 470/549, Loss: 3.3087
Epoch 7/100, Batch 480/549, Loss: 3.2713
Epoch 7/100, Batch 490/549, Loss: 3.2632
Epoch 7/100, Batch 500/549, Loss: 3.2877
Epoch 7/100, Batch 510/549, Loss: 3.3007
Epoch 7/100, Batch 520/549, Loss: 3.2708
Epoch 7/100, Batch 530/549, Loss: 3.2944
Epoch 7/100, Batch 540/549, Loss: 3.2933
New best model with validation loss: 3.0826, perplexity: 21.82
Epoch 7/100, Loss: 3.3165, Perplexity: 27.56, Val Loss: 3.0826, Val Perplexity: 21.82, Time: 1090.29s
Epoch 8/100, Batch 10/549, Loss: 3.3287
Epoch 8/100, Batch 20/549, Loss: 3.3375
Epoch 8/100, Batch 30/549, Loss: 3.3026
Epoch 8/100, Batch 40/549, Loss: 3.2624
Epoch 8/100, Batch 50/549, Loss: 3.2254
Epoch 8/100, Batch 60/549, Loss: 3.1971
Epoch 8/100, Batch 70/549, Loss: 3.2677
Epoch 8/100, Batch 80/549, Loss: 3.2755
Epoch 8/100, Batch 90/549, Loss: 3.2670
Epoch 8/100, Batch 100/549, Loss: 3.3193
Epoch 8/100, Batch 110/549, Loss: 3.2861
Epoch 8/100, Batch 120/549, Loss: 3.2746
Epoch 8/100, Batch 130/549, Loss: 3.2317
Epoch 8/100, Batch 140/549, Loss: 3.2331
Epoch 8/100, Batch 150/549, Loss: 3.3148
Epoch 8/100, Batch 160/549, Loss: 3.2451
Epoch 8/100, Batch 170/549, Loss: 3.2563
Epoch 8/100, Batch 180/549, Loss: 3.3081
Epoch 8/100, Batch 190/549, Loss: 3.1922
Epoch 8/100, Batch 200/549, Loss: 3.1976
Epoch 8/100, Batch 210/549, Loss: 3.1415
Epoch 8/100, Batch 220/549, Loss: 3.1761
Epoch 8/100, Batch 230/549, Loss: 3.2761
Epoch 8/100, Batch 240/549, Loss: 3.1948
Epoch 8/100, Batch 250/549, Loss: 3.1387
Epoch 8/100, Batch 260/549, Loss: 3.1693
Epoch 8/100, Batch 270/549, Loss: 3.1798
Epoch 8/100, Batch 280/549, Loss: 3.2015
Epoch 8/100, Batch 290/549, Loss: 3.2259
Epoch 8/100, Batch 300/549, Loss: 3.2653
Epoch 8/100, Batch 310/549, Loss: 3.2122
Epoch 8/100, Batch 320/549, Loss: 3.1812
Epoch 8/100, Batch 330/549, Loss: 3.1612
Epoch 8/100, Batch 340/549, Loss: 3.2176
Epoch 8/100, Batch 350/549, Loss: 3.2155
Epoch 8/100, Batch 360/549, Loss: 3.2483
Epoch 8/100, Batch 370/549, Loss: 3.2055
Epoch 8/100, Batch 380/549, Loss: 3.2870
Epoch 8/100, Batch 390/549, Loss: 3.2144
Epoch 8/100, Batch 400/549, Loss: 3.2472
Epoch 8/100, Batch 410/549, Loss: 3.2468
Epoch 8/100, Batch 420/549, Loss: 3.1595
Epoch 8/100, Batch 430/549, Loss: 3.2400
Epoch 8/100, Batch 440/549, Loss: 3.1825
Epoch 8/100, Batch 450/549, Loss: 3.2317
Epoch 8/100, Batch 460/549, Loss: 3.2108
Epoch 8/100, Batch 470/549, Loss: 3.2017
Epoch 8/100, Batch 480/549, Loss: 3.1707
Epoch 8/100, Batch 490/549, Loss: 3.1910
Epoch 8/100, Batch 500/549, Loss: 3.1902
Epoch 8/100, Batch 510/549, Loss: 3.2485
Epoch 8/100, Batch 520/549, Loss: 3.1867
Epoch 8/100, Batch 530/549, Loss: 3.2002
Epoch 8/100, Batch 540/549, Loss: 3.2141
New best model with validation loss: 2.9863, perplexity: 19.81
Epoch 8/100, Loss: 3.2324, Perplexity: 25.34, Val Loss: 2.9863, Val Perplexity: 19.81, Time: 1091.71s
Epoch 9/100, Batch 10/549, Loss: 3.2019
Epoch 9/100, Batch 20/549, Loss: 3.2534
Epoch 9/100, Batch 30/549, Loss: 3.2238
Epoch 9/100, Batch 40/549, Loss: 3.1687
Epoch 9/100, Batch 50/549, Loss: 3.1282
Epoch 9/100, Batch 60/549, Loss: 3.1233
Epoch 9/100, Batch 70/549, Loss: 3.1980
Epoch 9/100, Batch 80/549, Loss: 3.1476
Epoch 9/100, Batch 90/549, Loss: 3.1543
Epoch 9/100, Batch 100/549, Loss: 3.2478
Epoch 9/100, Batch 110/549, Loss: 3.1933
Epoch 9/100, Batch 120/549, Loss: 3.1888
Epoch 9/100, Batch 130/549, Loss: 3.1525
Epoch 9/100, Batch 140/549, Loss: 3.1521
Epoch 9/100, Batch 150/549, Loss: 3.2747
Epoch 9/100, Batch 160/549, Loss: 3.1656
Epoch 9/100, Batch 170/549, Loss: 3.1726
Epoch 9/100, Batch 180/549, Loss: 3.2178
Epoch 9/100, Batch 190/549, Loss: 3.0934
Epoch 9/100, Batch 200/549, Loss: 3.1188
Epoch 9/100, Batch 210/549, Loss: 3.0513
Epoch 9/100, Batch 220/549, Loss: 3.0927
Epoch 9/100, Batch 230/549, Loss: 3.1853
Epoch 9/100, Batch 240/549, Loss: 3.0866
Epoch 9/100, Batch 250/549, Loss: 3.0941
Epoch 9/100, Batch 260/549, Loss: 3.0795
Epoch 9/100, Batch 270/549, Loss: 3.1070
Epoch 9/100, Batch 280/549, Loss: 3.1159
Epoch 9/100, Batch 290/549, Loss: 3.1547
Epoch 9/100, Batch 300/549, Loss: 3.1876
Epoch 9/100, Batch 310/549, Loss: 3.1326
Epoch 9/100, Batch 320/549, Loss: 3.1025
Epoch 9/100, Batch 330/549, Loss: 3.0710
Epoch 9/100, Batch 340/549, Loss: 3.1277
Epoch 9/100, Batch 350/549, Loss: 3.1511
Epoch 9/100, Batch 360/549, Loss: 3.1867
Epoch 9/100, Batch 370/549, Loss: 3.1384
Epoch 9/100, Batch 380/549, Loss: 3.2025
Epoch 9/100, Batch 390/549, Loss: 3.1539
Epoch 9/100, Batch 400/549, Loss: 3.1612
Epoch 9/100, Batch 410/549, Loss: 3.1819
Epoch 9/100, Batch 420/549, Loss: 3.1029
Epoch 9/100, Batch 430/549, Loss: 3.1762
Epoch 9/100, Batch 440/549, Loss: 3.1221
Epoch 9/100, Batch 450/549, Loss: 3.1498
Epoch 9/100, Batch 460/549, Loss: 3.1363
Epoch 9/100, Batch 470/549, Loss: 3.1236
Epoch 9/100, Batch 480/549, Loss: 3.1130
Epoch 9/100, Batch 490/549, Loss: 3.1335
Epoch 9/100, Batch 500/549, Loss: 3.1085
Epoch 9/100, Batch 510/549, Loss: 3.1479
Epoch 9/100, Batch 520/549, Loss: 3.1017
Epoch 9/100, Batch 530/549, Loss: 3.1489
Epoch 9/100, Batch 540/549, Loss: 3.1334
New best model with validation loss: 2.9027, perplexity: 18.22
Epoch 9/100, Loss: 3.1520, Perplexity: 23.38, Val Loss: 2.9027, Val Perplexity: 18.22, Time: 1086.95s
Epoch 10/100, Batch 10/549, Loss: 3.1254
Epoch 10/100, Batch 20/549, Loss: 3.1758
Epoch 10/100, Batch 30/549, Loss: 3.1742
Epoch 10/100, Batch 40/549, Loss: 3.1098
Epoch 10/100, Batch 50/549, Loss: 3.0618
Epoch 10/100, Batch 60/549, Loss: 3.0314
Epoch 10/100, Batch 70/549, Loss: 3.1178
Epoch 10/100, Batch 80/549, Loss: 3.0775
Epoch 10/100, Batch 90/549, Loss: 3.0910
Epoch 10/100, Batch 100/549, Loss: 3.1581
Epoch 10/100, Batch 110/549, Loss: 3.1153
Epoch 10/100, Batch 120/549, Loss: 3.1097
Epoch 10/100, Batch 130/549, Loss: 3.0733
Epoch 10/100, Batch 140/549, Loss: 3.0672
Epoch 10/100, Batch 150/549, Loss: 3.1338
Epoch 10/100, Batch 160/549, Loss: 3.0871
Epoch 10/100, Batch 170/549, Loss: 3.0988
Epoch 10/100, Batch 180/549, Loss: 3.1399
Epoch 10/100, Batch 190/549, Loss: 3.0061
Epoch 10/100, Batch 200/549, Loss: 3.0409
Epoch 10/100, Batch 210/549, Loss: 2.9673
Epoch 10/100, Batch 220/549, Loss: 3.0090
Epoch 10/100, Batch 230/549, Loss: 3.0909
Epoch 10/100, Batch 240/549, Loss: 3.0005
Epoch 10/100, Batch 250/549, Loss: 2.9598
Epoch 10/100, Batch 260/549, Loss: 2.9927
Epoch 10/100, Batch 270/549, Loss: 3.0140
Epoch 10/100, Batch 280/549, Loss: 3.0448
Epoch 10/100, Batch 290/549, Loss: 3.0506
Epoch 10/100, Batch 300/549, Loss: 3.1297
Epoch 10/100, Batch 310/549, Loss: 3.0513
Epoch 10/100, Batch 320/549, Loss: 3.0171
Epoch 10/100, Batch 330/549, Loss: 2.9789
Epoch 10/100, Batch 340/549, Loss: 3.0450
Epoch 10/100, Batch 350/549, Loss: 3.0596
Epoch 10/100, Batch 360/549, Loss: 3.1184
Epoch 10/100, Batch 370/549, Loss: 3.0422
Epoch 10/100, Batch 380/549, Loss: 3.1075
Epoch 10/100, Batch 390/549, Loss: 3.0522
Epoch 10/100, Batch 400/549, Loss: 3.0892
Epoch 10/100, Batch 410/549, Loss: 3.0935
Epoch 10/100, Batch 420/549, Loss: 3.0259
Epoch 10/100, Batch 430/549, Loss: 3.0942
Epoch 10/100, Batch 440/549, Loss: 3.0418
Epoch 10/100, Batch 450/549, Loss: 3.0735
Epoch 10/100, Batch 460/549, Loss: 3.1026
Epoch 10/100, Batch 470/549, Loss: 3.0488
Epoch 10/100, Batch 480/549, Loss: 3.0140
Epoch 10/100, Batch 490/549, Loss: 3.0259
Epoch 10/100, Batch 500/549, Loss: 3.0133
Epoch 10/100, Batch 510/549, Loss: 3.0692
Epoch 10/100, Batch 520/549, Loss: 3.0245
Epoch 10/100, Batch 530/549, Loss: 3.0343
Epoch 10/100, Batch 540/549, Loss: 3.0450
New best model with validation loss: 2.8283, perplexity: 16.92
Epoch 10/100, Loss: 3.0709, Perplexity: 21.56, Val Loss: 2.8283, Val Perplexity: 16.92, Time: 1086.55s
Epoch 11/100, Batch 10/549, Loss: 3.0249
Epoch 11/100, Batch 20/549, Loss: 3.1004
Epoch 11/100, Batch 30/549, Loss: 3.0773
Epoch 11/100, Batch 40/549, Loss: 3.0032
Epoch 11/100, Batch 50/549, Loss: 2.9718
Epoch 11/100, Batch 60/549, Loss: 2.9403
Epoch 11/100, Batch 70/549, Loss: 3.0440
Epoch 11/100, Batch 80/549, Loss: 3.0014
Epoch 11/100, Batch 90/549, Loss: 2.9999
Epoch 11/100, Batch 100/549, Loss: 3.0822
Epoch 11/100, Batch 110/549, Loss: 3.0473
Epoch 11/100, Batch 120/549, Loss: 3.0432
Epoch 11/100, Batch 130/549, Loss: 3.0011
Epoch 11/100, Batch 140/549, Loss: 2.9949
Epoch 11/100, Batch 150/549, Loss: 3.0797
Epoch 11/100, Batch 160/549, Loss: 3.0178
Epoch 11/100, Batch 170/549, Loss: 3.0258
Epoch 11/100, Batch 180/549, Loss: 3.0716
Epoch 11/100, Batch 190/549, Loss: 2.9224
Epoch 11/100, Batch 200/549, Loss: 2.9620
Epoch 11/100, Batch 210/549, Loss: 2.9016
Epoch 11/100, Batch 220/549, Loss: 2.9609
Epoch 11/100, Batch 230/549, Loss: 3.0168
Epoch 11/100, Batch 240/549, Loss: 2.9563
Epoch 11/100, Batch 250/549, Loss: 2.8805
Epoch 11/100, Batch 260/549, Loss: 2.9144
Epoch 11/100, Batch 270/549, Loss: 2.9295
Epoch 11/100, Batch 280/549, Loss: 2.9578
Epoch 11/100, Batch 290/549, Loss: 2.9631
Epoch 11/100, Batch 300/549, Loss: 3.0195
Epoch 11/100, Batch 310/549, Loss: 2.9773
Epoch 11/100, Batch 320/549, Loss: 2.9311
Epoch 11/100, Batch 330/549, Loss: 2.9017
Epoch 11/100, Batch 340/549, Loss: 2.9462
Epoch 11/100, Batch 350/549, Loss: 2.9807
Epoch 11/100, Batch 360/549, Loss: 3.0284
Epoch 11/100, Batch 370/549, Loss: 2.9545
Epoch 11/100, Batch 380/549, Loss: 3.0302
Epoch 11/100, Batch 390/549, Loss: 2.9813
Epoch 11/100, Batch 400/549, Loss: 3.0137
Epoch 11/100, Batch 410/549, Loss: 3.0038
Epoch 11/100, Batch 420/549, Loss: 2.9487
Epoch 11/100, Batch 430/549, Loss: 3.0238
Epoch 11/100, Batch 440/549, Loss: 2.9545
Epoch 11/100, Batch 450/549, Loss: 2.9898
Epoch 11/100, Batch 460/549, Loss: 3.0005
Epoch 11/100, Batch 470/549, Loss: 2.9655
Epoch 11/100, Batch 480/549, Loss: 2.9387
Epoch 11/100, Batch 490/549, Loss: 2.9601
Epoch 11/100, Batch 500/549, Loss: 2.9557
Epoch 11/100, Batch 510/549, Loss: 2.9980
Epoch 11/100, Batch 520/549, Loss: 2.9521
Epoch 11/100, Batch 530/549, Loss: 3.0130
Epoch 11/100, Batch 540/549, Loss: 2.9583
New best model with validation loss: 2.7583, perplexity: 15.77
Epoch 11/100, Loss: 2.9946, Perplexity: 19.98, Val Loss: 2.7583, Val Perplexity: 15.77, Time: 1090.78s
Epoch 12/100, Batch 10/549, Loss: 2.9547
Epoch 12/100, Batch 20/549, Loss: 3.0875
Epoch 12/100, Batch 30/549, Loss: 3.0142
Epoch 12/100, Batch 40/549, Loss: 2.9364
Epoch 12/100, Batch 50/549, Loss: 2.8948
Epoch 12/100, Batch 60/549, Loss: 2.8535
Epoch 12/100, Batch 70/549, Loss: 2.9506
Epoch 12/100, Batch 80/549, Loss: 2.9194
Epoch 12/100, Batch 90/549, Loss: 2.9382
Epoch 12/100, Batch 100/549, Loss: 3.0095
Epoch 12/100, Batch 110/549, Loss: 3.0115
Epoch 12/100, Batch 120/549, Loss: 2.9772
Epoch 12/100, Batch 130/549, Loss: 2.9130
Epoch 12/100, Batch 140/549, Loss: 2.9331
Epoch 12/100, Batch 150/549, Loss: 3.0054
Epoch 12/100, Batch 160/549, Loss: 2.9444
Epoch 12/100, Batch 170/549, Loss: 2.9465
Epoch 12/100, Batch 180/549, Loss: 2.9726
Epoch 12/100, Batch 190/549, Loss: 2.8615
Epoch 12/100, Batch 200/549, Loss: 2.9457
Epoch 12/100, Batch 210/549, Loss: 2.8584
Epoch 12/100, Batch 220/549, Loss: 2.8720
Epoch 12/100, Batch 230/549, Loss: 2.9664
Epoch 12/100, Batch 240/549, Loss: 2.8474
Epoch 12/100, Batch 250/549, Loss: 2.8103
Epoch 12/100, Batch 260/549, Loss: 2.8616
Epoch 12/100, Batch 270/549, Loss: 2.8899
Epoch 12/100, Batch 280/549, Loss: 2.8893
Epoch 12/100, Batch 290/549, Loss: 2.9612
Epoch 12/100, Batch 300/549, Loss: 2.9605
Epoch 12/100, Batch 310/549, Loss: 2.9266
Epoch 12/100, Batch 320/549, Loss: 2.8548
Epoch 12/100, Batch 330/549, Loss: 2.8117
Epoch 12/100, Batch 340/549, Loss: 2.8746
Epoch 12/100, Batch 350/549, Loss: 2.9258
Epoch 12/100, Batch 360/549, Loss: 2.9471
Epoch 12/100, Batch 370/549, Loss: 2.8826
Epoch 12/100, Batch 380/549, Loss: 2.9538
Epoch 12/100, Batch 390/549, Loss: 2.9141
Epoch 12/100, Batch 400/549, Loss: 2.9426
Epoch 12/100, Batch 410/549, Loss: 3.0316
Epoch 12/100, Batch 420/549, Loss: 2.8811
Epoch 12/100, Batch 430/549, Loss: 2.9873
Epoch 12/100, Batch 440/549, Loss: 2.8773
Epoch 12/100, Batch 450/549, Loss: 2.9221
Epoch 12/100, Batch 460/549, Loss: 2.9720
Epoch 12/100, Batch 470/549, Loss: 2.9099
Epoch 12/100, Batch 480/549, Loss: 2.8554
Epoch 12/100, Batch 490/549, Loss: 2.8990
Epoch 12/100, Batch 500/549, Loss: 2.8762
Epoch 12/100, Batch 510/549, Loss: 2.9157
Epoch 12/100, Batch 520/549, Loss: 2.8679
Epoch 12/100, Batch 530/549, Loss: 2.9195
Epoch 12/100, Batch 540/549, Loss: 2.8781
New best model with validation loss: 2.6787, perplexity: 14.57
Epoch 12/100, Loss: 2.9243, Perplexity: 18.62, Val Loss: 2.6787, Val Perplexity: 14.57, Time: 1092.36s
Epoch 13/100, Batch 10/549, Loss: 2.8729
Epoch 13/100, Batch 20/549, Loss: 2.9673
Epoch 13/100, Batch 30/549, Loss: 2.9496
Epoch 13/100, Batch 40/549, Loss: 2.8741
Epoch 13/100, Batch 50/549, Loss: 2.8271
Epoch 13/100, Batch 60/549, Loss: 2.7840
Epoch 13/100, Batch 70/549, Loss: 2.8818
Epoch 13/100, Batch 80/549, Loss: 2.8449
Epoch 13/100, Batch 90/549, Loss: 2.8565
Epoch 13/100, Batch 100/549, Loss: 2.9486
Epoch 13/100, Batch 110/549, Loss: 2.9180
Epoch 13/100, Batch 120/549, Loss: 2.9619
Epoch 13/100, Batch 130/549, Loss: 2.8395
Epoch 13/100, Batch 140/549, Loss: 2.8481
Epoch 13/100, Batch 150/549, Loss: 2.9161
Epoch 13/100, Batch 160/549, Loss: 2.8821
Epoch 13/100, Batch 170/549, Loss: 2.8724
Epoch 13/100, Batch 180/549, Loss: 2.9010
Epoch 13/100, Batch 190/549, Loss: 2.7811
Epoch 13/100, Batch 200/549, Loss: 2.8266
Epoch 13/100, Batch 210/549, Loss: 2.7657
Epoch 13/100, Batch 220/549, Loss: 2.8081
Epoch 13/100, Batch 230/549, Loss: 2.8749
Epoch 13/100, Batch 240/549, Loss: 2.7781
Epoch 13/100, Batch 250/549, Loss: 2.7441
Epoch 13/100, Batch 260/549, Loss: 2.7639
Epoch 13/100, Batch 270/549, Loss: 2.8023
Epoch 13/100, Batch 280/549, Loss: 2.8202
Epoch 13/100, Batch 290/549, Loss: 2.8178
Epoch 13/100, Batch 300/549, Loss: 2.9353
Epoch 13/100, Batch 310/549, Loss: 2.8401
Epoch 13/100, Batch 320/549, Loss: 2.7749
Epoch 13/100, Batch 330/549, Loss: 2.7398
Epoch 13/100, Batch 340/549, Loss: 2.8026
Epoch 13/100, Batch 350/549, Loss: 2.8460
Epoch 13/100, Batch 360/549, Loss: 2.8792
Epoch 13/100, Batch 370/549, Loss: 2.8122
Epoch 13/100, Batch 380/549, Loss: 2.8688
Epoch 13/100, Batch 390/549, Loss: 2.8301
Epoch 13/100, Batch 400/549, Loss: 2.8760
Epoch 13/100, Batch 410/549, Loss: 2.8750
Epoch 13/100, Batch 420/549, Loss: 2.8245
Epoch 13/100, Batch 430/549, Loss: 2.8953
Epoch 13/100, Batch 440/549, Loss: 2.8150
Epoch 13/100, Batch 450/549, Loss: 2.8469
Epoch 13/100, Batch 460/549, Loss: 2.8167
Epoch 13/100, Batch 470/549, Loss: 2.8036
Epoch 13/100, Batch 480/549, Loss: 2.7669
Epoch 13/100, Batch 490/549, Loss: 2.8344
Epoch 13/100, Batch 500/549, Loss: 2.7988
Epoch 13/100, Batch 510/549, Loss: 2.8533
Epoch 13/100, Batch 520/549, Loss: 2.8186
Epoch 13/100, Batch 530/549, Loss: 2.7897
Epoch 13/100, Batch 540/549, Loss: 2.7884
New best model with validation loss: 2.5972, perplexity: 13.43
Epoch 13/100, Loss: 2.8497, Perplexity: 17.28, Val Loss: 2.5972, Val Perplexity: 13.43, Time: 1090.20s
Epoch 14/100, Batch 10/549, Loss: 2.7786
Epoch 14/100, Batch 20/549, Loss: 2.8882
Epoch 14/100, Batch 30/549, Loss: 2.8803
Epoch 14/100, Batch 40/549, Loss: 2.8114
Epoch 14/100, Batch 50/549, Loss: 2.7437
Epoch 14/100, Batch 60/549, Loss: 2.7062
Epoch 14/100, Batch 70/549, Loss: 2.7832
Epoch 14/100, Batch 80/549, Loss: 2.7717
Epoch 14/100, Batch 90/549, Loss: 2.7855
Epoch 14/100, Batch 100/549, Loss: 2.8554
Epoch 14/100, Batch 110/549, Loss: 2.8362
Epoch 14/100, Batch 120/549, Loss: 2.8319
Epoch 14/100, Batch 130/549, Loss: 2.7783
Epoch 14/100, Batch 140/549, Loss: 2.7659
Epoch 14/100, Batch 150/549, Loss: 2.8402
Epoch 14/100, Batch 160/549, Loss: 2.8033
Epoch 14/100, Batch 170/549, Loss: 2.7928
Epoch 14/100, Batch 180/549, Loss: 2.8205
Epoch 14/100, Batch 190/549, Loss: 2.7181
Epoch 14/100, Batch 200/549, Loss: 2.7647
Epoch 14/100, Batch 210/549, Loss: 2.6972
Epoch 14/100, Batch 220/549, Loss: 2.7391
Epoch 14/100, Batch 230/549, Loss: 2.8009
Epoch 14/100, Batch 240/549, Loss: 2.7032
Epoch 14/100, Batch 250/549, Loss: 2.6723
Epoch 14/100, Batch 260/549, Loss: 2.7222
Epoch 14/100, Batch 270/549, Loss: 2.7275
Epoch 14/100, Batch 280/549, Loss: 2.7359
Epoch 14/100, Batch 290/549, Loss: 2.7390
Epoch 14/100, Batch 300/549, Loss: 2.8150
Epoch 14/100, Batch 310/549, Loss: 2.7654
Epoch 14/100, Batch 320/549, Loss: 2.6937
Epoch 14/100, Batch 330/549, Loss: 2.6723
Epoch 14/100, Batch 340/549, Loss: 2.7288
Epoch 14/100, Batch 350/549, Loss: 2.7825
Epoch 14/100, Batch 360/549, Loss: 2.8343
Epoch 14/100, Batch 370/549, Loss: 2.7767
Epoch 14/100, Batch 380/549, Loss: 2.7898
Epoch 14/100, Batch 390/549, Loss: 2.7520
Epoch 14/100, Batch 400/549, Loss: 2.7887
Epoch 14/100, Batch 410/549, Loss: 2.7810
Epoch 14/100, Batch 420/549, Loss: 2.7314
Epoch 14/100, Batch 430/549, Loss: 2.8321
Epoch 14/100, Batch 440/549, Loss: 2.7467
Epoch 14/100, Batch 450/549, Loss: 2.7574
Epoch 14/100, Batch 460/549, Loss: 2.7408
Epoch 14/100, Batch 470/549, Loss: 2.7143
Epoch 14/100, Batch 480/549, Loss: 2.6999
Epoch 14/100, Batch 490/549, Loss: 2.7598
Epoch 14/100, Batch 500/549, Loss: 2.7066
Epoch 14/100, Batch 510/549, Loss: 2.7508
Epoch 14/100, Batch 520/549, Loss: 2.7556
Epoch 14/100, Batch 530/549, Loss: 2.7173
Epoch 14/100, Batch 540/549, Loss: 2.7000
New best model with validation loss: 2.5052, perplexity: 12.25
Epoch 14/100, Loss: 2.7737, Perplexity: 16.02, Val Loss: 2.5052, Val Perplexity: 12.25, Time: 1092.99s
Epoch 15/100, Batch 10/549, Loss: 2.7124
Epoch 15/100, Batch 20/549, Loss: 2.8038
Epoch 15/100, Batch 30/549, Loss: 2.7987
Epoch 15/100, Batch 40/549, Loss: 2.7364
Epoch 15/100, Batch 50/549, Loss: 2.6599
Epoch 15/100, Batch 60/549, Loss: 2.6324
Epoch 15/100, Batch 70/549, Loss: 2.7372
Epoch 15/100, Batch 80/549, Loss: 2.6938
Epoch 15/100, Batch 90/549, Loss: 2.6851
Epoch 15/100, Batch 100/549, Loss: 2.7772
Epoch 15/100, Batch 110/549, Loss: 2.7625
Epoch 15/100, Batch 120/549, Loss: 2.7533
Epoch 15/100, Batch 130/549, Loss: 2.7154
Epoch 15/100, Batch 140/549, Loss: 2.6849
Epoch 15/100, Batch 150/549, Loss: 2.7701
Epoch 15/100, Batch 160/549, Loss: 2.7198
Epoch 15/100, Batch 170/549, Loss: 2.7012
Epoch 15/100, Batch 180/549, Loss: 2.7408
Epoch 15/100, Batch 190/549, Loss: 2.6256
Epoch 15/100, Batch 200/549, Loss: 2.6720
Epoch 15/100, Batch 210/549, Loss: 2.6844
Epoch 15/100, Batch 220/549, Loss: 2.6513
Epoch 15/100, Batch 230/549, Loss: 2.7455
Epoch 15/100, Batch 240/549, Loss: 2.6354
Epoch 15/100, Batch 250/549, Loss: 2.5888
Epoch 15/100, Batch 260/549, Loss: 2.6058
Epoch 15/100, Batch 270/549, Loss: 2.6565
Epoch 15/100, Batch 280/549, Loss: 2.6950
Epoch 15/100, Batch 290/549, Loss: 2.7026
Epoch 15/100, Batch 300/549, Loss: 2.7365
Epoch 15/100, Batch 310/549, Loss: 2.6993
Epoch 15/100, Batch 320/549, Loss: 2.6465
Epoch 15/100, Batch 330/549, Loss: 2.6063
Epoch 15/100, Batch 340/549, Loss: 2.6566
Epoch 15/100, Batch 350/549, Loss: 2.7056
Epoch 15/100, Batch 360/549, Loss: 2.7286
Epoch 15/100, Batch 370/549, Loss: 2.6366
Epoch 15/100, Batch 380/549, Loss: 2.7201
Epoch 15/100, Batch 390/549, Loss: 2.7021
Epoch 15/100, Batch 400/549, Loss: 2.7250
Epoch 15/100, Batch 410/549, Loss: 2.7153
Epoch 15/100, Batch 420/549, Loss: 2.6631
Epoch 15/100, Batch 430/549, Loss: 2.7700
Epoch 15/100, Batch 440/549, Loss: 2.6780
Epoch 15/100, Batch 450/549, Loss: 2.6827
Epoch 15/100, Batch 460/549, Loss: 2.6690
Epoch 15/100, Batch 470/549, Loss: 2.6601
Epoch 15/100, Batch 480/549, Loss: 2.6306
Epoch 15/100, Batch 490/549, Loss: 2.6863
Epoch 15/100, Batch 500/549, Loss: 2.6528
Epoch 15/100, Batch 510/549, Loss: 2.6919
Epoch 15/100, Batch 520/549, Loss: 2.6473
Epoch 15/100, Batch 530/549, Loss: 2.6784
Epoch 15/100, Batch 540/549, Loss: 2.6389
New best model with validation loss: 2.4453, perplexity: 11.53
Epoch 15/100, Loss: 2.7011, Perplexity: 14.90, Val Loss: 2.4453, Val Perplexity: 11.53, Time: 1089.62s
Epoch 16/100, Batch 10/549, Loss: 2.6224
Epoch 16/100, Batch 20/549, Loss: 2.7371
Epoch 16/100, Batch 30/549, Loss: 2.7595
Epoch 16/100, Batch 40/549, Loss: 2.6867
Epoch 16/100, Batch 50/549, Loss: 2.6329
Epoch 16/100, Batch 60/549, Loss: 2.5621
Epoch 16/100, Batch 70/549, Loss: 2.6404
Epoch 16/100, Batch 80/549, Loss: 2.6218
Epoch 16/100, Batch 90/549, Loss: 2.6336
Epoch 16/100, Batch 100/549, Loss: 2.7039
Epoch 16/100, Batch 110/549, Loss: 2.6943
Epoch 16/100, Batch 120/549, Loss: 2.6972
Epoch 16/100, Batch 130/549, Loss: 2.6255
Epoch 16/100, Batch 140/549, Loss: 2.6131
Epoch 16/100, Batch 150/549, Loss: 2.7030
Epoch 16/100, Batch 160/549, Loss: 2.6521
Epoch 16/100, Batch 170/549, Loss: 2.6523
Epoch 16/100, Batch 180/549, Loss: 2.6730
Epoch 16/100, Batch 190/549, Loss: 2.5632
Epoch 16/100, Batch 200/549, Loss: 2.6209
Epoch 16/100, Batch 210/549, Loss: 2.5709
Epoch 16/100, Batch 220/549, Loss: 2.6044
Epoch 16/100, Batch 230/549, Loss: 2.6610
Epoch 16/100, Batch 240/549, Loss: 2.5537
Epoch 16/100, Batch 250/549, Loss: 2.5651
Epoch 16/100, Batch 260/549, Loss: 2.5544
Epoch 16/100, Batch 270/549, Loss: 2.6139
Epoch 16/100, Batch 280/549, Loss: 2.6107
Epoch 16/100, Batch 290/549, Loss: 2.6001
Epoch 16/100, Batch 300/549, Loss: 2.7115
Epoch 16/100, Batch 310/549, Loss: 2.6346
Epoch 16/100, Batch 320/549, Loss: 2.5603
Epoch 16/100, Batch 330/549, Loss: 2.5333
Epoch 16/100, Batch 340/549, Loss: 2.5953
Epoch 16/100, Batch 350/549, Loss: 2.6509
Epoch 16/100, Batch 360/549, Loss: 2.6733
Epoch 16/100, Batch 370/549, Loss: 2.5814
Epoch 16/100, Batch 380/549, Loss: 2.6494
Epoch 16/100, Batch 390/549, Loss: 2.6214
Epoch 16/100, Batch 400/549, Loss: 2.6765
Epoch 16/100, Batch 410/549, Loss: 2.6484
Epoch 16/100, Batch 420/549, Loss: 2.6179
Epoch 16/100, Batch 430/549, Loss: 2.7635
Epoch 16/100, Batch 440/549, Loss: 2.6209
Epoch 16/100, Batch 450/549, Loss: 2.6204
Epoch 16/100, Batch 460/549, Loss: 2.5974
Epoch 16/100, Batch 470/549, Loss: 2.6610
Epoch 16/100, Batch 480/549, Loss: 2.5711
Epoch 16/100, Batch 490/549, Loss: 2.6450
Epoch 16/100, Batch 500/549, Loss: 2.6301
Epoch 16/100, Batch 510/549, Loss: 2.6288
Epoch 16/100, Batch 520/549, Loss: 2.5746
Epoch 16/100, Batch 530/549, Loss: 2.5777
Epoch 16/100, Batch 540/549, Loss: 2.5709
New best model with validation loss: 2.3946, perplexity: 10.96
Epoch 16/100, Loss: 2.6400, Perplexity: 14.01, Val Loss: 2.3946, Val Perplexity: 10.96, Time: 1092.91s
Epoch 17/100, Batch 10/549, Loss: 2.5732
Epoch 17/100, Batch 20/549, Loss: 2.6958
Epoch 17/100, Batch 30/549, Loss: 2.7041
Epoch 17/100, Batch 40/549, Loss: 2.6220
Epoch 17/100, Batch 50/549, Loss: 2.5380
Epoch 17/100, Batch 60/549, Loss: 2.4993
Epoch 17/100, Batch 70/549, Loss: 2.5899
Epoch 17/100, Batch 80/549, Loss: 2.6505
Epoch 17/100, Batch 90/549, Loss: 2.6280
Epoch 17/100, Batch 100/549, Loss: 2.6509
Epoch 17/100, Batch 110/549, Loss: 2.6381
Epoch 17/100, Batch 120/549, Loss: 2.6311
Epoch 17/100, Batch 130/549, Loss: 2.5922
Epoch 17/100, Batch 140/549, Loss: 2.5743
Epoch 17/100, Batch 150/549, Loss: 2.6390
Epoch 17/100, Batch 160/549, Loss: 2.5941
Epoch 17/100, Batch 170/549, Loss: 2.5962
Epoch 17/100, Batch 180/549, Loss: 2.6105
Epoch 17/100, Batch 190/549, Loss: 2.5164
Epoch 17/100, Batch 200/549, Loss: 2.5625
Epoch 17/100, Batch 210/549, Loss: 2.5628
Epoch 17/100, Batch 220/549, Loss: 2.5509
Epoch 17/100, Batch 230/549, Loss: 2.6049
Epoch 17/100, Batch 240/549, Loss: 2.5792
Epoch 17/100, Batch 250/549, Loss: 2.4983
Epoch 17/100, Batch 260/549, Loss: 2.4938
Epoch 17/100, Batch 270/549, Loss: 2.5438
Epoch 17/100, Batch 280/549, Loss: 2.5563
Epoch 17/100, Batch 290/549, Loss: 2.5544
Epoch 17/100, Batch 300/549, Loss: 2.6123
Epoch 17/100, Batch 310/549, Loss: 2.5917
Epoch 17/100, Batch 320/549, Loss: 2.5054
Epoch 17/100, Batch 330/549, Loss: 2.4817
Epoch 17/100, Batch 340/549, Loss: 2.5431
Epoch 17/100, Batch 350/549, Loss: 2.5976
Epoch 17/100, Batch 360/549, Loss: 2.6232
Epoch 17/100, Batch 370/549, Loss: 2.5195
Epoch 17/100, Batch 380/549, Loss: 2.5995
Epoch 17/100, Batch 390/549, Loss: 2.5769
Epoch 17/100, Batch 400/549, Loss: 2.6316
Epoch 17/100, Batch 410/549, Loss: 2.5848
Epoch 17/100, Batch 420/549, Loss: 2.5602
Epoch 17/100, Batch 430/549, Loss: 2.6446
Epoch 17/100, Batch 440/549, Loss: 2.5652
Epoch 17/100, Batch 450/549, Loss: 2.6059
Epoch 17/100, Batch 460/549, Loss: 2.5709
Epoch 17/100, Batch 470/549, Loss: 2.5790
Epoch 17/100, Batch 480/549, Loss: 2.5176
Epoch 17/100, Batch 490/549, Loss: 2.5873
Epoch 17/100, Batch 500/549, Loss: 2.5351
Epoch 17/100, Batch 510/549, Loss: 2.5822
Epoch 17/100, Batch 520/549, Loss: 2.5157
Epoch 17/100, Batch 530/549, Loss: 2.5523
Epoch 17/100, Batch 540/549, Loss: 2.5097
New best model with validation loss: 2.3457, perplexity: 10.44
Epoch 17/100, Loss: 2.5867, Perplexity: 13.29, Val Loss: 2.3457, Val Perplexity: 10.44, Time: 1092.93s
Epoch 18/100, Batch 10/549, Loss: 2.5068
Epoch 18/100, Batch 20/549, Loss: 2.6386
Epoch 18/100, Batch 30/549, Loss: 2.6135
Epoch 18/100, Batch 40/549, Loss: 2.5648
Epoch 18/100, Batch 50/549, Loss: 2.5180
Epoch 18/100, Batch 60/549, Loss: 2.4503
Epoch 18/100, Batch 70/549, Loss: 2.5702
Epoch 18/100, Batch 80/549, Loss: 2.5259
Epoch 18/100, Batch 90/549, Loss: 2.5334
Epoch 18/100, Batch 100/549, Loss: 2.6066
Epoch 18/100, Batch 110/549, Loss: 2.6780
Epoch 18/100, Batch 120/549, Loss: 2.6011
Epoch 18/100, Batch 130/549, Loss: 2.5344
Epoch 18/100, Batch 140/549, Loss: 2.5210
Epoch 18/100, Batch 150/549, Loss: 2.6033
Epoch 18/100, Batch 160/549, Loss: 2.5590
Epoch 18/100, Batch 170/549, Loss: 2.5603
Epoch 18/100, Batch 180/549, Loss: 2.5579
Epoch 18/100, Batch 190/549, Loss: 2.4735
Epoch 18/100, Batch 200/549, Loss: 2.5158
Epoch 18/100, Batch 210/549, Loss: 2.4736
Epoch 18/100, Batch 220/549, Loss: 2.5247
Epoch 18/100, Batch 230/549, Loss: 2.5760
Epoch 18/100, Batch 240/549, Loss: 2.4681
Epoch 18/100, Batch 250/549, Loss: 2.4436
Epoch 18/100, Batch 260/549, Loss: 2.4827
Epoch 18/100, Batch 270/549, Loss: 2.4929
Epoch 18/100, Batch 280/549, Loss: 2.4964
Epoch 18/100, Batch 290/549, Loss: 2.4902
Epoch 18/100, Batch 300/549, Loss: 2.5825
Epoch 18/100, Batch 310/549, Loss: 2.5343
Epoch 18/100, Batch 320/549, Loss: 2.4664
Epoch 18/100, Batch 330/549, Loss: 2.4267
Epoch 18/100, Batch 340/549, Loss: 2.5064
Epoch 18/100, Batch 350/549, Loss: 2.6256
Epoch 18/100, Batch 360/549, Loss: 2.5961
Epoch 18/100, Batch 370/549, Loss: 2.4863
Epoch 18/100, Batch 380/549, Loss: 2.5360
Epoch 18/100, Batch 390/549, Loss: 2.5304
Epoch 18/100, Batch 400/549, Loss: 2.6098
Epoch 18/100, Batch 410/549, Loss: 2.5429
Epoch 18/100, Batch 420/549, Loss: 2.5088
Epoch 18/100, Batch 430/549, Loss: 2.6238
Epoch 18/100, Batch 440/549, Loss: 2.5326
Epoch 18/100, Batch 450/549, Loss: 2.5278
Epoch 18/100, Batch 460/549, Loss: 2.5503
Epoch 18/100, Batch 470/549, Loss: 2.5034
Epoch 18/100, Batch 480/549, Loss: 2.4844
Epoch 18/100, Batch 490/549, Loss: 2.5536
Epoch 18/100, Batch 500/549, Loss: 2.4963
Epoch 18/100, Batch 510/549, Loss: 2.5327
Epoch 18/100, Batch 520/549, Loss: 2.4804
Epoch 18/100, Batch 530/549, Loss: 2.4927
Epoch 18/100, Batch 540/549, Loss: 2.4644
New best model with validation loss: 2.3192, perplexity: 10.17
Epoch 18/100, Loss: 2.5438, Perplexity: 12.73, Val Loss: 2.3192, Val Perplexity: 10.17, Time: 1088.62s
Epoch 19/100, Batch 10/549, Loss: 2.4764
Epoch 19/100, Batch 20/549, Loss: 2.5939
Epoch 19/100, Batch 30/549, Loss: 2.5905
Epoch 19/100, Batch 40/549, Loss: 2.5322
Epoch 19/100, Batch 50/549, Loss: 2.4612
Epoch 19/100, Batch 60/549, Loss: 2.4026
Epoch 19/100, Batch 70/549, Loss: 2.5182
Epoch 19/100, Batch 80/549, Loss: 2.4860
Epoch 19/100, Batch 90/549, Loss: 2.5226
Epoch 19/100, Batch 100/549, Loss: 2.5679
Epoch 19/100, Batch 110/549, Loss: 2.5647
Epoch 19/100, Batch 120/549, Loss: 2.6035
Epoch 19/100, Batch 130/549, Loss: 2.4974
Epoch 19/100, Batch 140/549, Loss: 2.4803
Epoch 19/100, Batch 150/549, Loss: 2.5745
Epoch 19/100, Batch 160/549, Loss: 2.5210
Epoch 19/100, Batch 170/549, Loss: 2.5098
Epoch 19/100, Batch 180/549, Loss: 2.5434
Epoch 19/100, Batch 190/549, Loss: 2.4249
Epoch 19/100, Batch 200/549, Loss: 2.4867
Epoch 19/100, Batch 210/549, Loss: 2.4342
Epoch 19/100, Batch 220/549, Loss: 2.4646
Epoch 19/100, Batch 230/549, Loss: 2.5418
Epoch 19/100, Batch 240/549, Loss: 2.4194
Epoch 19/100, Batch 250/549, Loss: 2.4271
Epoch 19/100, Batch 260/549, Loss: 2.4308
Epoch 19/100, Batch 270/549, Loss: 2.4683
Epoch 19/100, Batch 280/549, Loss: 2.4634
Epoch 19/100, Batch 290/549, Loss: 2.4585
Epoch 19/100, Batch 300/549, Loss: 2.5281
Epoch 19/100, Batch 310/549, Loss: 2.5069
Epoch 19/100, Batch 320/549, Loss: 2.4248
Epoch 19/100, Batch 330/549, Loss: 2.4107
Epoch 19/100, Batch 340/549, Loss: 2.4505
Epoch 19/100, Batch 350/549, Loss: 2.5338
Epoch 19/100, Batch 360/549, Loss: 2.5331
Epoch 19/100, Batch 370/549, Loss: 2.4391
Epoch 19/100, Batch 380/549, Loss: 2.5118
Epoch 19/100, Batch 390/549, Loss: 2.4912
Epoch 19/100, Batch 400/549, Loss: 2.6073
Epoch 19/100, Batch 410/549, Loss: 2.5127
Epoch 19/100, Batch 420/549, Loss: 2.4826
Epoch 19/100, Batch 430/549, Loss: 2.5780
Epoch 19/100, Batch 440/549, Loss: 2.4939
Epoch 19/100, Batch 450/549, Loss: 2.4971
Epoch 19/100, Batch 460/549, Loss: 2.4879
Epoch 19/100, Batch 470/549, Loss: 2.5405
Epoch 19/100, Batch 480/549, Loss: 2.4529
Epoch 19/100, Batch 490/549, Loss: 2.5149
Epoch 19/100, Batch 500/549, Loss: 2.4555
Epoch 19/100, Batch 510/549, Loss: 2.5800
Epoch 19/100, Batch 520/549, Loss: 2.5094
Epoch 19/100, Batch 530/549, Loss: 2.4449
Epoch 19/100, Batch 540/549, Loss: 2.4264
New best model with validation loss: 2.2903, perplexity: 9.88
Epoch 19/100, Loss: 2.5046, Perplexity: 12.24, Val Loss: 2.2903, Val Perplexity: 9.88, Time: 1088.36s
Epoch 20/100, Batch 10/549, Loss: 2.4319
Epoch 20/100, Batch 20/549, Loss: 2.6041
Epoch 20/100, Batch 30/549, Loss: 2.5585
Epoch 20/100, Batch 40/549, Loss: 2.4842
Epoch 20/100, Batch 50/549, Loss: 2.4176
Epoch 20/100, Batch 60/549, Loss: 2.3761
Epoch 20/100, Batch 70/549, Loss: 2.5160
Epoch 20/100, Batch 80/549, Loss: 2.4493
Epoch 20/100, Batch 90/549, Loss: 2.4635
Epoch 20/100, Batch 100/549, Loss: 2.5261
Epoch 20/100, Batch 110/549, Loss: 2.5222
Epoch 20/100, Batch 120/549, Loss: 2.5492
Epoch 20/100, Batch 130/549, Loss: 2.4486
Epoch 20/100, Batch 140/549, Loss: 2.4981
Epoch 20/100, Batch 150/549, Loss: 2.5266
Epoch 20/100, Batch 160/549, Loss: 2.4888
Epoch 20/100, Batch 170/549, Loss: 2.4814
Epoch 20/100, Batch 180/549, Loss: 2.4791
Epoch 20/100, Batch 190/549, Loss: 2.4075
Epoch 20/100, Batch 200/549, Loss: 2.4492
Epoch 20/100, Batch 210/549, Loss: 2.4233
Epoch 20/100, Batch 220/549, Loss: 2.4310
Epoch 20/100, Batch 230/549, Loss: 2.5836
Epoch 20/100, Batch 240/549, Loss: 2.3753
Epoch 20/100, Batch 250/549, Loss: 2.3652
Epoch 20/100, Batch 260/549, Loss: 2.3818
Epoch 20/100, Batch 270/549, Loss: 2.4292
Epoch 20/100, Batch 280/549, Loss: 2.4397
Epoch 20/100, Batch 290/549, Loss: 2.4106
Epoch 20/100, Batch 300/549, Loss: 2.5122
Epoch 20/100, Batch 310/549, Loss: 2.5170
Epoch 20/100, Batch 320/549, Loss: 2.3779
Epoch 20/100, Batch 330/549, Loss: 2.3733
Epoch 20/100, Batch 340/549, Loss: 2.4336
Epoch 20/100, Batch 350/549, Loss: 2.4855
Epoch 20/100, Batch 360/549, Loss: 2.5025
Epoch 20/100, Batch 370/549, Loss: 2.4050
Epoch 20/100, Batch 380/549, Loss: 2.4839
Epoch 20/100, Batch 390/549, Loss: 2.4618
Epoch 20/100, Batch 400/549, Loss: 2.5828
Epoch 20/100, Batch 410/549, Loss: 2.4802
Epoch 20/100, Batch 420/549, Loss: 2.5188
Epoch 20/100, Batch 430/549, Loss: 2.5522
Epoch 20/100, Batch 440/549, Loss: 2.4657
Epoch 20/100, Batch 450/549, Loss: 2.4772
Epoch 20/100, Batch 460/549, Loss: 2.5206
Epoch 20/100, Batch 470/549, Loss: 2.4331
Epoch 20/100, Batch 480/549, Loss: 2.4172
Epoch 20/100, Batch 490/549, Loss: 2.4819
Epoch 20/100, Batch 500/549, Loss: 2.4255
Epoch 20/100, Batch 510/549, Loss: 2.4812
Epoch 20/100, Batch 520/549, Loss: 2.4414
Epoch 20/100, Batch 530/549, Loss: 2.4081
Epoch 20/100, Batch 540/549, Loss: 2.4696
New best model with validation loss: 2.2675, perplexity: 9.66
Epoch 20/100, Loss: 2.4716, Perplexity: 11.84, Val Loss: 2.2675, Val Perplexity: 9.66, Time: 1088.30s
Epoch 21/100, Batch 10/549, Loss: 2.4377
Epoch 21/100, Batch 20/549, Loss: 2.5238
Epoch 21/100, Batch 30/549, Loss: 2.6160
Epoch 21/100, Batch 40/549, Loss: 2.4615
Epoch 21/100, Batch 50/549, Loss: 2.3921
Epoch 21/100, Batch 60/549, Loss: 2.3519
Epoch 21/100, Batch 70/549, Loss: 2.4767
Epoch 21/100, Batch 80/549, Loss: 2.4355
Epoch 21/100, Batch 90/549, Loss: 2.4335
Epoch 21/100, Batch 100/549, Loss: 2.4981
Epoch 21/100, Batch 110/549, Loss: 2.4979
Epoch 21/100, Batch 120/549, Loss: 2.5317
Epoch 21/100, Batch 130/549, Loss: 2.4299
Epoch 21/100, Batch 140/549, Loss: 2.4830
Epoch 21/100, Batch 150/549, Loss: 2.5060
Epoch 21/100, Batch 160/549, Loss: 2.4525
Epoch 21/100, Batch 170/549, Loss: 2.4484
Epoch 21/100, Batch 180/549, Loss: 2.4433
Epoch 21/100, Batch 190/549, Loss: 2.3709
Epoch 21/100, Batch 200/549, Loss: 2.4676
Epoch 21/100, Batch 210/549, Loss: 2.3881
Epoch 21/100, Batch 220/549, Loss: 2.3907
Epoch 21/100, Batch 230/549, Loss: 2.4637
Epoch 21/100, Batch 240/549, Loss: 2.4064
Epoch 21/100, Batch 250/549, Loss: 2.3436
Epoch 21/100, Batch 260/549, Loss: 2.3539
Epoch 21/100, Batch 270/549, Loss: 2.4067
Epoch 21/100, Batch 280/549, Loss: 2.4165
Epoch 21/100, Batch 290/549, Loss: 2.3946
Epoch 21/100, Batch 300/549, Loss: 2.4794
Epoch 21/100, Batch 310/549, Loss: 2.4499
Epoch 21/100, Batch 320/549, Loss: 2.3619
Epoch 21/100, Batch 330/549, Loss: 2.3326
Epoch 21/100, Batch 340/549, Loss: 2.4091
Epoch 21/100, Batch 350/549, Loss: 2.5318
Epoch 21/100, Batch 360/549, Loss: 2.4868
Epoch 21/100, Batch 370/549, Loss: 2.3784
Epoch 21/100, Batch 380/549, Loss: 2.4642
Epoch 21/100, Batch 390/549, Loss: 2.4266
Epoch 21/100, Batch 400/549, Loss: 2.4866
Epoch 21/100, Batch 410/549, Loss: 2.4434
Epoch 21/100, Batch 420/549, Loss: 2.4277
Epoch 21/100, Batch 430/549, Loss: 2.5664
Epoch 21/100, Batch 440/549, Loss: 2.4508
Epoch 21/100, Batch 450/549, Loss: 2.4452
Epoch 21/100, Batch 460/549, Loss: 2.4286
Epoch 21/100, Batch 470/549, Loss: 2.4078
Epoch 21/100, Batch 480/549, Loss: 2.3845
Epoch 21/100, Batch 490/549, Loss: 2.4679
Epoch 21/100, Batch 500/549, Loss: 2.3935
Epoch 21/100, Batch 510/549, Loss: 2.4439
Epoch 21/100, Batch 520/549, Loss: 2.3864
Epoch 21/100, Batch 530/549, Loss: 2.3751
Epoch 21/100, Batch 540/549, Loss: 2.3994
New best model with validation loss: 2.2495, perplexity: 9.48
Epoch 21/100, Loss: 2.4446, Perplexity: 11.53, Val Loss: 2.2495, Val Perplexity: 9.48, Time: 1087.68s
Epoch 22/100, Batch 10/549, Loss: 2.3667
Epoch 22/100, Batch 20/549, Loss: 2.4989
Epoch 22/100, Batch 30/549, Loss: 2.4842
Epoch 22/100, Batch 40/549, Loss: 2.4355
Epoch 22/100, Batch 50/549, Loss: 2.3601
Epoch 22/100, Batch 60/549, Loss: 2.3311
Epoch 22/100, Batch 70/549, Loss: 2.4144
Epoch 22/100, Batch 80/549, Loss: 2.4465
Epoch 22/100, Batch 90/549, Loss: 2.3982
Epoch 22/100, Batch 100/549, Loss: 2.4700
Epoch 22/100, Batch 110/549, Loss: 2.4771
Epoch 22/100, Batch 120/549, Loss: 2.4864
Epoch 22/100, Batch 130/549, Loss: 2.4003
Epoch 22/100, Batch 140/549, Loss: 2.4644
Epoch 22/100, Batch 150/549, Loss: 2.4755
Epoch 22/100, Batch 160/549, Loss: 2.4438
Epoch 22/100, Batch 170/549, Loss: 2.4205
Epoch 22/100, Batch 180/549, Loss: 2.4310
Epoch 22/100, Batch 190/549, Loss: 2.3423
Epoch 22/100, Batch 200/549, Loss: 2.4558
Epoch 22/100, Batch 210/549, Loss: 2.3491
Epoch 22/100, Batch 220/549, Loss: 2.3813
Epoch 22/100, Batch 230/549, Loss: 2.4550
Epoch 22/100, Batch 240/549, Loss: 2.3250
Epoch 22/100, Batch 250/549, Loss: 2.3485
Epoch 22/100, Batch 260/549, Loss: 2.3300
Epoch 22/100, Batch 270/549, Loss: 2.3828
Epoch 22/100, Batch 280/549, Loss: 2.3930
Epoch 22/100, Batch 290/549, Loss: 2.3852
Epoch 22/100, Batch 300/549, Loss: 2.4570
Epoch 22/100, Batch 310/549, Loss: 2.4220
Epoch 22/100, Batch 320/549, Loss: 2.3220
Epoch 22/100, Batch 330/549, Loss: 2.3074
Epoch 22/100, Batch 340/549, Loss: 2.3679
Epoch 22/100, Batch 350/549, Loss: 2.4412
Epoch 22/100, Batch 360/549, Loss: 2.4708
Epoch 22/100, Batch 370/549, Loss: 2.3510
Epoch 22/100, Batch 380/549, Loss: 2.4248
Epoch 22/100, Batch 390/549, Loss: 2.3881
Epoch 22/100, Batch 400/549, Loss: 2.4908
Epoch 22/100, Batch 410/549, Loss: 2.4204
Epoch 22/100, Batch 420/549, Loss: 2.4012
Epoch 22/100, Batch 430/549, Loss: 2.5812
Epoch 22/100, Batch 440/549, Loss: 2.4129
Epoch 22/100, Batch 450/549, Loss: 2.4120
Epoch 22/100, Batch 460/549, Loss: 2.4058
Epoch 22/100, Batch 470/549, Loss: 2.3838
Epoch 22/100, Batch 480/549, Loss: 2.3932
Epoch 22/100, Batch 490/549, Loss: 2.4710
Epoch 22/100, Batch 500/549, Loss: 2.3607
Epoch 22/100, Batch 510/549, Loss: 2.4286
Epoch 22/100, Batch 520/549, Loss: 2.3557
Epoch 22/100, Batch 530/549, Loss: 2.3524
Epoch 22/100, Batch 540/549, Loss: 2.3656
New best model with validation loss: 2.2272, perplexity: 9.27
Epoch 22/100, Loss: 2.4190, Perplexity: 11.23, Val Loss: 2.2272, Val Perplexity: 9.27, Time: 1088.12s
Epoch 23/100, Batch 10/549, Loss: 2.3498
Epoch 23/100, Batch 20/549, Loss: 2.4734
Epoch 23/100, Batch 30/549, Loss: 2.4767
Epoch 23/100, Batch 40/549, Loss: 2.3979
Epoch 23/100, Batch 50/549, Loss: 2.3766
Epoch 23/100, Batch 60/549, Loss: 2.3015
Epoch 23/100, Batch 70/549, Loss: 2.3897
Epoch 23/100, Batch 80/549, Loss: 2.3798
Epoch 23/100, Batch 90/549, Loss: 2.3869
Epoch 23/100, Batch 100/549, Loss: 2.4435
Epoch 23/100, Batch 110/549, Loss: 2.4551
Epoch 23/100, Batch 120/549, Loss: 2.4583
Epoch 23/100, Batch 130/549, Loss: 2.3854
Epoch 23/100, Batch 140/549, Loss: 2.3662
Epoch 23/100, Batch 150/549, Loss: 2.4538
Epoch 23/100, Batch 160/549, Loss: 2.4127
Epoch 23/100, Batch 170/549, Loss: 2.4226
Epoch 23/100, Batch 180/549, Loss: 2.3992
Epoch 23/100, Batch 190/549, Loss: 2.3421
Epoch 23/100, Batch 200/549, Loss: 2.3786
Epoch 23/100, Batch 210/549, Loss: 2.3435
Epoch 23/100, Batch 220/549, Loss: 2.3497
Epoch 23/100, Batch 230/549, Loss: 2.4168
Epoch 23/100, Batch 240/549, Loss: 2.3027
Epoch 23/100, Batch 250/549, Loss: 2.3121
Epoch 23/100, Batch 260/549, Loss: 2.3063
Epoch 23/100, Batch 270/549, Loss: 2.3714
Epoch 23/100, Batch 280/549, Loss: 2.3744
Epoch 23/100, Batch 290/549, Loss: 2.3690
Epoch 23/100, Batch 300/549, Loss: 2.4331
Epoch 23/100, Batch 310/549, Loss: 2.3933
Epoch 23/100, Batch 320/549, Loss: 2.3054
Epoch 23/100, Batch 330/549, Loss: 2.2935
Epoch 23/100, Batch 340/549, Loss: 2.3363
Epoch 23/100, Batch 350/549, Loss: 2.4278
Epoch 23/100, Batch 360/549, Loss: 2.4228
Epoch 23/100, Batch 370/549, Loss: 2.3346
Epoch 23/100, Batch 380/549, Loss: 2.4258
Epoch 23/100, Batch 390/549, Loss: 2.3771
Epoch 23/100, Batch 400/549, Loss: 2.4425
Epoch 23/100, Batch 410/549, Loss: 2.3935
Epoch 23/100, Batch 420/549, Loss: 2.4030
Epoch 23/100, Batch 430/549, Loss: 2.4860
Epoch 23/100, Batch 440/549, Loss: 2.3960
Epoch 23/100, Batch 450/549, Loss: 2.4004
Epoch 23/100, Batch 460/549, Loss: 2.3698
Epoch 23/100, Batch 470/549, Loss: 2.3613
Epoch 23/100, Batch 480/549, Loss: 2.3399
Epoch 23/100, Batch 490/549, Loss: 2.4260
Epoch 23/100, Batch 500/549, Loss: 2.3624
Epoch 23/100, Batch 510/549, Loss: 2.4090
Epoch 23/100, Batch 520/549, Loss: 2.3349
Epoch 23/100, Batch 530/549, Loss: 2.3303
Epoch 23/100, Batch 540/549, Loss: 2.3254
New best model with validation loss: 2.2100, perplexity: 9.12
Epoch 23/100, Loss: 2.3967, Perplexity: 10.99, Val Loss: 2.2100, Val Perplexity: 9.12, Time: 1085.58s
Epoch 24/100, Batch 10/549, Loss: 2.3348
Epoch 24/100, Batch 20/549, Loss: 2.4489
Epoch 24/100, Batch 30/549, Loss: 2.4625
Epoch 24/100, Batch 40/549, Loss: 2.3873
Epoch 24/100, Batch 50/549, Loss: 2.3251
Epoch 24/100, Batch 60/549, Loss: 2.2899
Epoch 24/100, Batch 70/549, Loss: 2.3694
Epoch 24/100, Batch 80/549, Loss: 2.3517
Epoch 24/100, Batch 90/549, Loss: 2.3617
Epoch 24/100, Batch 100/549, Loss: 2.4353
Epoch 24/100, Batch 110/549, Loss: 2.4287
Epoch 24/100, Batch 120/549, Loss: 2.4352
Epoch 24/100, Batch 130/549, Loss: 2.3699
Epoch 24/100, Batch 140/549, Loss: 2.3506
Epoch 24/100, Batch 150/549, Loss: 2.4253
Epoch 24/100, Batch 160/549, Loss: 2.4066
Epoch 24/100, Batch 170/549, Loss: 2.3898
Epoch 24/100, Batch 180/549, Loss: 2.3745
Epoch 24/100, Batch 190/549, Loss: 2.3502
Epoch 24/100, Batch 200/549, Loss: 2.3582
Epoch 24/100, Batch 210/549, Loss: 2.3218
Epoch 24/100, Batch 220/549, Loss: 2.3299
Epoch 24/100, Batch 230/549, Loss: 2.4057
Epoch 24/100, Batch 240/549, Loss: 2.2774
Epoch 24/100, Batch 250/549, Loss: 2.2697
Epoch 24/100, Batch 260/549, Loss: 2.2929
Epoch 24/100, Batch 270/549, Loss: 2.3542
Epoch 24/100, Batch 280/549, Loss: 2.3395
Epoch 24/100, Batch 290/549, Loss: 2.3470
Epoch 24/100, Batch 300/549, Loss: 2.4150
Epoch 24/100, Batch 310/549, Loss: 2.4443
Epoch 24/100, Batch 320/549, Loss: 2.2967
Epoch 24/100, Batch 330/549, Loss: 2.2720
Epoch 24/100, Batch 340/549, Loss: 2.3634
Epoch 24/100, Batch 350/549, Loss: 2.4069
Epoch 24/100, Batch 360/549, Loss: 2.4061
Epoch 24/100, Batch 370/549, Loss: 2.3316
Epoch 24/100, Batch 380/549, Loss: 2.3895
Epoch 24/100, Batch 390/549, Loss: 2.3598
Epoch 24/100, Batch 400/549, Loss: 2.4448
Epoch 24/100, Batch 410/549, Loss: 2.4222
Epoch 24/100, Batch 420/549, Loss: 2.3617
Epoch 24/100, Batch 430/549, Loss: 2.4719
Epoch 24/100, Batch 440/549, Loss: 2.3794
Epoch 24/100, Batch 450/549, Loss: 2.3813
Epoch 24/100, Batch 460/549, Loss: 2.3647
Epoch 24/100, Batch 470/549, Loss: 2.3465
Epoch 24/100, Batch 480/549, Loss: 2.3392
Epoch 24/100, Batch 490/549, Loss: 2.4014
Epoch 24/100, Batch 500/549, Loss: 2.3317
Epoch 24/100, Batch 510/549, Loss: 2.3934
Epoch 24/100, Batch 520/549, Loss: 2.3613
Epoch 24/100, Batch 530/549, Loss: 2.3151
Epoch 24/100, Batch 540/549, Loss: 2.3202
New best model with validation loss: 2.1976, perplexity: 9.00
Epoch 24/100, Loss: 2.3771, Perplexity: 10.77, Val Loss: 2.1976, Val Perplexity: 9.00, Time: 1089.33s
Epoch 25/100, Batch 10/549, Loss: 2.3095
Epoch 25/100, Batch 20/549, Loss: 2.4257
Epoch 25/100, Batch 30/549, Loss: 2.4462
Epoch 25/100, Batch 40/549, Loss: 2.3995
Epoch 25/100, Batch 50/549, Loss: 2.3154
Epoch 25/100, Batch 60/549, Loss: 2.2686
Epoch 25/100, Batch 70/549, Loss: 2.3532
Epoch 25/100, Batch 80/549, Loss: 2.3334
Epoch 25/100, Batch 90/549, Loss: 2.3333
Epoch 25/100, Batch 100/549, Loss: 2.3958
Epoch 25/100, Batch 110/549, Loss: 2.4099
Epoch 25/100, Batch 120/549, Loss: 2.4236
Epoch 25/100, Batch 130/549, Loss: 2.3697
Epoch 25/100, Batch 140/549, Loss: 2.3413
Epoch 25/100, Batch 150/549, Loss: 2.4037
Epoch 25/100, Batch 160/549, Loss: 2.3911
Epoch 25/100, Batch 170/549, Loss: 2.3579
Epoch 25/100, Batch 180/549, Loss: 2.3586
Epoch 25/100, Batch 190/549, Loss: 2.2904
Epoch 25/100, Batch 200/549, Loss: 2.3490
Epoch 25/100, Batch 210/549, Loss: 2.3193
Epoch 25/100, Batch 220/549, Loss: 2.3210
Epoch 25/100, Batch 230/549, Loss: 2.3988
Epoch 25/100, Batch 240/549, Loss: 2.3307
Epoch 25/100, Batch 250/549, Loss: 2.2642
Epoch 25/100, Batch 260/549, Loss: 2.2757
Epoch 25/100, Batch 270/549, Loss: 2.3374
Epoch 25/100, Batch 280/549, Loss: 2.3326
Epoch 25/100, Batch 290/549, Loss: 2.3027
Epoch 25/100, Batch 300/549, Loss: 2.3914
Epoch 25/100, Batch 310/549, Loss: 2.4032
Epoch 25/100, Batch 320/549, Loss: 2.2720
Epoch 25/100, Batch 330/549, Loss: 2.2912
Epoch 25/100, Batch 340/549, Loss: 2.3191
Epoch 25/100, Batch 350/549, Loss: 2.3874
Epoch 25/100, Batch 360/549, Loss: 2.4234
Epoch 25/100, Batch 370/549, Loss: 2.2955
Epoch 25/100, Batch 380/549, Loss: 2.3852
Epoch 25/100, Batch 390/549, Loss: 2.3410
Epoch 25/100, Batch 400/549, Loss: 2.4075
Epoch 25/100, Batch 410/549, Loss: 2.3594
Epoch 25/100, Batch 420/549, Loss: 2.3661
Epoch 25/100, Batch 430/549, Loss: 2.4398
Epoch 25/100, Batch 440/549, Loss: 2.3702
Epoch 25/100, Batch 450/549, Loss: 2.3529
Epoch 25/100, Batch 460/549, Loss: 2.3504
Epoch 25/100, Batch 470/549, Loss: 2.3586
Epoch 25/100, Batch 480/549, Loss: 2.2969
Epoch 25/100, Batch 490/549, Loss: 2.3852
Epoch 25/100, Batch 500/549, Loss: 2.3465
Epoch 25/100, Batch 510/549, Loss: 2.3766
Epoch 25/100, Batch 520/549, Loss: 2.3020
Epoch 25/100, Batch 530/549, Loss: 2.3024
Epoch 25/100, Batch 540/549, Loss: 2.2825
New best model with validation loss: 2.1832, perplexity: 8.87
Epoch 25/100, Loss: 2.3597, Perplexity: 10.59, Val Loss: 2.1832, Val Perplexity: 8.87, Time: 1086.46s
Epoch 26/100, Batch 10/549, Loss: 2.2945
Epoch 26/100, Batch 20/549, Loss: 2.4090
Epoch 26/100, Batch 30/549, Loss: 2.4299
Epoch 26/100, Batch 40/549, Loss: 2.3523
Epoch 26/100, Batch 50/549, Loss: 2.2886
Epoch 26/100, Batch 60/549, Loss: 2.2440
Epoch 26/100, Batch 70/549, Loss: 2.4146
Epoch 26/100, Batch 80/549, Loss: 2.3241
Epoch 26/100, Batch 90/549, Loss: 2.3276
Epoch 26/100, Batch 100/549, Loss: 2.3874
Epoch 26/100, Batch 110/549, Loss: 2.3914
Epoch 26/100, Batch 120/549, Loss: 2.3899
Epoch 26/100, Batch 130/549, Loss: 2.3360
Epoch 26/100, Batch 140/549, Loss: 2.3107
Epoch 26/100, Batch 150/549, Loss: 2.3756
Epoch 26/100, Batch 160/549, Loss: 2.3503
Epoch 26/100, Batch 170/549, Loss: 2.3381
Epoch 26/100, Batch 180/549, Loss: 2.3401
Epoch 26/100, Batch 190/549, Loss: 2.2719
Epoch 26/100, Batch 200/549, Loss: 2.3201
Epoch 26/100, Batch 210/549, Loss: 2.3825
Epoch 26/100, Batch 220/549, Loss: 2.3023
Epoch 26/100, Batch 230/549, Loss: 2.3697
Epoch 26/100, Batch 240/549, Loss: 2.2537
Epoch 26/100, Batch 250/549, Loss: 2.2353
Epoch 26/100, Batch 260/549, Loss: 2.2612
Epoch 26/100, Batch 270/549, Loss: 2.3258
Epoch 26/100, Batch 280/549, Loss: 2.3061
Epoch 26/100, Batch 290/549, Loss: 2.2786
Epoch 26/100, Batch 300/549, Loss: 2.3815
Epoch 26/100, Batch 310/549, Loss: 2.3598
Epoch 26/100, Batch 320/549, Loss: 2.2488
Epoch 26/100, Batch 330/549, Loss: 2.2313
Epoch 26/100, Batch 340/549, Loss: 2.3029
Epoch 26/100, Batch 350/549, Loss: 2.3615
Epoch 26/100, Batch 360/549, Loss: 2.3791
Epoch 26/100, Batch 370/549, Loss: 2.2673
Epoch 26/100, Batch 380/549, Loss: 2.3497
Epoch 26/100, Batch 390/549, Loss: 2.3170
Epoch 26/100, Batch 400/549, Loss: 2.3948
Epoch 26/100, Batch 410/549, Loss: 2.3364
Epoch 26/100, Batch 420/549, Loss: 2.3400
Epoch 26/100, Batch 430/549, Loss: 2.4937
Epoch 26/100, Batch 440/549, Loss: 2.3668
Epoch 26/100, Batch 450/549, Loss: 2.3695
Epoch 26/100, Batch 460/549, Loss: 2.3357
Epoch 26/100, Batch 470/549, Loss: 2.3091
Epoch 26/100, Batch 480/549, Loss: 2.2895
Epoch 26/100, Batch 490/549, Loss: 2.3623
Epoch 26/100, Batch 500/549, Loss: 2.3343
Epoch 26/100, Batch 510/549, Loss: 2.3597
Epoch 26/100, Batch 520/549, Loss: 2.2863
Epoch 26/100, Batch 530/549, Loss: 2.2917
Epoch 26/100, Batch 540/549, Loss: 2.2813
New best model with validation loss: 2.1663, perplexity: 8.73
Epoch 26/100, Loss: 2.3412, Perplexity: 10.39, Val Loss: 2.1663, Val Perplexity: 8.73, Time: 1088.45s
Epoch 27/100, Batch 10/549, Loss: 2.2756
Epoch 27/100, Batch 20/549, Loss: 2.4733
Epoch 27/100, Batch 30/549, Loss: 2.4080
Epoch 27/100, Batch 40/549, Loss: 2.3357
Epoch 27/100, Batch 50/549, Loss: 2.2757
Epoch 27/100, Batch 60/549, Loss: 2.2356
Epoch 27/100, Batch 70/549, Loss: 2.3179
Epoch 27/100, Batch 80/549, Loss: 2.2993
Epoch 27/100, Batch 90/549, Loss: 2.3134
Epoch 27/100, Batch 100/549, Loss: 2.3885
Epoch 27/100, Batch 110/549, Loss: 2.3822
Epoch 27/100, Batch 120/549, Loss: 2.4074
Epoch 27/100, Batch 130/549, Loss: 2.3092
Epoch 27/100, Batch 140/549, Loss: 2.2938
Epoch 27/100, Batch 150/549, Loss: 2.3708
Epoch 27/100, Batch 160/549, Loss: 2.3269
Epoch 27/100, Batch 170/549, Loss: 2.3287
Epoch 27/100, Batch 180/549, Loss: 2.3548
Epoch 27/100, Batch 190/549, Loss: 2.2850
Epoch 27/100, Batch 200/549, Loss: 2.3028
Epoch 27/100, Batch 210/549, Loss: 2.2737
Epoch 27/100, Batch 220/549, Loss: 2.2809
Epoch 27/100, Batch 230/549, Loss: 2.3608
Epoch 27/100, Batch 240/549, Loss: 2.2305
Epoch 27/100, Batch 250/549, Loss: 2.2299
Epoch 27/100, Batch 260/549, Loss: 2.2402
Epoch 27/100, Batch 270/549, Loss: 2.3143
Epoch 27/100, Batch 280/549, Loss: 2.3062
Epoch 27/100, Batch 290/549, Loss: 2.2674
Epoch 27/100, Batch 300/549, Loss: 2.3603
Epoch 27/100, Batch 310/549, Loss: 2.3333
Epoch 27/100, Batch 320/549, Loss: 2.2413
Epoch 27/100, Batch 330/549, Loss: 2.2222
Epoch 27/100, Batch 340/549, Loss: 2.2927
Epoch 27/100, Batch 350/549, Loss: 2.3493
Epoch 27/100, Batch 360/549, Loss: 2.3516
Epoch 27/100, Batch 370/549, Loss: 2.2637
Epoch 27/100, Batch 380/549, Loss: 2.3489
Epoch 27/100, Batch 390/549, Loss: 2.3127
Epoch 27/100, Batch 400/549, Loss: 2.3778
Epoch 27/100, Batch 410/549, Loss: 2.3183
Epoch 27/100, Batch 420/549, Loss: 2.3160
Epoch 27/100, Batch 430/549, Loss: 2.4131
Epoch 27/100, Batch 440/549, Loss: 2.3295
Epoch 27/100, Batch 450/549, Loss: 2.3326
Epoch 27/100, Batch 460/549, Loss: 2.3683
Epoch 27/100, Batch 470/549, Loss: 2.2867
Epoch 27/100, Batch 480/549, Loss: 2.3460
Epoch 27/100, Batch 490/549, Loss: 2.3560
Epoch 27/100, Batch 500/549, Loss: 2.2791
Epoch 27/100, Batch 510/549, Loss: 2.3555
Epoch 27/100, Batch 520/549, Loss: 2.2748
Epoch 27/100, Batch 530/549, Loss: 2.2685
Epoch 27/100, Batch 540/549, Loss: 2.2601
New best model with validation loss: 2.1602, perplexity: 8.67
Epoch 27/100, Loss: 2.3259, Perplexity: 10.24, Val Loss: 2.1602, Val Perplexity: 8.67, Time: 1089.17s
Epoch 28/100, Batch 10/549, Loss: 2.3314
Epoch 28/100, Batch 20/549, Loss: 2.3826
Epoch 28/100, Batch 30/549, Loss: 2.4192
Epoch 28/100, Batch 40/549, Loss: 2.3184
Epoch 28/100, Batch 50/549, Loss: 2.2617
Epoch 28/100, Batch 60/549, Loss: 2.2056
Epoch 28/100, Batch 70/549, Loss: 2.3068
Epoch 28/100, Batch 80/549, Loss: 2.2874
Epoch 28/100, Batch 90/549, Loss: 2.2890
Epoch 28/100, Batch 100/549, Loss: 2.3596
Epoch 28/100, Batch 110/549, Loss: 2.3606
Epoch 28/100, Batch 120/549, Loss: 2.3723
Epoch 28/100, Batch 130/549, Loss: 2.3020
Epoch 28/100, Batch 140/549, Loss: 2.2796
Epoch 28/100, Batch 150/549, Loss: 2.3655
Epoch 28/100, Batch 160/549, Loss: 2.3285
Epoch 28/100, Batch 170/549, Loss: 2.3176
Epoch 28/100, Batch 180/549, Loss: 2.3079
Epoch 28/100, Batch 190/549, Loss: 2.2665
Epoch 28/100, Batch 200/549, Loss: 2.2865
Epoch 28/100, Batch 210/549, Loss: 2.2624
Epoch 28/100, Batch 220/549, Loss: 2.2650
Epoch 28/100, Batch 230/549, Loss: 2.3381
Epoch 28/100, Batch 240/549, Loss: 2.2145
Epoch 28/100, Batch 250/549, Loss: 2.2131
Epoch 28/100, Batch 260/549, Loss: 2.2325
Epoch 28/100, Batch 270/549, Loss: 2.3394
Epoch 28/100, Batch 280/549, Loss: 2.2917
Epoch 28/100, Batch 290/549, Loss: 2.2478
Epoch 28/100, Batch 300/549, Loss: 2.3531
Epoch 28/100, Batch 310/549, Loss: 2.3507
Epoch 28/100, Batch 320/549, Loss: 2.2095
Epoch 28/100, Batch 330/549, Loss: 2.2351
Epoch 28/100, Batch 340/549, Loss: 2.3396
Epoch 28/100, Batch 350/549, Loss: 2.3430
Epoch 28/100, Batch 360/549, Loss: 2.3454
Epoch 28/100, Batch 370/549, Loss: 2.2536
Epoch 28/100, Batch 380/549, Loss: 2.3279
Epoch 28/100, Batch 390/549, Loss: 2.3201
Epoch 28/100, Batch 400/549, Loss: 2.3769
Epoch 28/100, Batch 410/549, Loss: 2.3081
Epoch 28/100, Batch 420/549, Loss: 2.3030
Epoch 28/100, Batch 430/549, Loss: 2.3883
Epoch 28/100, Batch 440/549, Loss: 2.3080
Epoch 28/100, Batch 450/549, Loss: 2.3208
Epoch 28/100, Batch 460/549, Loss: 2.3002
Epoch 28/100, Batch 470/549, Loss: 2.3200
Epoch 28/100, Batch 480/549, Loss: 2.2809
Epoch 28/100, Batch 490/549, Loss: 2.3579
Epoch 28/100, Batch 500/549, Loss: 2.2712
Epoch 28/100, Batch 510/549, Loss: 2.3229
Epoch 28/100, Batch 520/549, Loss: 2.2600
Epoch 28/100, Batch 530/549, Loss: 2.2599
Epoch 28/100, Batch 540/549, Loss: 2.2417
New best model with validation loss: 2.1518, perplexity: 8.60
Epoch 28/100, Loss: 2.3110, Perplexity: 10.08, Val Loss: 2.1518, Val Perplexity: 8.60, Time: 1087.18s
Epoch 29/100, Batch 10/549, Loss: 2.2425
Epoch 29/100, Batch 20/549, Loss: 2.3618
Epoch 29/100, Batch 30/549, Loss: 2.3753
Epoch 29/100, Batch 40/549, Loss: 2.3050
Epoch 29/100, Batch 50/549, Loss: 2.2510
Epoch 29/100, Batch 60/549, Loss: 2.2088
Epoch 29/100, Batch 70/549, Loss: 2.3000
Epoch 29/100, Batch 80/549, Loss: 2.2823
Epoch 29/100, Batch 90/549, Loss: 2.2831
Epoch 29/100, Batch 100/549, Loss: 2.3659
Epoch 29/100, Batch 110/549, Loss: 2.3536
Epoch 29/100, Batch 120/549, Loss: 2.3603
Epoch 29/100, Batch 130/549, Loss: 2.2925
Epoch 29/100, Batch 140/549, Loss: 2.2758
Epoch 29/100, Batch 150/549, Loss: 2.3484
Epoch 29/100, Batch 160/549, Loss: 2.2989
Epoch 29/100, Batch 170/549, Loss: 2.3453
Epoch 29/100, Batch 180/549, Loss: 2.2889
Epoch 29/100, Batch 190/549, Loss: 2.2345
Epoch 29/100, Batch 200/549, Loss: 2.3057
Epoch 29/100, Batch 210/549, Loss: 2.2545
Epoch 29/100, Batch 220/549, Loss: 2.2576
Epoch 29/100, Batch 230/549, Loss: 2.3079
Epoch 29/100, Batch 240/549, Loss: 2.2032
Epoch 29/100, Batch 250/549, Loss: 2.2392
Epoch 29/100, Batch 260/549, Loss: 2.2107
Epoch 29/100, Batch 270/549, Loss: 2.2730
Epoch 29/100, Batch 280/549, Loss: 2.2656
Epoch 29/100, Batch 290/549, Loss: 2.2302
Epoch 29/100, Batch 300/549, Loss: 2.3409
Epoch 29/100, Batch 310/549, Loss: 2.3047
Epoch 29/100, Batch 320/549, Loss: 2.2101
Epoch 29/100, Batch 330/549, Loss: 2.2098
Epoch 29/100, Batch 340/549, Loss: 2.2436
Epoch 29/100, Batch 350/549, Loss: 2.3169
Epoch 29/100, Batch 360/549, Loss: 2.3489
Epoch 29/100, Batch 370/549, Loss: 2.2999
Epoch 29/100, Batch 380/549, Loss: 2.3160
Epoch 29/100, Batch 390/549, Loss: 2.2793
Epoch 29/100, Batch 400/549, Loss: 2.3507
Epoch 29/100, Batch 410/549, Loss: 2.2999
Epoch 29/100, Batch 420/549, Loss: 2.2851
Epoch 29/100, Batch 430/549, Loss: 2.3992
Epoch 29/100, Batch 440/549, Loss: 2.3082
Epoch 29/100, Batch 450/549, Loss: 2.3777
Epoch 29/100, Batch 460/549, Loss: 2.2906
Epoch 29/100, Batch 470/549, Loss: 2.2619
Epoch 29/100, Batch 480/549, Loss: 2.2505
Epoch 29/100, Batch 490/549, Loss: 2.3497
Epoch 29/100, Batch 500/549, Loss: 2.2920
Epoch 29/100, Batch 510/549, Loss: 2.3130
Epoch 29/100, Batch 520/549, Loss: 2.2533
Epoch 29/100, Batch 530/549, Loss: 2.2568
Epoch 29/100, Batch 540/549, Loss: 2.2275
New best model with validation loss: 2.1466, perplexity: 8.56
Epoch 29/100, Loss: 2.2991, Perplexity: 9.97, Val Loss: 2.1466, Val Perplexity: 8.56, Time: 1089.68s
Epoch 30/100, Batch 10/549, Loss: 2.2468
Epoch 30/100, Batch 20/549, Loss: 2.3463
Epoch 30/100, Batch 30/549, Loss: 2.3571
Epoch 30/100, Batch 40/549, Loss: 2.2997
Epoch 30/100, Batch 50/549, Loss: 2.2525
Epoch 30/100, Batch 60/549, Loss: 2.2667
Epoch 30/100, Batch 70/549, Loss: 2.2736
Epoch 30/100, Batch 80/549, Loss: 2.2863
Epoch 30/100, Batch 90/549, Loss: 2.3255
Epoch 30/100, Batch 100/549, Loss: 2.3400
Epoch 30/100, Batch 110/549, Loss: 2.3400
Epoch 30/100, Batch 120/549, Loss: 2.3467
Epoch 30/100, Batch 130/549, Loss: 2.2831
Epoch 30/100, Batch 140/549, Loss: 2.2464
Epoch 30/100, Batch 150/549, Loss: 2.3250
Epoch 30/100, Batch 160/549, Loss: 2.2876
Epoch 30/100, Batch 170/549, Loss: 2.3018
Epoch 30/100, Batch 180/549, Loss: 2.2866
Epoch 30/100, Batch 190/549, Loss: 2.3002
Epoch 30/100, Batch 200/549, Loss: 2.2778
Epoch 30/100, Batch 210/549, Loss: 2.2479
Epoch 30/100, Batch 220/549, Loss: 2.2542
Epoch 30/100, Batch 230/549, Loss: 2.3191
Epoch 30/100, Batch 240/549, Loss: 2.1996
Epoch 30/100, Batch 250/549, Loss: 2.1786
Epoch 30/100, Batch 260/549, Loss: 2.1980
Epoch 30/100, Batch 270/549, Loss: 2.2613
Epoch 30/100, Batch 280/549, Loss: 2.2494
Epoch 30/100, Batch 290/549, Loss: 2.2260
Epoch 30/100, Batch 300/549, Loss: 2.3296
Epoch 30/100, Batch 310/549, Loss: 2.3012
Epoch 30/100, Batch 320/549, Loss: 2.2083
Epoch 30/100, Batch 330/549, Loss: 2.1914
Epoch 30/100, Batch 340/549, Loss: 2.2425
Epoch 30/100, Batch 350/549, Loss: 2.3340
Epoch 30/100, Batch 360/549, Loss: 2.3143
Epoch 30/100, Batch 370/549, Loss: 2.2148
Epoch 30/100, Batch 380/549, Loss: 2.2990
Epoch 30/100, Batch 390/549, Loss: 2.2772
Epoch 30/100, Batch 400/549, Loss: 2.3231
Epoch 30/100, Batch 410/549, Loss: 2.3264
Epoch 30/100, Batch 420/549, Loss: 2.2899
Epoch 30/100, Batch 430/549, Loss: 2.3881
Epoch 30/100, Batch 440/549, Loss: 2.2893
Epoch 30/100, Batch 450/549, Loss: 2.2862
Epoch 30/100, Batch 460/549, Loss: 2.2747
Epoch 30/100, Batch 470/549, Loss: 2.3077
Epoch 30/100, Batch 480/549, Loss: 2.2519
Epoch 30/100, Batch 490/549, Loss: 2.3148
Epoch 30/100, Batch 500/549, Loss: 2.2488
Epoch 30/100, Batch 510/549, Loss: 2.3072
Epoch 30/100, Batch 520/549, Loss: 2.2375
Epoch 30/100, Batch 530/549, Loss: 2.2537
Epoch 30/100, Batch 540/549, Loss: 2.3279
New best model with validation loss: 2.1412, perplexity: 8.51
Epoch 30/100, Loss: 2.2869, Perplexity: 9.84, Val Loss: 2.1412, Val Perplexity: 8.51, Time: 1088.40s
Epoch 31/100, Batch 10/549, Loss: 2.2428
Epoch 31/100, Batch 20/549, Loss: 2.3318
Epoch 31/100, Batch 30/549, Loss: 2.3507
Epoch 31/100, Batch 40/549, Loss: 2.2790
Epoch 31/100, Batch 50/549, Loss: 2.2129
Epoch 31/100, Batch 60/549, Loss: 2.2294
Epoch 31/100, Batch 70/549, Loss: 2.2807
Epoch 31/100, Batch 80/549, Loss: 2.3098
Epoch 31/100, Batch 90/549, Loss: 2.2571
Epoch 31/100, Batch 100/549, Loss: 2.3219
Epoch 31/100, Batch 110/549, Loss: 2.3197
Epoch 31/100, Batch 120/549, Loss: 2.3365
Epoch 31/100, Batch 130/549, Loss: 2.2574
Epoch 31/100, Batch 140/549, Loss: 2.2360
Epoch 31/100, Batch 150/549, Loss: 2.3179
Epoch 31/100, Batch 160/549, Loss: 2.2839
Epoch 31/100, Batch 170/549, Loss: 2.2890
Epoch 31/100, Batch 180/549, Loss: 2.3279
Epoch 31/100, Batch 190/549, Loss: 2.2409
Epoch 31/100, Batch 200/549, Loss: 2.2807
Epoch 31/100, Batch 210/549, Loss: 2.2271
Epoch 31/100, Batch 220/549, Loss: 2.2382
Epoch 31/100, Batch 230/549, Loss: 2.2959
Epoch 31/100, Batch 240/549, Loss: 2.1975
Epoch 31/100, Batch 250/549, Loss: 2.1709
Epoch 31/100, Batch 260/549, Loss: 2.2050
Epoch 31/100, Batch 270/549, Loss: 2.2676
Epoch 31/100, Batch 280/549, Loss: 2.2484
Epoch 31/100, Batch 290/549, Loss: 2.2651
Epoch 31/100, Batch 300/549, Loss: 2.3260
Epoch 31/100, Batch 310/549, Loss: 2.2962
Epoch 31/100, Batch 320/549, Loss: 2.1886
Epoch 31/100, Batch 330/549, Loss: 2.2356
Epoch 31/100, Batch 340/549, Loss: 2.2471
Epoch 31/100, Batch 350/549, Loss: 2.3044
Epoch 31/100, Batch 360/549, Loss: 2.3085
Epoch 31/100, Batch 370/549, Loss: 2.2131
Epoch 31/100, Batch 380/549, Loss: 2.2899
Epoch 31/100, Batch 390/549, Loss: 2.2554
Epoch 31/100, Batch 400/549, Loss: 2.3342
Epoch 31/100, Batch 410/549, Loss: 2.2660
Epoch 31/100, Batch 420/549, Loss: 2.2669
Epoch 31/100, Batch 430/549, Loss: 2.3710
Epoch 31/100, Batch 440/549, Loss: 2.2947
Epoch 31/100, Batch 450/549, Loss: 2.2920
Epoch 31/100, Batch 460/549, Loss: 2.2629
Epoch 31/100, Batch 470/549, Loss: 2.2394
Epoch 31/100, Batch 480/549, Loss: 2.2223
Epoch 31/100, Batch 490/549, Loss: 2.3068
Epoch 31/100, Batch 500/549, Loss: 2.2399
Epoch 31/100, Batch 510/549, Loss: 2.2793
Epoch 31/100, Batch 520/549, Loss: 2.2472
Epoch 31/100, Batch 530/549, Loss: 2.2151
Epoch 31/100, Batch 540/549, Loss: 2.2182
New best model with validation loss: 2.1320, perplexity: 8.43
Epoch 31/100, Loss: 2.2754, Perplexity: 9.73, Val Loss: 2.1320, Val Perplexity: 8.43, Time: 1090.30s
Epoch 32/100, Batch 10/549, Loss: 2.2031
Epoch 32/100, Batch 20/549, Loss: 2.3498
Epoch 32/100, Batch 30/549, Loss: 2.3401
Epoch 32/100, Batch 40/549, Loss: 2.2995
Epoch 32/100, Batch 50/549, Loss: 2.2046
Epoch 32/100, Batch 60/549, Loss: 2.1625
Epoch 32/100, Batch 70/549, Loss: 2.2608
Epoch 32/100, Batch 80/549, Loss: 2.2406
Epoch 32/100, Batch 90/549, Loss: 2.3003
Epoch 32/100, Batch 100/549, Loss: 2.3262
Epoch 32/100, Batch 110/549, Loss: 2.3207
Epoch 32/100, Batch 120/549, Loss: 2.3238
Epoch 32/100, Batch 130/549, Loss: 2.2391
Epoch 32/100, Batch 140/549, Loss: 2.2383
Epoch 32/100, Batch 150/549, Loss: 2.3117
Epoch 32/100, Batch 160/549, Loss: 2.2645
Epoch 32/100, Batch 170/549, Loss: 2.2584
Epoch 32/100, Batch 180/549, Loss: 2.2683
Epoch 32/100, Batch 190/549, Loss: 2.1942
Epoch 32/100, Batch 200/549, Loss: 2.2554
Epoch 32/100, Batch 210/549, Loss: 2.2281
Epoch 32/100, Batch 220/549, Loss: 2.2412
Epoch 32/100, Batch 230/549, Loss: 2.3155
Epoch 32/100, Batch 240/549, Loss: 2.1835
Epoch 32/100, Batch 250/549, Loss: 2.1633
Epoch 32/100, Batch 260/549, Loss: 2.2004
Epoch 32/100, Batch 270/549, Loss: 2.2385
Epoch 32/100, Batch 280/549, Loss: 2.2344
Epoch 32/100, Batch 290/549, Loss: 2.1934
Epoch 32/100, Batch 300/549, Loss: 2.2894
Epoch 32/100, Batch 310/549, Loss: 2.2663
Epoch 32/100, Batch 320/549, Loss: 2.1685
Epoch 32/100, Batch 330/549, Loss: 2.1634
Epoch 32/100, Batch 340/549, Loss: 2.2290
Epoch 32/100, Batch 350/549, Loss: 2.3285
Epoch 32/100, Batch 360/549, Loss: 2.3157
Epoch 32/100, Batch 370/549, Loss: 2.1999
Epoch 32/100, Batch 380/549, Loss: 2.3117
Epoch 32/100, Batch 390/549, Loss: 2.2709
Epoch 32/100, Batch 400/549, Loss: 2.3757
Epoch 32/100, Batch 410/549, Loss: 2.2605
Epoch 32/100, Batch 420/549, Loss: 2.2509
Epoch 32/100, Batch 430/549, Loss: 2.3767
Epoch 32/100, Batch 440/549, Loss: 2.2657
Epoch 32/100, Batch 450/549, Loss: 2.2724
Epoch 32/100, Batch 460/549, Loss: 2.2591
Epoch 32/100, Batch 470/549, Loss: 2.2476
Epoch 32/100, Batch 480/549, Loss: 2.3082
Epoch 32/100, Batch 490/549, Loss: 2.2949
Epoch 32/100, Batch 500/549, Loss: 2.2297
Epoch 32/100, Batch 510/549, Loss: 2.2714
Epoch 32/100, Batch 520/549, Loss: 2.2100
Epoch 32/100, Batch 530/549, Loss: 2.2085
Epoch 32/100, Batch 540/549, Loss: 2.2654
New best model with validation loss: 2.1236, perplexity: 8.36
Epoch 32/100, Loss: 2.2644, Perplexity: 9.63, Val Loss: 2.1236, Val Perplexity: 8.36, Time: 1089.72s
Epoch 33/100, Batch 10/549, Loss: 2.2559
Epoch 33/100, Batch 20/549, Loss: 2.3174
Epoch 33/100, Batch 30/549, Loss: 2.3376
Epoch 33/100, Batch 40/549, Loss: 2.2684
Epoch 33/100, Batch 50/549, Loss: 2.2016
Epoch 33/100, Batch 60/549, Loss: 2.1532
Epoch 33/100, Batch 70/549, Loss: 2.2479
Epoch 33/100, Batch 80/549, Loss: 2.2373
Epoch 33/100, Batch 90/549, Loss: 2.2244
Epoch 33/100, Batch 100/549, Loss: 2.3088
Epoch 33/100, Batch 110/549, Loss: 2.3131
Epoch 33/100, Batch 120/549, Loss: 2.3055
Epoch 33/100, Batch 130/549, Loss: 2.2320
Epoch 33/100, Batch 140/549, Loss: 2.2121
Epoch 33/100, Batch 150/549, Loss: 2.3073
Epoch 33/100, Batch 160/549, Loss: 2.2599
Epoch 33/100, Batch 170/549, Loss: 2.2485
Epoch 33/100, Batch 180/549, Loss: 2.2419
Epoch 33/100, Batch 190/549, Loss: 2.2372
Epoch 33/100, Batch 200/549, Loss: 2.2778
Epoch 33/100, Batch 210/549, Loss: 2.2094
Epoch 33/100, Batch 220/549, Loss: 2.2715
Epoch 33/100, Batch 230/549, Loss: 2.2627
Epoch 33/100, Batch 240/549, Loss: 2.1512
Epoch 33/100, Batch 250/549, Loss: 2.1598
Epoch 33/100, Batch 260/549, Loss: 2.1649
Epoch 33/100, Batch 270/549, Loss: 2.2362
Epoch 33/100, Batch 280/549, Loss: 2.2282
Epoch 33/100, Batch 290/549, Loss: 2.1989
Epoch 33/100, Batch 300/549, Loss: 2.2870
Epoch 33/100, Batch 310/549, Loss: 2.2609
Epoch 33/100, Batch 320/549, Loss: 2.1622
Epoch 33/100, Batch 330/549, Loss: 2.1467
Epoch 33/100, Batch 340/549, Loss: 2.2165
Epoch 33/100, Batch 350/549, Loss: 2.2798
Epoch 33/100, Batch 360/549, Loss: 2.2916
Epoch 33/100, Batch 370/549, Loss: 2.1910
Epoch 33/100, Batch 380/549, Loss: 2.2829
Epoch 33/100, Batch 390/549, Loss: 2.2396
Epoch 33/100, Batch 400/549, Loss: 2.3490
Epoch 33/100, Batch 410/549, Loss: 2.2460
Epoch 33/100, Batch 420/549, Loss: 2.2523
Epoch 33/100, Batch 430/549, Loss: 2.3454
Epoch 33/100, Batch 440/549, Loss: 2.2602
Epoch 33/100, Batch 450/549, Loss: 2.2654
Epoch 33/100, Batch 460/549, Loss: 2.2499
Epoch 33/100, Batch 470/549, Loss: 2.2656
Epoch 33/100, Batch 480/549, Loss: 2.2107
Epoch 33/100, Batch 490/549, Loss: 2.2976
Epoch 33/100, Batch 500/549, Loss: 2.2179
Epoch 33/100, Batch 510/549, Loss: 2.2693
Epoch 33/100, Batch 520/549, Loss: 2.2021
Epoch 33/100, Batch 530/549, Loss: 2.2024
Epoch 33/100, Batch 540/549, Loss: 2.1810
New best model with validation loss: 2.1137, perplexity: 8.28
Epoch 33/100, Loss: 2.2541, Perplexity: 9.53, Val Loss: 2.1137, Val Perplexity: 8.28, Time: 1089.92s
Epoch 34/100, Batch 10/549, Loss: 2.1871
Epoch 34/100, Batch 20/549, Loss: 2.3090
Epoch 34/100, Batch 30/549, Loss: 2.3088
Epoch 34/100, Batch 40/549, Loss: 2.3093
Epoch 34/100, Batch 50/549, Loss: 2.2234
Epoch 34/100, Batch 60/549, Loss: 2.1430
Epoch 34/100, Batch 70/549, Loss: 2.2338
Epoch 34/100, Batch 80/549, Loss: 2.2265
Epoch 34/100, Batch 90/549, Loss: 2.2198
Epoch 34/100, Batch 100/549, Loss: 2.3023
Epoch 34/100, Batch 110/549, Loss: 2.2896
Epoch 34/100, Batch 120/549, Loss: 2.3379
Epoch 34/100, Batch 130/549, Loss: 2.2262
Epoch 34/100, Batch 140/549, Loss: 2.2033
Epoch 34/100, Batch 150/549, Loss: 2.2783
Epoch 34/100, Batch 160/549, Loss: 2.2472
Epoch 34/100, Batch 170/549, Loss: 2.2464
Epoch 34/100, Batch 180/549, Loss: 2.2348
Epoch 34/100, Batch 190/549, Loss: 2.1900
Epoch 34/100, Batch 200/549, Loss: 2.2483
Epoch 34/100, Batch 210/549, Loss: 2.2105
Epoch 34/100, Batch 220/549, Loss: 2.2290
Epoch 34/100, Batch 230/549, Loss: 2.2903
Epoch 34/100, Batch 240/549, Loss: 2.1456
Epoch 34/100, Batch 250/549, Loss: 2.1461
Epoch 34/100, Batch 260/549, Loss: 2.1426
Epoch 34/100, Batch 270/549, Loss: 2.2099
Epoch 34/100, Batch 280/549, Loss: 2.2135
Epoch 34/100, Batch 290/549, Loss: 2.1921
Epoch 34/100, Batch 300/549, Loss: 2.2955
Epoch 34/100, Batch 310/549, Loss: 2.2480
Epoch 34/100, Batch 320/549, Loss: 2.1458
Epoch 34/100, Batch 330/549, Loss: 2.1814
Epoch 34/100, Batch 340/549, Loss: 2.2154
Epoch 34/100, Batch 350/549, Loss: 2.2791
Epoch 34/100, Batch 360/549, Loss: 2.2831
Epoch 34/100, Batch 370/549, Loss: 2.1764
Epoch 34/100, Batch 380/549, Loss: 2.2548
Epoch 34/100, Batch 390/549, Loss: 2.2683
Epoch 34/100, Batch 400/549, Loss: 2.2849
Epoch 34/100, Batch 410/549, Loss: 2.2781
Epoch 34/100, Batch 420/549, Loss: 2.2600
Epoch 34/100, Batch 430/549, Loss: 2.3516
Epoch 34/100, Batch 440/549, Loss: 2.2561
Epoch 34/100, Batch 450/549, Loss: 2.2597
Epoch 34/100, Batch 460/549, Loss: 2.2453
Epoch 34/100, Batch 470/549, Loss: 2.2081
Epoch 34/100, Batch 480/549, Loss: 2.2174
Epoch 34/100, Batch 490/549, Loss: 2.2838
Epoch 34/100, Batch 500/549, Loss: 2.2116
Epoch 34/100, Batch 510/549, Loss: 2.3155
Epoch 34/100, Batch 520/549, Loss: 2.1939
Epoch 34/100, Batch 530/549, Loss: 2.1923
Epoch 34/100, Batch 540/549, Loss: 2.1779
Epoch 34/100, Loss: 2.2463, Perplexity: 9.45, Val Loss: 2.1138, Val Perplexity: 8.28, Time: 1083.21s
Epoch 35/100, Batch 10/549, Loss: 2.1953
Epoch 35/100, Batch 20/549, Loss: 2.3164
Epoch 35/100, Batch 30/549, Loss: 2.3080
Epoch 35/100, Batch 40/549, Loss: 2.2354
Epoch 35/100, Batch 50/549, Loss: 2.1936
Epoch 35/100, Batch 60/549, Loss: 2.1393
Epoch 35/100, Batch 70/549, Loss: 2.2587
Epoch 35/100, Batch 80/549, Loss: 2.2103
Epoch 35/100, Batch 90/549, Loss: 2.2483
Epoch 35/100, Batch 100/549, Loss: 2.2809
Epoch 35/100, Batch 110/549, Loss: 2.2859
Epoch 35/100, Batch 120/549, Loss: 2.2962
Epoch 35/100, Batch 130/549, Loss: 2.2073
Epoch 35/100, Batch 140/549, Loss: 2.1942
Epoch 35/100, Batch 150/549, Loss: 2.2748
Epoch 35/100, Batch 160/549, Loss: 2.2478
Epoch 35/100, Batch 170/549, Loss: 2.2323
Epoch 35/100, Batch 180/549, Loss: 2.2173
Epoch 35/100, Batch 190/549, Loss: 2.1630
Epoch 35/100, Batch 200/549, Loss: 2.2308
Epoch 35/100, Batch 210/549, Loss: 2.1887
Epoch 35/100, Batch 220/549, Loss: 2.1930
Epoch 35/100, Batch 230/549, Loss: 2.2574
Epoch 35/100, Batch 240/549, Loss: 2.1383
Epoch 35/100, Batch 250/549, Loss: 2.1432
Epoch 35/100, Batch 260/549, Loss: 2.1497
Epoch 35/100, Batch 270/549, Loss: 2.2136
Epoch 35/100, Batch 280/549, Loss: 2.2069
Epoch 35/100, Batch 290/549, Loss: 2.1726
Epoch 35/100, Batch 300/549, Loss: 2.2618
Epoch 35/100, Batch 310/549, Loss: 2.2582
Epoch 35/100, Batch 320/549, Loss: 2.2614
Epoch 35/100, Batch 330/549, Loss: 2.1364
Epoch 35/100, Batch 340/549, Loss: 2.2225
Epoch 35/100, Batch 350/549, Loss: 2.2648
Epoch 35/100, Batch 360/549, Loss: 2.2744
Epoch 35/100, Batch 370/549, Loss: 2.1761
Epoch 35/100, Batch 380/549, Loss: 2.2558
Epoch 35/100, Batch 390/549, Loss: 2.2201
Epoch 35/100, Batch 400/549, Loss: 2.3048
Epoch 35/100, Batch 410/549, Loss: 2.2230
Epoch 35/100, Batch 420/549, Loss: 2.2299
Epoch 35/100, Batch 430/549, Loss: 2.3303
Epoch 35/100, Batch 440/549, Loss: 2.2546
Epoch 35/100, Batch 450/549, Loss: 2.2572
Epoch 35/100, Batch 460/549, Loss: 2.2682
Epoch 35/100, Batch 470/549, Loss: 2.2669
Epoch 35/100, Batch 480/549, Loss: 2.1952
Epoch 35/100, Batch 490/549, Loss: 2.2696
Epoch 35/100, Batch 500/549, Loss: 2.2040
Epoch 35/100, Batch 510/549, Loss: 2.2506
Epoch 35/100, Batch 520/549, Loss: 2.1814
Epoch 35/100, Batch 530/549, Loss: 2.1809
Epoch 35/100, Batch 540/549, Loss: 2.1685
New best model with validation loss: 2.1083, perplexity: 8.23
Epoch 35/100, Loss: 2.2364, Perplexity: 9.36, Val Loss: 2.1083, Val Perplexity: 8.23, Time: 1086.23s
Epoch 36/100, Batch 10/549, Loss: 2.1720
Epoch 36/100, Batch 20/549, Loss: 2.2811
Epoch 36/100, Batch 30/549, Loss: 2.2993
Epoch 36/100, Batch 40/549, Loss: 2.2332
Epoch 36/100, Batch 50/549, Loss: 2.1769
Epoch 36/100, Batch 60/549, Loss: 2.1268
Epoch 36/100, Batch 70/549, Loss: 2.2085
Epoch 36/100, Batch 80/549, Loss: 2.2044
Epoch 36/100, Batch 90/549, Loss: 2.2101
Epoch 36/100, Batch 100/549, Loss: 2.2697
Epoch 36/100, Batch 110/549, Loss: 2.3173
Epoch 36/100, Batch 120/549, Loss: 2.2873
Epoch 36/100, Batch 130/549, Loss: 2.2177
Epoch 36/100, Batch 140/549, Loss: 2.2333
Epoch 36/100, Batch 150/549, Loss: 2.2749
Epoch 36/100, Batch 160/549, Loss: 2.2271
Epoch 36/100, Batch 170/549, Loss: 2.2499
Epoch 36/100, Batch 180/549, Loss: 2.2649
Epoch 36/100, Batch 190/549, Loss: 2.1625
Epoch 36/100, Batch 200/549, Loss: 2.2195
Epoch 36/100, Batch 210/549, Loss: 2.1681
Epoch 36/100, Batch 220/549, Loss: 2.1883
Epoch 36/100, Batch 230/549, Loss: 2.2607
Epoch 36/100, Batch 240/549, Loss: 2.1465
Epoch 36/100, Batch 250/549, Loss: 2.1356
Epoch 36/100, Batch 260/549, Loss: 2.1460
Epoch 36/100, Batch 270/549, Loss: 2.2007
Epoch 36/100, Batch 280/549, Loss: 2.2226
Epoch 36/100, Batch 290/549, Loss: 2.1629
Epoch 36/100, Batch 300/549, Loss: 2.2915
Epoch 36/100, Batch 310/549, Loss: 2.2485
Epoch 36/100, Batch 320/549, Loss: 2.1529
Epoch 36/100, Batch 330/549, Loss: 2.1266
Epoch 36/100, Batch 340/549, Loss: 2.1929
Epoch 36/100, Batch 350/549, Loss: 2.2478
Epoch 36/100, Batch 360/549, Loss: 2.2968
Epoch 36/100, Batch 370/549, Loss: 2.1655
Epoch 36/100, Batch 380/549, Loss: 2.2308
Epoch 36/100, Batch 390/549, Loss: 2.2078
Epoch 36/100, Batch 400/549, Loss: 2.2635
Epoch 36/100, Batch 410/549, Loss: 2.2583
Epoch 36/100, Batch 420/549, Loss: 2.2249
Epoch 36/100, Batch 430/549, Loss: 2.3126
Epoch 36/100, Batch 440/549, Loss: 2.2408
Epoch 36/100, Batch 450/549, Loss: 2.2556
Epoch 36/100, Batch 460/549, Loss: 2.2456
Epoch 36/100, Batch 470/549, Loss: 2.1887
Epoch 36/100, Batch 480/549, Loss: 2.1831
Epoch 36/100, Batch 490/549, Loss: 2.2558
Epoch 36/100, Batch 500/549, Loss: 2.1967
Epoch 36/100, Batch 510/549, Loss: 2.2346
Epoch 36/100, Batch 520/549, Loss: 2.1827
Epoch 36/100, Batch 530/549, Loss: 2.1733
Epoch 36/100, Batch 540/549, Loss: 2.1598
New best model with validation loss: 2.1009, perplexity: 8.17
Epoch 36/100, Loss: 2.2269, Perplexity: 9.27, Val Loss: 2.1009, Val Perplexity: 8.17, Time: 1083.69s
Epoch 37/100, Batch 10/549, Loss: 2.1604
Epoch 37/100, Batch 20/549, Loss: 2.2796
Epoch 37/100, Batch 30/549, Loss: 2.2810
Epoch 37/100, Batch 40/549, Loss: 2.2231
Epoch 37/100, Batch 50/549, Loss: 2.1645
Epoch 37/100, Batch 60/549, Loss: 2.1120
Epoch 37/100, Batch 70/549, Loss: 2.2051
Epoch 37/100, Batch 80/549, Loss: 2.1988
Epoch 37/100, Batch 90/549, Loss: 2.2113
Epoch 37/100, Batch 100/549, Loss: 2.2976
Epoch 37/100, Batch 110/549, Loss: 2.2736
Epoch 37/100, Batch 120/549, Loss: 2.2878
Epoch 37/100, Batch 130/549, Loss: 2.2075
Epoch 37/100, Batch 140/549, Loss: 2.1857
Epoch 37/100, Batch 150/549, Loss: 2.2731
Epoch 37/100, Batch 160/549, Loss: 2.2113
Epoch 37/100, Batch 170/549, Loss: 2.2272
Epoch 37/100, Batch 180/549, Loss: 2.2197
Epoch 37/100, Batch 190/549, Loss: 2.1655
Epoch 37/100, Batch 200/549, Loss: 2.2013
Epoch 37/100, Batch 210/549, Loss: 2.1678
Epoch 37/100, Batch 220/549, Loss: 2.1696
Epoch 37/100, Batch 230/549, Loss: 2.2322
Epoch 37/100, Batch 240/549, Loss: 2.1254
Epoch 37/100, Batch 250/549, Loss: 2.1703
Epoch 37/100, Batch 260/549, Loss: 2.1298
Epoch 37/100, Batch 270/549, Loss: 2.1969
Epoch 37/100, Batch 280/549, Loss: 2.1925
Epoch 37/100, Batch 290/549, Loss: 2.1679
Epoch 37/100, Batch 300/549, Loss: 2.2593
Epoch 37/100, Batch 310/549, Loss: 2.2214
Epoch 37/100, Batch 320/549, Loss: 2.1325
Epoch 37/100, Batch 330/549, Loss: 2.1082
Epoch 37/100, Batch 340/549, Loss: 2.1928
Epoch 37/100, Batch 350/549, Loss: 2.2382
Epoch 37/100, Batch 360/549, Loss: 2.2614
Epoch 37/100, Batch 370/549, Loss: 2.1508
Epoch 37/100, Batch 380/549, Loss: 2.2640
Epoch 37/100, Batch 390/549, Loss: 2.1937
Epoch 37/100, Batch 400/549, Loss: 2.2517
Epoch 37/100, Batch 410/549, Loss: 2.2016
Epoch 37/100, Batch 420/549, Loss: 2.2192
Epoch 37/100, Batch 430/549, Loss: 2.3118
Epoch 37/100, Batch 440/549, Loss: 2.2282
Epoch 37/100, Batch 450/549, Loss: 2.2387
Epoch 37/100, Batch 460/549, Loss: 2.2583
Epoch 37/100, Batch 470/549, Loss: 2.1864
Epoch 37/100, Batch 480/549, Loss: 2.1793
Epoch 37/100, Batch 490/549, Loss: 2.2521
Epoch 37/100, Batch 500/549, Loss: 2.1859
Epoch 37/100, Batch 510/549, Loss: 2.2308
Epoch 37/100, Batch 520/549, Loss: 2.2106
Epoch 37/100, Batch 530/549, Loss: 2.2023
Epoch 37/100, Batch 540/549, Loss: 2.1531
New best model with validation loss: 2.0953, perplexity: 8.13
Epoch 37/100, Loss: 2.2184, Perplexity: 9.19, Val Loss: 2.0953, Val Perplexity: 8.13, Time: 1083.91s
Epoch 38/100, Batch 10/549, Loss: 2.1581
Epoch 38/100, Batch 20/549, Loss: 2.2529
Epoch 38/100, Batch 30/549, Loss: 2.2850
Epoch 38/100, Batch 40/549, Loss: 2.2194
Epoch 38/100, Batch 50/549, Loss: 2.1975
Epoch 38/100, Batch 60/549, Loss: 2.1107
Epoch 38/100, Batch 70/549, Loss: 2.1905
Epoch 38/100, Batch 80/549, Loss: 2.1872
Epoch 38/100, Batch 90/549, Loss: 2.2138
Epoch 38/100, Batch 100/549, Loss: 2.3079
Epoch 38/100, Batch 110/549, Loss: 2.2573
Epoch 38/100, Batch 120/549, Loss: 2.2661
Epoch 38/100, Batch 130/549, Loss: 2.1999
Epoch 38/100, Batch 140/549, Loss: 2.1710
Epoch 38/100, Batch 150/549, Loss: 2.2517
Epoch 38/100, Batch 160/549, Loss: 2.2180
Epoch 38/100, Batch 170/549, Loss: 2.2361
Epoch 38/100, Batch 180/549, Loss: 2.1978
Epoch 38/100, Batch 190/549, Loss: 2.1453
Epoch 38/100, Batch 200/549, Loss: 2.1850
Epoch 38/100, Batch 210/549, Loss: 2.1729
Epoch 38/100, Batch 220/549, Loss: 2.1610
Epoch 38/100, Batch 230/549, Loss: 2.2478
Epoch 38/100, Batch 240/549, Loss: 2.1071
Epoch 38/100, Batch 250/549, Loss: 2.1087
Epoch 38/100, Batch 260/549, Loss: 2.1170
Epoch 38/100, Batch 270/549, Loss: 2.1897
Epoch 38/100, Batch 280/549, Loss: 2.2217
Epoch 38/100, Batch 290/549, Loss: 2.1462
Epoch 38/100, Batch 300/549, Loss: 2.2428
Epoch 38/100, Batch 310/549, Loss: 2.2322
Epoch 38/100, Batch 320/549, Loss: 2.1133
Epoch 38/100, Batch 330/549, Loss: 2.1619
Epoch 38/100, Batch 340/549, Loss: 2.1802
Epoch 38/100, Batch 350/549, Loss: 2.2405
Epoch 38/100, Batch 360/549, Loss: 2.2441
Epoch 38/100, Batch 370/549, Loss: 2.1397
Epoch 38/100, Batch 380/549, Loss: 2.2213
Epoch 38/100, Batch 390/549, Loss: 2.1973
Epoch 38/100, Batch 400/549, Loss: 2.2505
Epoch 38/100, Batch 410/549, Loss: 2.1921
Epoch 38/100, Batch 420/549, Loss: 2.2021
Epoch 38/100, Batch 430/549, Loss: 2.3144
Epoch 38/100, Batch 440/549, Loss: 2.2069
Epoch 38/100, Batch 450/549, Loss: 2.2221
Epoch 38/100, Batch 460/549, Loss: 2.2074
Epoch 38/100, Batch 470/549, Loss: 2.1742
Epoch 38/100, Batch 480/549, Loss: 2.1678
Epoch 38/100, Batch 490/549, Loss: 2.2885
Epoch 38/100, Batch 500/549, Loss: 2.1757
Epoch 38/100, Batch 510/549, Loss: 2.2165
Epoch 38/100, Batch 520/549, Loss: 2.1632
Epoch 38/100, Batch 530/549, Loss: 2.1701
Epoch 38/100, Batch 540/549, Loss: 2.1475
New best model with validation loss: 2.0934, perplexity: 8.11
Epoch 38/100, Loss: 2.2109, Perplexity: 9.12, Val Loss: 2.0934, Val Perplexity: 8.11, Time: 1086.21s
Epoch 39/100, Batch 10/549, Loss: 2.1974
Epoch 39/100, Batch 20/549, Loss: 2.2467
Epoch 39/100, Batch 30/549, Loss: 2.2751
Epoch 39/100, Batch 40/549, Loss: 2.2152
Epoch 39/100, Batch 50/549, Loss: 2.2299
Epoch 39/100, Batch 60/549, Loss: 2.1096
Epoch 39/100, Batch 70/549, Loss: 2.2300
Epoch 39/100, Batch 80/549, Loss: 2.1786
Epoch 39/100, Batch 90/549, Loss: 2.2315
Epoch 39/100, Batch 100/549, Loss: 2.2836
Epoch 39/100, Batch 110/549, Loss: 2.2519
Epoch 39/100, Batch 120/549, Loss: 2.2581
Epoch 39/100, Batch 130/549, Loss: 2.1923
Epoch 39/100, Batch 140/549, Loss: 2.2044
Epoch 39/100, Batch 150/549, Loss: 2.2470
Epoch 39/100, Batch 160/549, Loss: 2.2251
Epoch 39/100, Batch 170/549, Loss: 2.1895
Epoch 39/100, Batch 180/549, Loss: 2.1849
Epoch 39/100, Batch 190/549, Loss: 2.1389
Epoch 39/100, Batch 200/549, Loss: 2.1806
Epoch 39/100, Batch 210/549, Loss: 2.1540
Epoch 39/100, Batch 220/549, Loss: 2.1599
Epoch 39/100, Batch 230/549, Loss: 2.2173
Epoch 39/100, Batch 240/549, Loss: 2.1177
Epoch 39/100, Batch 250/549, Loss: 2.1199
Epoch 39/100, Batch 260/549, Loss: 2.1114
Epoch 39/100, Batch 270/549, Loss: 2.1757
Epoch 39/100, Batch 280/549, Loss: 2.1727
Epoch 39/100, Batch 290/549, Loss: 2.1401
Epoch 39/100, Batch 300/549, Loss: 2.2295
Epoch 39/100, Batch 310/549, Loss: 2.2107
Epoch 39/100, Batch 320/549, Loss: 2.1045
Epoch 39/100, Batch 330/549, Loss: 2.0935
Epoch 39/100, Batch 340/549, Loss: 2.1893
Epoch 39/100, Batch 350/549, Loss: 2.2794
Epoch 39/100, Batch 360/549, Loss: 2.2272
Epoch 39/100, Batch 370/549, Loss: 2.1473
Epoch 39/100, Batch 380/549, Loss: 2.2150
Epoch 39/100, Batch 390/549, Loss: 2.2420
Epoch 39/100, Batch 400/549, Loss: 2.2415
Epoch 39/100, Batch 410/549, Loss: 2.2002
Epoch 39/100, Batch 420/549, Loss: 2.2368
Epoch 39/100, Batch 430/549, Loss: 2.2970
Epoch 39/100, Batch 440/549, Loss: 2.2157
Epoch 39/100, Batch 450/549, Loss: 2.2156
Epoch 39/100, Batch 460/549, Loss: 2.2052
Epoch 39/100, Batch 470/549, Loss: 2.1739
Epoch 39/100, Batch 480/549, Loss: 2.1568
Epoch 39/100, Batch 490/549, Loss: 2.2538
Epoch 39/100, Batch 500/549, Loss: 2.1718
Epoch 39/100, Batch 510/549, Loss: 2.2130
Epoch 39/100, Batch 520/549, Loss: 2.1893
Epoch 39/100, Batch 530/549, Loss: 2.1531
Epoch 39/100, Batch 540/549, Loss: 2.1326
New best model with validation loss: 2.0854, perplexity: 8.05
Epoch 39/100, Loss: 2.2014, Perplexity: 9.04, Val Loss: 2.0854, Val Perplexity: 8.05, Time: 1088.33s
Epoch 40/100, Batch 10/549, Loss: 2.1445
Epoch 40/100, Batch 20/549, Loss: 2.2540
Epoch 40/100, Batch 30/549, Loss: 2.2617
Epoch 40/100, Batch 40/549, Loss: 2.2585
Epoch 40/100, Batch 50/549, Loss: 2.1419
Epoch 40/100, Batch 60/549, Loss: 2.0836
Epoch 40/100, Batch 70/549, Loss: 2.2022
Epoch 40/100, Batch 80/549, Loss: 2.2274
Epoch 40/100, Batch 90/549, Loss: 2.1661
Epoch 40/100, Batch 100/549, Loss: 2.2428
Epoch 40/100, Batch 110/549, Loss: 2.2392
Epoch 40/100, Batch 120/549, Loss: 2.3148
Epoch 40/100, Batch 130/549, Loss: 2.1666
Epoch 40/100, Batch 140/549, Loss: 2.1993
Epoch 40/100, Batch 150/549, Loss: 2.2403
Epoch 40/100, Batch 160/549, Loss: 2.1971
Epoch 40/100, Batch 170/549, Loss: 2.2006
Epoch 40/100, Batch 180/549, Loss: 2.2091
Epoch 40/100, Batch 190/549, Loss: 2.1479
Epoch 40/100, Batch 200/549, Loss: 2.1790
Epoch 40/100, Batch 210/549, Loss: 2.1685
Epoch 40/100, Batch 220/549, Loss: 2.1618
Epoch 40/100, Batch 230/549, Loss: 2.2081
Epoch 40/100, Batch 240/549, Loss: 2.0994
Epoch 40/100, Batch 250/549, Loss: 2.1032
Epoch 40/100, Batch 260/549, Loss: 2.1046
Epoch 40/100, Batch 270/549, Loss: 2.1601
Epoch 40/100, Batch 280/549, Loss: 2.1712
Epoch 40/100, Batch 290/549, Loss: 2.1360
Epoch 40/100, Batch 300/549, Loss: 2.2177
Epoch 40/100, Batch 310/549, Loss: 2.2103
Epoch 40/100, Batch 320/549, Loss: 2.1088
Epoch 40/100, Batch 330/549, Loss: 2.0867
Epoch 40/100, Batch 340/549, Loss: 2.1696
Epoch 40/100, Batch 350/549, Loss: 2.2276
Epoch 40/100, Batch 360/549, Loss: 2.2422
Epoch 40/100, Batch 370/549, Loss: 2.1230
Epoch 40/100, Batch 380/549, Loss: 2.2062
Epoch 40/100, Batch 390/549, Loss: 2.1775
Epoch 40/100, Batch 400/549, Loss: 2.2443
Epoch 40/100, Batch 410/549, Loss: 2.1831
Epoch 40/100, Batch 420/549, Loss: 2.1981
Epoch 40/100, Batch 430/549, Loss: 2.2911
Epoch 40/100, Batch 440/549, Loss: 2.2066
Epoch 40/100, Batch 450/549, Loss: 2.2129
Epoch 40/100, Batch 460/549, Loss: 2.1938
Epoch 40/100, Batch 470/549, Loss: 2.1491
Epoch 40/100, Batch 480/549, Loss: 2.1514
Epoch 40/100, Batch 490/549, Loss: 2.2866
Epoch 40/100, Batch 500/549, Loss: 2.1669
Epoch 40/100, Batch 510/549, Loss: 2.2081
Epoch 40/100, Batch 520/549, Loss: 2.1397
Epoch 40/100, Batch 530/549, Loss: 2.1523
Epoch 40/100, Batch 540/549, Loss: 2.1244
New best model with validation loss: 2.0827, perplexity: 8.03
Epoch 40/100, Loss: 2.1935, Perplexity: 8.97, Val Loss: 2.0827, Val Perplexity: 8.03, Time: 1088.58s
Epoch 41/100, Batch 10/549, Loss: 2.1287
Epoch 41/100, Batch 20/549, Loss: 2.2451
Epoch 41/100, Batch 30/549, Loss: 2.2519
Epoch 41/100, Batch 40/549, Loss: 2.2042
Epoch 41/100, Batch 50/549, Loss: 2.1440
Epoch 41/100, Batch 60/549, Loss: 2.0708
Epoch 41/100, Batch 70/549, Loss: 2.1683
Epoch 41/100, Batch 80/549, Loss: 2.1861
Epoch 41/100, Batch 90/549, Loss: 2.1658
Epoch 41/100, Batch 100/549, Loss: 2.2413
Epoch 41/100, Batch 110/549, Loss: 2.2375
Epoch 41/100, Batch 120/549, Loss: 2.3055
Epoch 41/100, Batch 130/549, Loss: 2.2125
Epoch 41/100, Batch 140/549, Loss: 2.1550
Epoch 41/100, Batch 150/549, Loss: 2.2301
Epoch 41/100, Batch 160/549, Loss: 2.1813
Epoch 41/100, Batch 170/549, Loss: 2.1879
Epoch 41/100, Batch 180/549, Loss: 2.1735
Epoch 41/100, Batch 190/549, Loss: 2.1211
Epoch 41/100, Batch 200/549, Loss: 2.1715
Epoch 41/100, Batch 210/549, Loss: 2.1763
Epoch 41/100, Batch 220/549, Loss: 2.1515
Epoch 41/100, Batch 230/549, Loss: 2.2026
Epoch 41/100, Batch 240/549, Loss: 2.0970
Epoch 41/100, Batch 250/549, Loss: 2.0865
Epoch 41/100, Batch 260/549, Loss: 2.0968
Epoch 41/100, Batch 270/549, Loss: 2.1593
Epoch 41/100, Batch 280/549, Loss: 2.1699
Epoch 41/100, Batch 290/549, Loss: 2.1247
Epoch 41/100, Batch 300/549, Loss: 2.2226
Epoch 41/100, Batch 310/549, Loss: 2.2473
Epoch 41/100, Batch 320/549, Loss: 2.1722
Epoch 41/100, Batch 330/549, Loss: 2.0816
Epoch 41/100, Batch 340/549, Loss: 2.1450
Epoch 41/100, Batch 350/549, Loss: 2.2235
Epoch 41/100, Batch 360/549, Loss: 2.2245
Epoch 41/100, Batch 370/549, Loss: 2.1288
Epoch 41/100, Batch 380/549, Loss: 2.2425
Epoch 41/100, Batch 390/549, Loss: 2.1813
Epoch 41/100, Batch 400/549, Loss: 2.2586
Epoch 41/100, Batch 410/549, Loss: 2.1668
Epoch 41/100, Batch 420/549, Loss: 2.1784
Epoch 41/100, Batch 430/549, Loss: 2.2855
Epoch 41/100, Batch 440/549, Loss: 2.1875
Epoch 41/100, Batch 450/549, Loss: 2.2001
Epoch 41/100, Batch 460/549, Loss: 2.1813
Epoch 41/100, Batch 470/549, Loss: 2.2067
Epoch 41/100, Batch 480/549, Loss: 2.1467
Epoch 41/100, Batch 490/549, Loss: 2.2249
Epoch 41/100, Batch 500/549, Loss: 2.1570
Epoch 41/100, Batch 510/549, Loss: 2.2103
Epoch 41/100, Batch 520/549, Loss: 2.1405
Epoch 41/100, Batch 530/549, Loss: 2.1441
Epoch 41/100, Batch 540/549, Loss: 2.1731
New best model with validation loss: 2.0819, perplexity: 8.02
Epoch 41/100, Loss: 2.1876, Perplexity: 8.91, Val Loss: 2.0819, Val Perplexity: 8.02, Time: 1088.52s
Epoch 42/100, Batch 10/549, Loss: 2.1196
Epoch 42/100, Batch 20/549, Loss: 2.2448
Epoch 42/100, Batch 30/549, Loss: 2.2621
Epoch 42/100, Batch 40/549, Loss: 2.1818
Epoch 42/100, Batch 50/549, Loss: 2.1365
Epoch 42/100, Batch 60/549, Loss: 2.0689
Epoch 42/100, Batch 70/549, Loss: 2.1611
Epoch 42/100, Batch 80/549, Loss: 2.1616
Epoch 42/100, Batch 90/549, Loss: 2.1442
Epoch 42/100, Batch 100/549, Loss: 2.2283
Epoch 42/100, Batch 110/549, Loss: 2.2200
Epoch 42/100, Batch 120/549, Loss: 2.2696
Epoch 42/100, Batch 130/549, Loss: 2.1639
Epoch 42/100, Batch 140/549, Loss: 2.1413
Epoch 42/100, Batch 150/549, Loss: 2.2234
Epoch 42/100, Batch 160/549, Loss: 2.2218
Epoch 42/100, Batch 170/549, Loss: 2.1911
Epoch 42/100, Batch 180/549, Loss: 2.1642
Epoch 42/100, Batch 190/549, Loss: 2.1117
Epoch 42/100, Batch 200/549, Loss: 2.1745
Epoch 42/100, Batch 210/549, Loss: 2.1378
Epoch 42/100, Batch 220/549, Loss: 2.1678
Epoch 42/100, Batch 230/549, Loss: 2.2046
Epoch 42/100, Batch 240/549, Loss: 2.0941
Epoch 42/100, Batch 250/549, Loss: 2.0820
Epoch 42/100, Batch 260/549, Loss: 2.0953
Epoch 42/100, Batch 270/549, Loss: 2.1653
Epoch 42/100, Batch 280/549, Loss: 2.1512
Epoch 42/100, Batch 290/549, Loss: 2.1481
Epoch 42/100, Batch 300/549, Loss: 2.2570
Epoch 42/100, Batch 310/549, Loss: 2.2361
Epoch 42/100, Batch 320/549, Loss: 2.0887
Epoch 42/100, Batch 330/549, Loss: 2.0890
Epoch 42/100, Batch 340/549, Loss: 2.1471
Epoch 42/100, Batch 350/549, Loss: 2.2078
Epoch 42/100, Batch 360/549, Loss: 2.2419
Epoch 42/100, Batch 370/549, Loss: 2.1268
Epoch 42/100, Batch 380/549, Loss: 2.1867
Epoch 42/100, Batch 390/549, Loss: 2.1651
Epoch 42/100, Batch 400/549, Loss: 2.2180
Epoch 42/100, Batch 410/549, Loss: 2.1676
Epoch 42/100, Batch 420/549, Loss: 2.1772
Epoch 42/100, Batch 430/549, Loss: 2.2836
Epoch 42/100, Batch 440/549, Loss: 2.1882
Epoch 42/100, Batch 450/549, Loss: 2.1870
Epoch 42/100, Batch 460/549, Loss: 2.1689
Epoch 42/100, Batch 470/549, Loss: 2.1717
Epoch 42/100, Batch 480/549, Loss: 2.1369
Epoch 42/100, Batch 490/549, Loss: 2.2262
Epoch 42/100, Batch 500/549, Loss: 2.1493
Epoch 42/100, Batch 510/549, Loss: 2.1971
Epoch 42/100, Batch 520/549, Loss: 2.1385
Epoch 42/100, Batch 530/549, Loss: 2.1302
Epoch 42/100, Batch 540/549, Loss: 2.1290
New best model with validation loss: 2.0778, perplexity: 7.99
Epoch 42/100, Loss: 2.1804, Perplexity: 8.85, Val Loss: 2.0778, Val Perplexity: 7.99, Time: 1087.61s
Epoch 43/100, Batch 10/549, Loss: 2.1128
Epoch 43/100, Batch 20/549, Loss: 2.2266
Epoch 43/100, Batch 30/549, Loss: 2.2429
Epoch 43/100, Batch 40/549, Loss: 2.2191
Epoch 43/100, Batch 50/549, Loss: 2.1131
Epoch 43/100, Batch 60/549, Loss: 2.0547
Epoch 43/100, Batch 70/549, Loss: 2.1615
Epoch 43/100, Batch 80/549, Loss: 2.1441
Epoch 43/100, Batch 90/549, Loss: 2.1504
Epoch 43/100, Batch 100/549, Loss: 2.2233
Epoch 43/100, Batch 110/549, Loss: 2.2328
Epoch 43/100, Batch 120/549, Loss: 2.2368
Epoch 43/100, Batch 130/549, Loss: 2.1447
Epoch 43/100, Batch 140/549, Loss: 2.1452
Epoch 43/100, Batch 150/549, Loss: 2.2092
Epoch 43/100, Batch 160/549, Loss: 2.1739
Epoch 43/100, Batch 170/549, Loss: 2.1748
Epoch 43/100, Batch 180/549, Loss: 2.1750
Epoch 43/100, Batch 190/549, Loss: 2.1081
Epoch 43/100, Batch 200/549, Loss: 2.1635
Epoch 43/100, Batch 210/549, Loss: 2.1633
Epoch 43/100, Batch 220/549, Loss: 2.1319
Epoch 43/100, Batch 230/549, Loss: 2.1888
Epoch 43/100, Batch 240/549, Loss: 2.0781
Epoch 43/100, Batch 250/549, Loss: 2.0945
Epoch 43/100, Batch 260/549, Loss: 2.1338
Epoch 43/100, Batch 270/549, Loss: 2.1546
Epoch 43/100, Batch 280/549, Loss: 2.1444
Epoch 43/100, Batch 290/549, Loss: 2.1236
Epoch 43/100, Batch 300/549, Loss: 2.2065
Epoch 43/100, Batch 310/549, Loss: 2.1871
Epoch 43/100, Batch 320/549, Loss: 2.0816
Epoch 43/100, Batch 330/549, Loss: 2.1284
Epoch 43/100, Batch 340/549, Loss: 2.1323
Epoch 43/100, Batch 350/549, Loss: 2.2083
Epoch 43/100, Batch 360/549, Loss: 2.2160
Epoch 43/100, Batch 370/549, Loss: 2.1206
Epoch 43/100, Batch 380/549, Loss: 2.1910
Epoch 43/100, Batch 390/549, Loss: 2.1567
Epoch 43/100, Batch 400/549, Loss: 2.2115
Epoch 43/100, Batch 410/549, Loss: 2.1767
Epoch 43/100, Batch 420/549, Loss: 2.1729
Epoch 43/100, Batch 430/549, Loss: 2.2671
Epoch 43/100, Batch 440/549, Loss: 2.1752
Epoch 43/100, Batch 450/549, Loss: 2.1812
Epoch 43/100, Batch 460/549, Loss: 2.1740
Epoch 43/100, Batch 470/549, Loss: 2.1377
Epoch 43/100, Batch 480/549, Loss: 2.1430
Epoch 43/100, Batch 490/549, Loss: 2.2076
Epoch 43/100, Batch 500/549, Loss: 2.1417
Epoch 43/100, Batch 510/549, Loss: 2.1889
Epoch 43/100, Batch 520/549, Loss: 2.1251
Epoch 43/100, Batch 530/549, Loss: 2.1218
Epoch 43/100, Batch 540/549, Loss: 2.1035
New best model with validation loss: 2.0775, perplexity: 7.98
Epoch 43/100, Loss: 2.1737, Perplexity: 8.79, Val Loss: 2.0775, Val Perplexity: 7.98, Time: 1090.20s
Epoch 44/100, Batch 10/549, Loss: 2.1414
Epoch 44/100, Batch 20/549, Loss: 2.2491
Epoch 44/100, Batch 30/549, Loss: 2.2281
Epoch 44/100, Batch 40/549, Loss: 2.1782
Epoch 44/100, Batch 50/549, Loss: 2.1143
Epoch 44/100, Batch 60/549, Loss: 2.0927
Epoch 44/100, Batch 70/549, Loss: 2.1995
Epoch 44/100, Batch 80/549, Loss: 2.1270
Epoch 44/100, Batch 90/549, Loss: 2.1419
Epoch 44/100, Batch 100/549, Loss: 2.2218
Epoch 44/100, Batch 110/549, Loss: 2.2217
Epoch 44/100, Batch 120/549, Loss: 2.2459
Epoch 44/100, Batch 130/549, Loss: 2.1628
Epoch 44/100, Batch 140/549, Loss: 2.1325
Epoch 44/100, Batch 150/549, Loss: 2.2101
Epoch 44/100, Batch 160/549, Loss: 2.1608
Epoch 44/100, Batch 170/549, Loss: 2.2098
Epoch 44/100, Batch 180/549, Loss: 2.1551
Epoch 44/100, Batch 190/549, Loss: 2.1065
Epoch 44/100, Batch 200/549, Loss: 2.1608
Epoch 44/100, Batch 210/549, Loss: 2.1238
Epoch 44/100, Batch 220/549, Loss: 2.1179
Epoch 44/100, Batch 230/549, Loss: 2.1754
Epoch 44/100, Batch 240/549, Loss: 2.1004
Epoch 44/100, Batch 250/549, Loss: 2.0611
Epoch 44/100, Batch 260/549, Loss: 2.0910
Epoch 44/100, Batch 270/549, Loss: 2.1471
Epoch 44/100, Batch 280/549, Loss: 2.1376
Epoch 44/100, Batch 290/549, Loss: 2.0989
Epoch 44/100, Batch 300/549, Loss: 2.1907
Epoch 44/100, Batch 310/549, Loss: 2.1824
Epoch 44/100, Batch 320/549, Loss: 2.0729
Epoch 44/100, Batch 330/549, Loss: 2.0582
Epoch 44/100, Batch 340/549, Loss: 2.1192
Epoch 44/100, Batch 350/549, Loss: 2.2016
Epoch 44/100, Batch 360/549, Loss: 2.2489
Epoch 44/100, Batch 370/549, Loss: 2.1021
Epoch 44/100, Batch 380/549, Loss: 2.1983
Epoch 44/100, Batch 390/549, Loss: 2.1591
Epoch 44/100, Batch 400/549, Loss: 2.2139
Epoch 44/100, Batch 410/549, Loss: 2.1443
Epoch 44/100, Batch 420/549, Loss: 2.1654
Epoch 44/100, Batch 430/549, Loss: 2.2624
Epoch 44/100, Batch 440/549, Loss: 2.1697
Epoch 44/100, Batch 450/549, Loss: 2.2016
Epoch 44/100, Batch 460/549, Loss: 2.1730
Epoch 44/100, Batch 470/549, Loss: 2.1353
Epoch 44/100, Batch 480/549, Loss: 2.1223
Epoch 44/100, Batch 490/549, Loss: 2.1984
Epoch 44/100, Batch 500/549, Loss: 2.1393
Epoch 44/100, Batch 510/549, Loss: 2.1785
Epoch 44/100, Batch 520/549, Loss: 2.1477
Epoch 44/100, Batch 530/549, Loss: 2.1112
Epoch 44/100, Batch 540/549, Loss: 2.1004
New best model with validation loss: 2.0693, perplexity: 7.92
Epoch 44/100, Loss: 2.1673, Perplexity: 8.73, Val Loss: 2.0693, Val Perplexity: 7.92, Time: 1087.66s
Epoch 45/100, Batch 10/549, Loss: 2.1021
Epoch 45/100, Batch 20/549, Loss: 2.2315
Epoch 45/100, Batch 30/549, Loss: 2.2886
Epoch 45/100, Batch 40/549, Loss: 2.1565
Epoch 45/100, Batch 50/549, Loss: 2.1875
Epoch 45/100, Batch 60/549, Loss: 2.0537
Epoch 45/100, Batch 70/549, Loss: 2.1853
Epoch 45/100, Batch 80/549, Loss: 2.1308
Epoch 45/100, Batch 90/549, Loss: 2.1445
Epoch 45/100, Batch 100/549, Loss: 2.2038
Epoch 45/100, Batch 110/549, Loss: 2.1977
Epoch 45/100, Batch 120/549, Loss: 2.2205
Epoch 45/100, Batch 130/549, Loss: 2.1431
Epoch 45/100, Batch 140/549, Loss: 2.1217
Epoch 45/100, Batch 150/549, Loss: 2.2057
Epoch 45/100, Batch 160/549, Loss: 2.1743
Epoch 45/100, Batch 170/549, Loss: 2.1505
Epoch 45/100, Batch 180/549, Loss: 2.1472
Epoch 45/100, Batch 190/549, Loss: 2.0847
Epoch 45/100, Batch 200/549, Loss: 2.1464
Epoch 45/100, Batch 210/549, Loss: 2.1155
Epoch 45/100, Batch 220/549, Loss: 2.1162
Epoch 45/100, Batch 230/549, Loss: 2.1975
Epoch 45/100, Batch 240/549, Loss: 2.0704
Epoch 45/100, Batch 250/549, Loss: 2.0627
Epoch 45/100, Batch 260/549, Loss: 2.0765
Epoch 45/100, Batch 270/549, Loss: 2.1602
Epoch 45/100, Batch 280/549, Loss: 2.1336
Epoch 45/100, Batch 290/549, Loss: 2.1020
Epoch 45/100, Batch 300/549, Loss: 2.2059
Epoch 45/100, Batch 310/549, Loss: 2.1631
Epoch 45/100, Batch 320/549, Loss: 2.1208
Epoch 45/100, Batch 330/549, Loss: 2.0814
Epoch 45/100, Batch 340/549, Loss: 2.1279
Epoch 45/100, Batch 350/549, Loss: 2.1906
Epoch 45/100, Batch 360/549, Loss: 2.1921
Epoch 45/100, Batch 370/549, Loss: 2.0986
Epoch 45/100, Batch 380/549, Loss: 2.1829
Epoch 45/100, Batch 390/549, Loss: 2.1423
Epoch 45/100, Batch 400/549, Loss: 2.2162
Epoch 45/100, Batch 410/549, Loss: 2.1415
Epoch 45/100, Batch 420/549, Loss: 2.1608
Epoch 45/100, Batch 430/549, Loss: 2.2565
Epoch 45/100, Batch 440/549, Loss: 2.1633
Epoch 45/100, Batch 450/549, Loss: 2.1854
Epoch 45/100, Batch 460/549, Loss: 2.1839
Epoch 45/100, Batch 470/549, Loss: 2.1233
Epoch 45/100, Batch 480/549, Loss: 2.1187
Epoch 45/100, Batch 490/549, Loss: 2.2060
Epoch 45/100, Batch 500/549, Loss: 2.1295
Epoch 45/100, Batch 510/549, Loss: 2.2684
Epoch 45/100, Batch 520/549, Loss: 2.1281
Epoch 45/100, Batch 530/549, Loss: 2.1110
Epoch 45/100, Batch 540/549, Loss: 2.1056
New best model with validation loss: 2.0691, perplexity: 7.92
Epoch 45/100, Loss: 2.1608, Perplexity: 8.68, Val Loss: 2.0691, Val Perplexity: 7.92, Time: 1086.19s
Epoch 46/100, Batch 10/549, Loss: 2.0930
Epoch 46/100, Batch 20/549, Loss: 2.2286
Epoch 46/100, Batch 30/549, Loss: 2.2199
Epoch 46/100, Batch 40/549, Loss: 2.1524
Epoch 46/100, Batch 50/549, Loss: 2.1175
Epoch 46/100, Batch 60/549, Loss: 2.0411
Epoch 46/100, Batch 70/549, Loss: 2.1376
Epoch 46/100, Batch 80/549, Loss: 2.1425
Epoch 46/100, Batch 90/549, Loss: 2.1348
Epoch 46/100, Batch 100/549, Loss: 2.2045
Epoch 46/100, Batch 110/549, Loss: 2.2237
Epoch 46/100, Batch 120/549, Loss: 2.2861
Epoch 46/100, Batch 130/549, Loss: 2.1608
Epoch 46/100, Batch 140/549, Loss: 2.1242
Epoch 46/100, Batch 150/549, Loss: 2.1944
Epoch 46/100, Batch 160/549, Loss: 2.1765
Epoch 46/100, Batch 170/549, Loss: 2.1572
Epoch 46/100, Batch 180/549, Loss: 2.1867
Epoch 46/100, Batch 190/549, Loss: 2.1339
Epoch 46/100, Batch 200/549, Loss: 2.1405
Epoch 46/100, Batch 210/549, Loss: 2.1223
Epoch 46/100, Batch 220/549, Loss: 2.1235
Epoch 46/100, Batch 230/549, Loss: 2.1651
Epoch 46/100, Batch 240/549, Loss: 2.0676
Epoch 46/100, Batch 250/549, Loss: 2.0713
Epoch 46/100, Batch 260/549, Loss: 2.0957
Epoch 46/100, Batch 270/549, Loss: 2.1330
Epoch 46/100, Batch 280/549, Loss: 2.1440
Epoch 46/100, Batch 290/549, Loss: 2.1238
Epoch 46/100, Batch 300/549, Loss: 2.1864
Epoch 46/100, Batch 310/549, Loss: 2.1723
Epoch 46/100, Batch 320/549, Loss: 2.0813
Epoch 46/100, Batch 330/549, Loss: 2.0654
Epoch 46/100, Batch 340/549, Loss: 2.1465
Epoch 46/100, Batch 350/549, Loss: 2.1881
Epoch 46/100, Batch 360/549, Loss: 2.1898
Epoch 46/100, Batch 370/549, Loss: 2.1049
Epoch 46/100, Batch 380/549, Loss: 2.1656
Epoch 46/100, Batch 390/549, Loss: 2.1375
Epoch 46/100, Batch 400/549, Loss: 2.1949
Epoch 46/100, Batch 410/549, Loss: 2.1533
Epoch 46/100, Batch 420/549, Loss: 2.1456
Epoch 46/100, Batch 430/549, Loss: 2.2595
Epoch 46/100, Batch 440/549, Loss: 2.1646
Epoch 46/100, Batch 450/549, Loss: 2.1630
Epoch 46/100, Batch 460/549, Loss: 2.1584
Epoch 46/100, Batch 470/549, Loss: 2.1655
Epoch 46/100, Batch 480/549, Loss: 2.1127
Epoch 46/100, Batch 490/549, Loss: 2.1927
Epoch 46/100, Batch 500/549, Loss: 2.1382
Epoch 46/100, Batch 510/549, Loss: 2.1731
Epoch 46/100, Batch 520/549, Loss: 2.1058
Epoch 46/100, Batch 530/549, Loss: 2.1094
Epoch 46/100, Batch 540/549, Loss: 2.0903
New best model with validation loss: 2.0661, perplexity: 7.89
Epoch 46/100, Loss: 2.1565, Perplexity: 8.64, Val Loss: 2.0661, Val Perplexity: 7.89, Time: 1083.44s
Epoch 47/100, Batch 10/549, Loss: 2.0839
Epoch 47/100, Batch 20/549, Loss: 2.1911
Epoch 47/100, Batch 30/549, Loss: 2.2229
Epoch 47/100, Batch 40/549, Loss: 2.1491
Epoch 47/100, Batch 50/549, Loss: 2.0993
Epoch 47/100, Batch 60/549, Loss: 2.0316
Epoch 47/100, Batch 70/549, Loss: 2.1387
Epoch 47/100, Batch 80/549, Loss: 2.1115
Epoch 47/100, Batch 90/549, Loss: 2.1365
Epoch 47/100, Batch 100/549, Loss: 2.1901
Epoch 47/100, Batch 110/549, Loss: 2.2044
Epoch 47/100, Batch 120/549, Loss: 2.2235
Epoch 47/100, Batch 130/549, Loss: 2.1475
Epoch 47/100, Batch 140/549, Loss: 2.1079
Epoch 47/100, Batch 150/549, Loss: 2.1997
Epoch 47/100, Batch 160/549, Loss: 2.1525
Epoch 47/100, Batch 170/549, Loss: 2.1343
Epoch 47/100, Batch 180/549, Loss: 2.1389
Epoch 47/100, Batch 190/549, Loss: 2.0849
Epoch 47/100, Batch 200/549, Loss: 2.1392
Epoch 47/100, Batch 210/549, Loss: 2.1432
Epoch 47/100, Batch 220/549, Loss: 2.1092
Epoch 47/100, Batch 230/549, Loss: 2.1643
Epoch 47/100, Batch 240/549, Loss: 2.0571
Epoch 47/100, Batch 250/549, Loss: 2.0518
Epoch 47/100, Batch 260/549, Loss: 2.0699
Epoch 47/100, Batch 270/549, Loss: 2.1253
Epoch 47/100, Batch 280/549, Loss: 2.1285
Epoch 47/100, Batch 290/549, Loss: 2.0853
Epoch 47/100, Batch 300/549, Loss: 2.2245
Epoch 47/100, Batch 310/549, Loss: 2.1619
Epoch 47/100, Batch 320/549, Loss: 2.0648
Epoch 47/100, Batch 330/549, Loss: 2.0518
Epoch 47/100, Batch 340/549, Loss: 2.1277
Epoch 47/100, Batch 350/549, Loss: 2.1799
Epoch 47/100, Batch 360/549, Loss: 2.2047
Epoch 47/100, Batch 370/549, Loss: 2.0899
Epoch 47/100, Batch 380/549, Loss: 2.1579
Epoch 47/100, Batch 390/549, Loss: 2.1324
Epoch 47/100, Batch 400/549, Loss: 2.1884
Epoch 47/100, Batch 410/549, Loss: 2.1415
Epoch 47/100, Batch 420/549, Loss: 2.1430
Epoch 47/100, Batch 430/549, Loss: 2.2434
Epoch 47/100, Batch 440/549, Loss: 2.1555
Epoch 47/100, Batch 450/549, Loss: 2.1623
Epoch 47/100, Batch 460/549, Loss: 2.1595
Epoch 47/100, Batch 470/549, Loss: 2.1171
Epoch 47/100, Batch 480/549, Loss: 2.1202
Epoch 47/100, Batch 490/549, Loss: 2.1849
Epoch 47/100, Batch 500/549, Loss: 2.1029
Epoch 47/100, Batch 510/549, Loss: 2.1828
Epoch 47/100, Batch 520/549, Loss: 2.1615
Epoch 47/100, Batch 530/549, Loss: 2.1011
Epoch 47/100, Batch 540/549, Loss: 2.1096
New best model with validation loss: 2.0624, perplexity: 7.87
Epoch 47/100, Loss: 2.1497, Perplexity: 8.58, Val Loss: 2.0624, Val Perplexity: 7.87, Time: 1087.90s
Epoch 48/100, Batch 10/549, Loss: 2.0880
Epoch 48/100, Batch 20/549, Loss: 2.1795
Epoch 48/100, Batch 30/549, Loss: 2.2087
Epoch 48/100, Batch 40/549, Loss: 2.1439
Epoch 48/100, Batch 50/549, Loss: 2.0836
Epoch 48/100, Batch 60/549, Loss: 2.0327
Epoch 48/100, Batch 70/549, Loss: 2.1335
Epoch 48/100, Batch 80/549, Loss: 2.1120
Epoch 48/100, Batch 90/549, Loss: 2.1737
Epoch 48/100, Batch 100/549, Loss: 2.1900
Epoch 48/100, Batch 110/549, Loss: 2.1819
Epoch 48/100, Batch 120/549, Loss: 2.2224
Epoch 48/100, Batch 130/549, Loss: 2.1388
Epoch 48/100, Batch 140/549, Loss: 2.1112
Epoch 48/100, Batch 150/549, Loss: 2.1790
Epoch 48/100, Batch 160/549, Loss: 2.1502
Epoch 48/100, Batch 170/549, Loss: 2.1365
Epoch 48/100, Batch 180/549, Loss: 2.1633
Epoch 48/100, Batch 190/549, Loss: 2.0785
Epoch 48/100, Batch 200/549, Loss: 2.1608
Epoch 48/100, Batch 210/549, Loss: 2.1011
Epoch 48/100, Batch 220/549, Loss: 2.0988
Epoch 48/100, Batch 230/549, Loss: 2.2106
Epoch 48/100, Batch 240/549, Loss: 2.0575
Epoch 48/100, Batch 250/549, Loss: 2.0442
Epoch 48/100, Batch 260/549, Loss: 2.0844
Epoch 48/100, Batch 270/549, Loss: 2.1234
Epoch 48/100, Batch 280/549, Loss: 2.1211
Epoch 48/100, Batch 290/549, Loss: 2.1269
Epoch 48/100, Batch 300/549, Loss: 2.1663
Epoch 48/100, Batch 310/549, Loss: 2.1464
Epoch 48/100, Batch 320/549, Loss: 2.0862
Epoch 48/100, Batch 330/549, Loss: 2.0435
Epoch 48/100, Batch 340/549, Loss: 2.1082
Epoch 48/100, Batch 350/549, Loss: 2.1684
Epoch 48/100, Batch 360/549, Loss: 2.1769
Epoch 48/100, Batch 370/549, Loss: 2.1154
Epoch 48/100, Batch 380/549, Loss: 2.1581
Epoch 48/100, Batch 390/549, Loss: 2.1648
Epoch 48/100, Batch 400/549, Loss: 2.1875
Epoch 48/100, Batch 410/549, Loss: 2.1267
Epoch 48/100, Batch 420/549, Loss: 2.1408
Epoch 48/100, Batch 430/549, Loss: 2.2658
Epoch 48/100, Batch 440/549, Loss: 2.1410
Epoch 48/100, Batch 450/549, Loss: 2.1584
Epoch 48/100, Batch 460/549, Loss: 2.1487
Epoch 48/100, Batch 470/549, Loss: 2.1221
Epoch 48/100, Batch 480/549, Loss: 2.1078
Epoch 48/100, Batch 490/549, Loss: 2.1877
Epoch 48/100, Batch 500/549, Loss: 2.0997
Epoch 48/100, Batch 510/549, Loss: 2.1621
Epoch 48/100, Batch 520/549, Loss: 2.1003
Epoch 48/100, Batch 530/549, Loss: 2.0953
Epoch 48/100, Batch 540/549, Loss: 2.0920
New best model with validation loss: 2.0622, perplexity: 7.86
Epoch 48/100, Loss: 2.1426, Perplexity: 8.52, Val Loss: 2.0622, Val Perplexity: 7.86, Time: 1088.83s
Epoch 49/100, Batch 10/549, Loss: 2.0712
Epoch 49/100, Batch 20/549, Loss: 2.1826
Epoch 49/100, Batch 30/549, Loss: 2.2239
Epoch 49/100, Batch 40/549, Loss: 2.1396
Epoch 49/100, Batch 50/549, Loss: 2.0878
Epoch 49/100, Batch 60/549, Loss: 2.0354
Epoch 49/100, Batch 70/549, Loss: 2.1145
Epoch 49/100, Batch 80/549, Loss: 2.1111
Epoch 49/100, Batch 90/549, Loss: 2.1228
Epoch 49/100, Batch 100/549, Loss: 2.1814
Epoch 49/100, Batch 110/549, Loss: 2.1905
Epoch 49/100, Batch 120/549, Loss: 2.2170
Epoch 49/100, Batch 130/549, Loss: 2.1067
Epoch 49/100, Batch 140/549, Loss: 2.0967
Epoch 49/100, Batch 150/549, Loss: 2.1724
Epoch 49/100, Batch 160/549, Loss: 2.1429
Epoch 49/100, Batch 170/549, Loss: 2.1678
Epoch 49/100, Batch 180/549, Loss: 2.1241
Epoch 49/100, Batch 190/549, Loss: 2.0764
Epoch 49/100, Batch 200/549, Loss: 2.1258
Epoch 49/100, Batch 210/549, Loss: 2.1076
Epoch 49/100, Batch 220/549, Loss: 2.0893
Epoch 49/100, Batch 230/549, Loss: 2.1898
Epoch 49/100, Batch 240/549, Loss: 2.0553
Epoch 49/100, Batch 250/549, Loss: 2.0886
Epoch 49/100, Batch 260/549, Loss: 2.0721
Epoch 49/100, Batch 270/549, Loss: 2.1131
Epoch 49/100, Batch 280/549, Loss: 2.1143
Epoch 49/100, Batch 290/549, Loss: 2.0985
Epoch 49/100, Batch 300/549, Loss: 2.1650
Epoch 49/100, Batch 310/549, Loss: 2.1477
Epoch 49/100, Batch 320/549, Loss: 2.0476
Epoch 49/100, Batch 330/549, Loss: 2.0363
Epoch 49/100, Batch 340/549, Loss: 2.1014
Epoch 49/100, Batch 350/549, Loss: 2.1709
Epoch 49/100, Batch 360/549, Loss: 2.2430
Epoch 49/100, Batch 370/549, Loss: 2.0905
Epoch 49/100, Batch 380/549, Loss: 2.1462
Epoch 49/100, Batch 390/549, Loss: 2.1259
Epoch 49/100, Batch 400/549, Loss: 2.1786
Epoch 49/100, Batch 410/549, Loss: 2.1328
Epoch 49/100, Batch 420/549, Loss: 2.1424
Epoch 49/100, Batch 430/549, Loss: 2.2254
Epoch 49/100, Batch 440/549, Loss: 2.1394
Epoch 49/100, Batch 450/549, Loss: 2.1882
Epoch 49/100, Batch 460/549, Loss: 2.1753
Epoch 49/100, Batch 470/549, Loss: 2.1119
Epoch 49/100, Batch 480/549, Loss: 2.0902
Epoch 49/100, Batch 490/549, Loss: 2.1836
Epoch 49/100, Batch 500/549, Loss: 2.1054
Epoch 49/100, Batch 510/549, Loss: 2.1539
Epoch 49/100, Batch 520/549, Loss: 2.0965
Epoch 49/100, Batch 530/549, Loss: 2.0876
Epoch 49/100, Batch 540/549, Loss: 2.0681
New best model with validation loss: 2.0604, perplexity: 7.85
Epoch 49/100, Loss: 2.1386, Perplexity: 8.49, Val Loss: 2.0604, Val Perplexity: 7.85, Time: 1089.13s
Epoch 50/100, Batch 10/549, Loss: 2.0720
Epoch 50/100, Batch 20/549, Loss: 2.1741
Epoch 50/100, Batch 30/549, Loss: 2.2401
Epoch 50/100, Batch 40/549, Loss: 2.1380
Epoch 50/100, Batch 50/549, Loss: 2.0735
Epoch 50/100, Batch 60/549, Loss: 2.0198
Epoch 50/100, Batch 70/549, Loss: 2.1398
Epoch 50/100, Batch 80/549, Loss: 2.1225
Epoch 50/100, Batch 90/549, Loss: 2.1791
Epoch 50/100, Batch 100/549, Loss: 2.1747
Epoch 50/100, Batch 110/549, Loss: 2.1906
Epoch 50/100, Batch 120/549, Loss: 2.2233
Epoch 50/100, Batch 130/549, Loss: 2.1547
Epoch 50/100, Batch 140/549, Loss: 2.0842
Epoch 50/100, Batch 150/549, Loss: 2.1704
Epoch 50/100, Batch 160/549, Loss: 2.1560
Epoch 50/100, Batch 170/549, Loss: 2.1128
Epoch 50/100, Batch 180/549, Loss: 2.1710
Epoch 50/100, Batch 190/549, Loss: 2.0789
Epoch 50/100, Batch 200/549, Loss: 2.1219
Epoch 50/100, Batch 210/549, Loss: 2.0885
Epoch 50/100, Batch 220/549, Loss: 2.0873
Epoch 50/100, Batch 230/549, Loss: 2.1509
Epoch 50/100, Batch 240/549, Loss: 2.0374
Epoch 50/100, Batch 250/549, Loss: 2.0620
Epoch 50/100, Batch 260/549, Loss: 2.0495
Epoch 50/100, Batch 270/549, Loss: 2.1112
Epoch 50/100, Batch 280/549, Loss: 2.1202
Epoch 50/100, Batch 290/549, Loss: 2.0732
Epoch 50/100, Batch 300/549, Loss: 2.1650
Epoch 50/100, Batch 310/549, Loss: 2.1399
Epoch 50/100, Batch 320/549, Loss: 2.0646
Epoch 50/100, Batch 330/549, Loss: 2.0732
Epoch 50/100, Batch 340/549, Loss: 2.1155
Epoch 50/100, Batch 350/549, Loss: 2.1584
Epoch 50/100, Batch 360/549, Loss: 2.1660
Epoch 50/100, Batch 370/549, Loss: 2.0701
Epoch 50/100, Batch 380/549, Loss: 2.1477
Epoch 50/100, Batch 390/549, Loss: 2.1124
Epoch 50/100, Batch 400/549, Loss: 2.1787
Epoch 50/100, Batch 410/549, Loss: 2.1405
Epoch 50/100, Batch 420/549, Loss: 2.1260
Epoch 50/100, Batch 430/549, Loss: 2.2305
Epoch 50/100, Batch 440/549, Loss: 2.1994
Epoch 50/100, Batch 450/549, Loss: 2.1766
Epoch 50/100, Batch 460/549, Loss: 2.1375
Epoch 50/100, Batch 470/549, Loss: 2.0904
Epoch 50/100, Batch 480/549, Loss: 2.1007
Epoch 50/100, Batch 490/549, Loss: 2.1781
Epoch 50/100, Batch 500/549, Loss: 2.1426
Epoch 50/100, Batch 510/549, Loss: 2.2052
Epoch 50/100, Batch 520/549, Loss: 2.0931
Epoch 50/100, Batch 530/549, Loss: 2.0852
Epoch 50/100, Batch 540/549, Loss: 2.0649
New best model with validation loss: 2.0594, perplexity: 7.84
Epoch 50/100, Loss: 2.1320, Perplexity: 8.43, Val Loss: 2.0594, Val Perplexity: 7.84, Time: 1089.56s
Epoch 51/100, Batch 10/549, Loss: 2.0630
Epoch 51/100, Batch 20/549, Loss: 2.1827
Epoch 51/100, Batch 30/549, Loss: 2.1902
Epoch 51/100, Batch 40/549, Loss: 2.1608
Epoch 51/100, Batch 50/549, Loss: 2.0728
Epoch 51/100, Batch 60/549, Loss: 2.0655
Epoch 51/100, Batch 70/549, Loss: 2.1041
Epoch 51/100, Batch 80/549, Loss: 2.1098
Epoch 51/100, Batch 90/549, Loss: 2.1062
Epoch 51/100, Batch 100/549, Loss: 2.1653
Epoch 51/100, Batch 110/549, Loss: 2.2005
Epoch 51/100, Batch 120/549, Loss: 2.1908
Epoch 51/100, Batch 130/549, Loss: 2.1067
Epoch 51/100, Batch 140/549, Loss: 2.0872
Epoch 51/100, Batch 150/549, Loss: 2.1777
Epoch 51/100, Batch 160/549, Loss: 2.1339
Epoch 51/100, Batch 170/549, Loss: 2.1180
Epoch 51/100, Batch 180/549, Loss: 2.1161
Epoch 51/100, Batch 190/549, Loss: 2.0540
Epoch 51/100, Batch 200/549, Loss: 2.1167
Epoch 51/100, Batch 210/549, Loss: 2.0854
Epoch 51/100, Batch 220/549, Loss: 2.1261
Epoch 51/100, Batch 230/549, Loss: 2.1798
Epoch 51/100, Batch 240/549, Loss: 2.0261
Epoch 51/100, Batch 250/549, Loss: 2.0313
Epoch 51/100, Batch 260/549, Loss: 2.0444
Epoch 51/100, Batch 270/549, Loss: 2.1111
Epoch 51/100, Batch 280/549, Loss: 2.1008
Epoch 51/100, Batch 290/549, Loss: 2.0799
Epoch 51/100, Batch 300/549, Loss: 2.1434
Epoch 51/100, Batch 310/549, Loss: 2.1728
Epoch 51/100, Batch 320/549, Loss: 2.0390
Epoch 51/100, Batch 330/549, Loss: 2.0692
Epoch 51/100, Batch 340/549, Loss: 2.0957
Epoch 51/100, Batch 350/549, Loss: 2.1549
Epoch 51/100, Batch 360/549, Loss: 2.1615
Epoch 51/100, Batch 370/549, Loss: 2.0641
Epoch 51/100, Batch 380/549, Loss: 2.1427
Epoch 51/100, Batch 390/549, Loss: 2.1093
Epoch 51/100, Batch 400/549, Loss: 2.2489
Epoch 51/100, Batch 410/549, Loss: 2.1161
Epoch 51/100, Batch 420/549, Loss: 2.1295
Epoch 51/100, Batch 430/549, Loss: 2.2175
Epoch 51/100, Batch 440/549, Loss: 2.1303
Epoch 51/100, Batch 450/549, Loss: 2.1473
Epoch 51/100, Batch 460/549, Loss: 2.1266
Epoch 51/100, Batch 470/549, Loss: 2.0986
Epoch 51/100, Batch 480/549, Loss: 2.0774
Epoch 51/100, Batch 490/549, Loss: 2.1685
Epoch 51/100, Batch 500/549, Loss: 2.0861
Epoch 51/100, Batch 510/549, Loss: 2.1613
Epoch 51/100, Batch 520/549, Loss: 2.0757
Epoch 51/100, Batch 530/549, Loss: 2.0865
Epoch 51/100, Batch 540/549, Loss: 2.0612
New best model with validation loss: 2.0552, perplexity: 7.81
Epoch 51/100, Loss: 2.1274, Perplexity: 8.39, Val Loss: 2.0552, Val Perplexity: 7.81, Time: 1089.43s
Epoch 52/100, Batch 10/549, Loss: 2.0525
Epoch 52/100, Batch 20/549, Loss: 2.1647
Epoch 52/100, Batch 30/549, Loss: 2.1786
Epoch 52/100, Batch 40/549, Loss: 2.1472
Epoch 52/100, Batch 50/549, Loss: 2.0598
Epoch 52/100, Batch 60/549, Loss: 2.0037
Epoch 52/100, Batch 70/549, Loss: 2.1095
Epoch 52/100, Batch 80/549, Loss: 2.1015
Epoch 52/100, Batch 90/549, Loss: 2.1079
Epoch 52/100, Batch 100/549, Loss: 2.1625
Epoch 52/100, Batch 110/549, Loss: 2.1785
Epoch 52/100, Batch 120/549, Loss: 2.1896
Epoch 52/100, Batch 130/549, Loss: 2.1011
Epoch 52/100, Batch 140/549, Loss: 2.0784
Epoch 52/100, Batch 150/549, Loss: 2.1667
Epoch 52/100, Batch 160/549, Loss: 2.1320
Epoch 52/100, Batch 170/549, Loss: 2.1537
Epoch 52/100, Batch 180/549, Loss: 2.1109
Epoch 52/100, Batch 190/549, Loss: 2.0893
Epoch 52/100, Batch 200/549, Loss: 2.1026
Epoch 52/100, Batch 210/549, Loss: 2.0733
Epoch 52/100, Batch 220/549, Loss: 2.0892
Epoch 52/100, Batch 230/549, Loss: 2.1342
Epoch 52/100, Batch 240/549, Loss: 2.0360
Epoch 52/100, Batch 250/549, Loss: 2.0327
Epoch 52/100, Batch 260/549, Loss: 2.0346
Epoch 52/100, Batch 270/549, Loss: 2.1354
Epoch 52/100, Batch 280/549, Loss: 2.1874
Epoch 52/100, Batch 290/549, Loss: 2.0642
Epoch 52/100, Batch 300/549, Loss: 2.1428
Epoch 52/100, Batch 310/549, Loss: 2.1356
Epoch 52/100, Batch 320/549, Loss: 2.0386
Epoch 52/100, Batch 330/549, Loss: 2.0234
Epoch 52/100, Batch 340/549, Loss: 2.0850
Epoch 52/100, Batch 350/549, Loss: 2.1580
Epoch 52/100, Batch 360/549, Loss: 2.1468
Epoch 52/100, Batch 370/549, Loss: 2.0640
Epoch 52/100, Batch 380/549, Loss: 2.1302
Epoch 52/100, Batch 390/549, Loss: 2.1219
Epoch 52/100, Batch 400/549, Loss: 2.1657
Epoch 52/100, Batch 410/549, Loss: 2.1135
Epoch 52/100, Batch 420/549, Loss: 2.1197
Epoch 52/100, Batch 430/549, Loss: 2.2427
Epoch 52/100, Batch 440/549, Loss: 2.1254
Epoch 52/100, Batch 450/549, Loss: 2.1592
Epoch 52/100, Batch 460/549, Loss: 2.1664
Epoch 52/100, Batch 470/549, Loss: 2.0820
Epoch 52/100, Batch 480/549, Loss: 2.1177
Epoch 52/100, Batch 490/549, Loss: 2.1578
Epoch 52/100, Batch 500/549, Loss: 2.0789
Epoch 52/100, Batch 510/549, Loss: 2.1413
Epoch 52/100, Batch 520/549, Loss: 2.0785
Epoch 52/100, Batch 530/549, Loss: 2.1176
Epoch 52/100, Batch 540/549, Loss: 2.0978
New best model with validation loss: 2.0514, perplexity: 7.78
Epoch 52/100, Loss: 2.1239, Perplexity: 8.36, Val Loss: 2.0514, Val Perplexity: 7.78, Time: 1088.00s
Epoch 53/100, Batch 10/549, Loss: 2.0539
Epoch 53/100, Batch 20/549, Loss: 2.1832
Epoch 53/100, Batch 30/549, Loss: 2.1791
Epoch 53/100, Batch 40/549, Loss: 2.1188
Epoch 53/100, Batch 50/549, Loss: 2.0674
Epoch 53/100, Batch 60/549, Loss: 2.0059
Epoch 53/100, Batch 70/549, Loss: 2.1530
Epoch 53/100, Batch 80/549, Loss: 2.0931
Epoch 53/100, Batch 90/549, Loss: 2.1071
Epoch 53/100, Batch 100/549, Loss: 2.1569
Epoch 53/100, Batch 110/549, Loss: 2.1732
Epoch 53/100, Batch 120/549, Loss: 2.1854
Epoch 53/100, Batch 130/549, Loss: 2.0986
Epoch 53/100, Batch 140/549, Loss: 2.0753
Epoch 53/100, Batch 150/549, Loss: 2.1702
Epoch 53/100, Batch 160/549, Loss: 2.1167
Epoch 53/100, Batch 170/549, Loss: 2.1164
Epoch 53/100, Batch 180/549, Loss: 2.0923
Epoch 53/100, Batch 190/549, Loss: 2.0558
Epoch 53/100, Batch 200/549, Loss: 2.1230
Epoch 53/100, Batch 210/549, Loss: 2.0858
Epoch 53/100, Batch 220/549, Loss: 2.0826
Epoch 53/100, Batch 230/549, Loss: 2.1286
Epoch 53/100, Batch 240/549, Loss: 2.0262
Epoch 53/100, Batch 250/549, Loss: 2.0394
Epoch 53/100, Batch 260/549, Loss: 2.0399
Epoch 53/100, Batch 270/549, Loss: 2.0961
Epoch 53/100, Batch 280/549, Loss: 2.0956
Epoch 53/100, Batch 290/549, Loss: 2.0669
Epoch 53/100, Batch 300/549, Loss: 2.1459
Epoch 53/100, Batch 310/549, Loss: 2.1558
Epoch 53/100, Batch 320/549, Loss: 2.0200
Epoch 53/100, Batch 330/549, Loss: 2.0229
Epoch 53/100, Batch 340/549, Loss: 2.1341
Epoch 53/100, Batch 350/549, Loss: 2.1491
Epoch 53/100, Batch 360/549, Loss: 2.1431
Epoch 53/100, Batch 370/549, Loss: 2.1042
Epoch 53/100, Batch 380/549, Loss: 2.1824
Epoch 53/100, Batch 390/549, Loss: 2.0959
Epoch 53/100, Batch 400/549, Loss: 2.2018
Epoch 53/100, Batch 410/549, Loss: 2.1071
Epoch 53/100, Batch 420/549, Loss: 2.1850
Epoch 53/100, Batch 430/549, Loss: 2.2087
Epoch 53/100, Batch 440/549, Loss: 2.1108
Epoch 53/100, Batch 450/549, Loss: 2.1980
Epoch 53/100, Batch 460/549, Loss: 2.1444
Epoch 53/100, Batch 470/549, Loss: 2.0949
Epoch 53/100, Batch 480/549, Loss: 2.0808
Epoch 53/100, Batch 490/549, Loss: 2.1678
Epoch 53/100, Batch 500/549, Loss: 2.0808
Epoch 53/100, Batch 510/549, Loss: 2.1416
Epoch 53/100, Batch 520/549, Loss: 2.0591
Epoch 53/100, Batch 530/549, Loss: 2.0727
Epoch 53/100, Batch 540/549, Loss: 2.0556
Epoch 53/100, Loss: 2.1187, Perplexity: 8.32, Val Loss: 2.0555, Val Perplexity: 7.81, Time: 1086.03s
Epoch 54/100, Batch 10/549, Loss: 2.0806
Epoch 54/100, Batch 20/549, Loss: 2.1949
Epoch 54/100, Batch 30/549, Loss: 2.1901
Epoch 54/100, Batch 40/549, Loss: 2.1169
Epoch 54/100, Batch 50/549, Loss: 2.0750
Epoch 54/100, Batch 60/549, Loss: 2.0035
Epoch 54/100, Batch 70/549, Loss: 2.0851
Epoch 54/100, Batch 80/549, Loss: 2.1014
Epoch 54/100, Batch 90/549, Loss: 2.1131
Epoch 54/100, Batch 100/549, Loss: 2.1574
Epoch 54/100, Batch 110/549, Loss: 2.1620
Epoch 54/100, Batch 120/549, Loss: 2.1811
Epoch 54/100, Batch 130/549, Loss: 2.0927
Epoch 54/100, Batch 140/549, Loss: 2.0732
Epoch 54/100, Batch 150/549, Loss: 2.1490
Epoch 54/100, Batch 160/549, Loss: 2.1115
Epoch 54/100, Batch 170/549, Loss: 2.1047
Epoch 54/100, Batch 180/549, Loss: 2.1105
Epoch 54/100, Batch 190/549, Loss: 2.0730
Epoch 54/100, Batch 200/549, Loss: 2.0969
Epoch 54/100, Batch 210/549, Loss: 2.0947
Epoch 54/100, Batch 220/549, Loss: 2.0660
Epoch 54/100, Batch 230/549, Loss: 2.1258
Epoch 54/100, Batch 240/549, Loss: 2.0165
Epoch 54/100, Batch 250/549, Loss: 2.0951
Epoch 54/100, Batch 260/549, Loss: 2.0341
Epoch 54/100, Batch 270/549, Loss: 2.1054
Epoch 54/100, Batch 280/549, Loss: 2.0936
Epoch 54/100, Batch 290/549, Loss: 2.0448
Epoch 54/100, Batch 300/549, Loss: 2.1480
Epoch 54/100, Batch 310/549, Loss: 2.1429
Epoch 54/100, Batch 320/549, Loss: 2.0325
Epoch 54/100, Batch 330/549, Loss: 2.0315
Epoch 54/100, Batch 340/549, Loss: 2.1295
Epoch 54/100, Batch 350/549, Loss: 2.1402
Epoch 54/100, Batch 360/549, Loss: 2.1482
Epoch 54/100, Batch 370/549, Loss: 2.0653
Epoch 54/100, Batch 380/549, Loss: 2.1344
Epoch 54/100, Batch 390/549, Loss: 2.1038
Epoch 54/100, Batch 400/549, Loss: 2.1610
Epoch 54/100, Batch 410/549, Loss: 2.1193
Epoch 54/100, Batch 420/549, Loss: 2.1167
Epoch 54/100, Batch 430/549, Loss: 2.1989
Epoch 54/100, Batch 440/549, Loss: 2.1198
Epoch 54/100, Batch 450/549, Loss: 2.1320
Epoch 54/100, Batch 460/549, Loss: 2.1143
Epoch 54/100, Batch 470/549, Loss: 2.0716
Epoch 54/100, Batch 480/549, Loss: 2.0785
Epoch 54/100, Batch 490/549, Loss: 2.1571
Epoch 54/100, Batch 500/549, Loss: 2.0652
Epoch 54/100, Batch 510/549, Loss: 2.1460
Epoch 54/100, Batch 520/549, Loss: 2.0725
Epoch 54/100, Batch 530/549, Loss: 2.0768
Epoch 54/100, Batch 540/549, Loss: 2.0494
New best model with validation loss: 2.0466, perplexity: 7.74
Epoch 54/100, Loss: 2.1140, Perplexity: 8.28, Val Loss: 2.0466, Val Perplexity: 7.74, Time: 1086.55s
Epoch 55/100, Batch 10/549, Loss: 2.0449
Epoch 55/100, Batch 20/549, Loss: 2.1564
Epoch 55/100, Batch 30/549, Loss: 2.1703
Epoch 55/100, Batch 40/549, Loss: 2.1144
Epoch 55/100, Batch 50/549, Loss: 2.0507
Epoch 55/100, Batch 60/549, Loss: 2.0600
Epoch 55/100, Batch 70/549, Loss: 2.0979
Epoch 55/100, Batch 80/549, Loss: 2.0949
Epoch 55/100, Batch 90/549, Loss: 2.0860
Epoch 55/100, Batch 100/549, Loss: 2.1406
Epoch 55/100, Batch 110/549, Loss: 2.1607
Epoch 55/100, Batch 120/549, Loss: 2.1902
Epoch 55/100, Batch 130/549, Loss: 2.0796
Epoch 55/100, Batch 140/549, Loss: 2.1067
Epoch 55/100, Batch 150/549, Loss: 2.1442
Epoch 55/100, Batch 160/549, Loss: 2.1197
Epoch 55/100, Batch 170/549, Loss: 2.1038
Epoch 55/100, Batch 180/549, Loss: 2.0988
Epoch 55/100, Batch 190/549, Loss: 2.0437
Epoch 55/100, Batch 200/549, Loss: 2.1456
Epoch 55/100, Batch 210/549, Loss: 2.0695
Epoch 55/100, Batch 220/549, Loss: 2.0908
Epoch 55/100, Batch 230/549, Loss: 2.1355
Epoch 55/100, Batch 240/549, Loss: 2.0099
Epoch 55/100, Batch 250/549, Loss: 2.0433
Epoch 55/100, Batch 260/549, Loss: 2.0322
Epoch 55/100, Batch 270/549, Loss: 2.0969
Epoch 55/100, Batch 280/549, Loss: 2.1110
Epoch 55/100, Batch 290/549, Loss: 2.1027
Epoch 55/100, Batch 300/549, Loss: 2.1309
Epoch 55/100, Batch 310/549, Loss: 2.1433
Epoch 55/100, Batch 320/549, Loss: 2.0253
Epoch 55/100, Batch 330/549, Loss: 2.0087
Epoch 55/100, Batch 340/549, Loss: 2.0726
Epoch 55/100, Batch 350/549, Loss: 2.1441
Epoch 55/100, Batch 360/549, Loss: 2.1462
Epoch 55/100, Batch 370/549, Loss: 2.0603
Epoch 55/100, Batch 380/549, Loss: 2.1143
Epoch 55/100, Batch 390/549, Loss: 2.0912
Epoch 55/100, Batch 400/549, Loss: 2.1452
Epoch 55/100, Batch 410/549, Loss: 2.0963
Epoch 55/100, Batch 420/549, Loss: 2.1193
Epoch 55/100, Batch 430/549, Loss: 2.1906
Epoch 55/100, Batch 440/549, Loss: 2.1401
Epoch 55/100, Batch 450/549, Loss: 2.1400
Epoch 55/100, Batch 460/549, Loss: 2.1083
Epoch 55/100, Batch 470/549, Loss: 2.0948
Epoch 55/100, Batch 480/549, Loss: 2.0691
Epoch 55/100, Batch 490/549, Loss: 2.1510
Epoch 55/100, Batch 500/549, Loss: 2.0729
Epoch 55/100, Batch 510/549, Loss: 2.1267
Epoch 55/100, Batch 520/549, Loss: 2.0529
Epoch 55/100, Batch 530/549, Loss: 2.0642
Epoch 55/100, Batch 540/549, Loss: 2.0926
New best model with validation loss: 2.0433, perplexity: 7.72
Epoch 55/100, Loss: 2.1092, Perplexity: 8.24, Val Loss: 2.0433, Val Perplexity: 7.72, Time: 1085.71s
Epoch 56/100, Batch 10/549, Loss: 2.0570
Epoch 56/100, Batch 20/549, Loss: 2.1528
Epoch 56/100, Batch 30/549, Loss: 2.2087
Epoch 56/100, Batch 40/549, Loss: 2.1132
Epoch 56/100, Batch 50/549, Loss: 2.0453
Epoch 56/100, Batch 60/549, Loss: 1.9896
Epoch 56/100, Batch 70/549, Loss: 2.0889
Epoch 56/100, Batch 80/549, Loss: 2.0744
Epoch 56/100, Batch 90/549, Loss: 2.0947
Epoch 56/100, Batch 100/549, Loss: 2.1493
Epoch 56/100, Batch 110/549, Loss: 2.1704
Epoch 56/100, Batch 120/549, Loss: 2.1636
Epoch 56/100, Batch 130/549, Loss: 2.0801
Epoch 56/100, Batch 140/549, Loss: 2.0553
Epoch 56/100, Batch 150/549, Loss: 2.1507
Epoch 56/100, Batch 160/549, Loss: 2.1094
Epoch 56/100, Batch 170/549, Loss: 2.1087
Epoch 56/100, Batch 180/549, Loss: 2.1010
Epoch 56/100, Batch 190/549, Loss: 2.0499
Epoch 56/100, Batch 200/549, Loss: 2.0850
Epoch 56/100, Batch 210/549, Loss: 2.0706
Epoch 56/100, Batch 220/549, Loss: 2.0639
Epoch 56/100, Batch 230/549, Loss: 2.1137
Epoch 56/100, Batch 240/549, Loss: 2.0078
Epoch 56/100, Batch 250/549, Loss: 2.0129
Epoch 56/100, Batch 260/549, Loss: 2.0137
Epoch 56/100, Batch 270/549, Loss: 2.0833
Epoch 56/100, Batch 280/549, Loss: 2.0800
Epoch 56/100, Batch 290/549, Loss: 2.1147
Epoch 56/100, Batch 300/549, Loss: 2.1455
Epoch 56/100, Batch 310/549, Loss: 2.1112
Epoch 56/100, Batch 320/549, Loss: 2.0638
Epoch 56/100, Batch 330/549, Loss: 2.0104
Epoch 56/100, Batch 340/549, Loss: 2.0743
Epoch 56/100, Batch 350/549, Loss: 2.1343
Epoch 56/100, Batch 360/549, Loss: 2.1827
Epoch 56/100, Batch 370/549, Loss: 2.0417
Epoch 56/100, Batch 380/549, Loss: 2.1250
Epoch 56/100, Batch 390/549, Loss: 2.0858
Epoch 56/100, Batch 400/549, Loss: 2.1446
Epoch 56/100, Batch 410/549, Loss: 2.0976
Epoch 56/100, Batch 420/549, Loss: 2.1475
Epoch 56/100, Batch 430/549, Loss: 2.1988
Epoch 56/100, Batch 440/549, Loss: 2.1051
Epoch 56/100, Batch 450/549, Loss: 2.1140
Epoch 56/100, Batch 460/549, Loss: 2.1087
Epoch 56/100, Batch 470/549, Loss: 2.0662
Epoch 56/100, Batch 480/549, Loss: 2.0596
Epoch 56/100, Batch 490/549, Loss: 2.1522
Epoch 56/100, Batch 500/549, Loss: 2.0728
Epoch 56/100, Batch 510/549, Loss: 2.1251
Epoch 56/100, Batch 520/549, Loss: 2.1001
Epoch 56/100, Batch 530/549, Loss: 2.0540
Epoch 56/100, Batch 540/549, Loss: 2.0293
New best model with validation loss: 2.0394, perplexity: 7.69
Epoch 56/100, Loss: 2.1045, Perplexity: 8.20, Val Loss: 2.0394, Val Perplexity: 7.69, Time: 1089.64s
Epoch 57/100, Batch 10/549, Loss: 2.0411
Epoch 57/100, Batch 20/549, Loss: 2.1448
Epoch 57/100, Batch 30/549, Loss: 2.1502
Epoch 57/100, Batch 40/549, Loss: 2.1288
Epoch 57/100, Batch 50/549, Loss: 2.0408
Epoch 57/100, Batch 60/549, Loss: 1.9909
Epoch 57/100, Batch 70/549, Loss: 2.0749
Epoch 57/100, Batch 80/549, Loss: 2.0773
Epoch 57/100, Batch 90/549, Loss: 2.1075
Epoch 57/100, Batch 100/549, Loss: 2.1453
Epoch 57/100, Batch 110/549, Loss: 2.1854
Epoch 57/100, Batch 120/549, Loss: 2.1687
Epoch 57/100, Batch 130/549, Loss: 2.0888
Epoch 57/100, Batch 140/549, Loss: 2.0604
Epoch 57/100, Batch 150/549, Loss: 2.1288
Epoch 57/100, Batch 160/549, Loss: 2.1001
Epoch 57/100, Batch 170/549, Loss: 2.2439
Epoch 57/100, Batch 180/549, Loss: 2.1233
Epoch 57/100, Batch 190/549, Loss: 2.0320
Epoch 57/100, Batch 200/549, Loss: 2.0992
Epoch 57/100, Batch 210/549, Loss: 2.0572
Epoch 57/100, Batch 220/549, Loss: 2.0664
Epoch 57/100, Batch 230/549, Loss: 2.1526
Epoch 57/100, Batch 240/549, Loss: 2.0118
Epoch 57/100, Batch 250/549, Loss: 2.0032
Epoch 57/100, Batch 260/549, Loss: 2.0102
Epoch 57/100, Batch 270/549, Loss: 2.0775
Epoch 57/100, Batch 280/549, Loss: 2.0716
Epoch 57/100, Batch 290/549, Loss: 2.0391
Epoch 57/100, Batch 300/549, Loss: 2.1724
Epoch 57/100, Batch 310/549, Loss: 2.1090
Epoch 57/100, Batch 320/549, Loss: 2.0308
Epoch 57/100, Batch 330/549, Loss: 2.0105
Epoch 57/100, Batch 340/549, Loss: 2.0767
Epoch 57/100, Batch 350/549, Loss: 2.1219
Epoch 57/100, Batch 360/549, Loss: 2.1317
Epoch 57/100, Batch 370/549, Loss: 2.0235
Epoch 57/100, Batch 380/549, Loss: 2.1155
Epoch 57/100, Batch 390/549, Loss: 2.0813
Epoch 57/100, Batch 400/549, Loss: 2.1346
Epoch 57/100, Batch 410/549, Loss: 2.0736
Epoch 57/100, Batch 420/549, Loss: 2.1058
Epoch 57/100, Batch 430/549, Loss: 2.1892
Epoch 57/100, Batch 440/549, Loss: 2.0969
Epoch 57/100, Batch 450/549, Loss: 2.1154
Epoch 57/100, Batch 460/549, Loss: 2.1015
Epoch 57/100, Batch 470/549, Loss: 2.0592
Epoch 57/100, Batch 480/549, Loss: 2.0930
Epoch 57/100, Batch 490/549, Loss: 2.1570
Epoch 57/100, Batch 500/549, Loss: 2.0588
Epoch 57/100, Batch 510/549, Loss: 2.1251
Epoch 57/100, Batch 520/549, Loss: 2.0488
Epoch 57/100, Batch 530/549, Loss: 2.0463
Epoch 57/100, Batch 540/549, Loss: 2.0341
Epoch 57/100, Loss: 2.0987, Perplexity: 8.16, Val Loss: 2.0402, Val Perplexity: 7.69, Time: 1089.26s
Epoch 58/100, Batch 10/549, Loss: 2.0338
Epoch 58/100, Batch 20/549, Loss: 2.1384
Epoch 58/100, Batch 30/549, Loss: 2.1617
Epoch 58/100, Batch 40/549, Loss: 2.1050
Epoch 58/100, Batch 50/549, Loss: 2.0608
Epoch 58/100, Batch 60/549, Loss: 2.0071
Epoch 58/100, Batch 70/549, Loss: 2.0864
Epoch 58/100, Batch 80/549, Loss: 2.0760
Epoch 58/100, Batch 90/549, Loss: 2.0769
Epoch 58/100, Batch 100/549, Loss: 2.1327
Epoch 58/100, Batch 110/549, Loss: 2.1848
Epoch 58/100, Batch 120/549, Loss: 2.1663
Epoch 58/100, Batch 130/549, Loss: 2.0809
Epoch 58/100, Batch 140/549, Loss: 2.0437
Epoch 58/100, Batch 150/549, Loss: 2.1281
Epoch 58/100, Batch 160/549, Loss: 2.1071
Epoch 58/100, Batch 170/549, Loss: 2.1172
Epoch 58/100, Batch 180/549, Loss: 2.1087
Epoch 58/100, Batch 190/549, Loss: 2.0167
Epoch 58/100, Batch 200/549, Loss: 2.0801
Epoch 58/100, Batch 210/549, Loss: 2.0527
Epoch 58/100, Batch 220/549, Loss: 2.0535
Epoch 58/100, Batch 230/549, Loss: 2.1480
Epoch 58/100, Batch 240/549, Loss: 2.0011
Epoch 58/100, Batch 250/549, Loss: 1.9940
Epoch 58/100, Batch 260/549, Loss: 2.0348
Epoch 58/100, Batch 270/549, Loss: 2.1032
Epoch 58/100, Batch 280/549, Loss: 2.0736
Epoch 58/100, Batch 290/549, Loss: 2.0314
Epoch 58/100, Batch 300/549, Loss: 2.1205
Epoch 58/100, Batch 310/549, Loss: 2.1122
Epoch 58/100, Batch 320/549, Loss: 2.0148
Epoch 58/100, Batch 330/549, Loss: 1.9901
Epoch 58/100, Batch 340/549, Loss: 2.0692
Epoch 58/100, Batch 350/549, Loss: 2.1268
Epoch 58/100, Batch 360/549, Loss: 2.1351
Epoch 58/100, Batch 370/549, Loss: 2.0565
Epoch 58/100, Batch 380/549, Loss: 2.0967
Epoch 58/100, Batch 390/549, Loss: 2.0810
Epoch 58/100, Batch 400/549, Loss: 2.1346
Epoch 58/100, Batch 410/549, Loss: 2.0903
Epoch 58/100, Batch 420/549, Loss: 2.0889
Epoch 58/100, Batch 430/549, Loss: 2.2249
Epoch 58/100, Batch 440/549, Loss: 2.1354
Epoch 58/100, Batch 450/549, Loss: 2.1207
Epoch 58/100, Batch 460/549, Loss: 2.0888
Epoch 58/100, Batch 470/549, Loss: 2.0464
Epoch 58/100, Batch 480/549, Loss: 2.0506
Epoch 58/100, Batch 490/549, Loss: 2.1356
Epoch 58/100, Batch 500/549, Loss: 2.0816
Epoch 58/100, Batch 510/549, Loss: 2.1112
Epoch 58/100, Batch 520/549, Loss: 2.0487
Epoch 58/100, Batch 530/549, Loss: 2.0504
Epoch 58/100, Batch 540/549, Loss: 2.0297
New best model with validation loss: 2.0361, perplexity: 7.66
Epoch 58/100, Loss: 2.0940, Perplexity: 8.12, Val Loss: 2.0361, Val Perplexity: 7.66, Time: 1089.42s
Epoch 59/100, Batch 10/549, Loss: 2.0314
Epoch 59/100, Batch 20/549, Loss: 2.1315
Epoch 59/100, Batch 30/549, Loss: 2.1490
Epoch 59/100, Batch 40/549, Loss: 2.1064
Epoch 59/100, Batch 50/549, Loss: 2.0370
Epoch 59/100, Batch 60/549, Loss: 1.9775
Epoch 59/100, Batch 70/549, Loss: 2.0836
Epoch 59/100, Batch 80/549, Loss: 2.0710
Epoch 59/100, Batch 90/549, Loss: 2.0725
Epoch 59/100, Batch 100/549, Loss: 2.1327
Epoch 59/100, Batch 110/549, Loss: 2.1352
Epoch 59/100, Batch 120/549, Loss: 2.2100
Epoch 59/100, Batch 130/549, Loss: 2.0723
Epoch 59/100, Batch 140/549, Loss: 2.0541
Epoch 59/100, Batch 150/549, Loss: 2.1270
Epoch 59/100, Batch 160/549, Loss: 2.0852
Epoch 59/100, Batch 170/549, Loss: 2.1315
Epoch 59/100, Batch 180/549, Loss: 2.0807
Epoch 59/100, Batch 190/549, Loss: 2.0639
Epoch 59/100, Batch 200/549, Loss: 2.0739
Epoch 59/100, Batch 210/549, Loss: 2.0442
Epoch 59/100, Batch 220/549, Loss: 2.0547
Epoch 59/100, Batch 230/549, Loss: 2.0969
Epoch 59/100, Batch 240/549, Loss: 1.9878
Epoch 59/100, Batch 250/549, Loss: 1.9995
Epoch 59/100, Batch 260/549, Loss: 2.0051
Epoch 59/100, Batch 270/549, Loss: 2.0604
Epoch 59/100, Batch 280/549, Loss: 2.0730
Epoch 59/100, Batch 290/549, Loss: 2.0343
Epoch 59/100, Batch 300/549, Loss: 2.1627
Epoch 59/100, Batch 310/549, Loss: 2.1085
Epoch 59/100, Batch 320/549, Loss: 2.0250
Epoch 59/100, Batch 330/549, Loss: 1.9922
Epoch 59/100, Batch 340/549, Loss: 2.0627
Epoch 59/100, Batch 350/549, Loss: 2.1195
Epoch 59/100, Batch 360/549, Loss: 2.1275
Epoch 59/100, Batch 370/549, Loss: 2.0247
Epoch 59/100, Batch 380/549, Loss: 2.1029
Epoch 59/100, Batch 390/549, Loss: 2.1297
Epoch 59/100, Batch 400/549, Loss: 2.1382
Epoch 59/100, Batch 410/549, Loss: 2.0709
Epoch 59/100, Batch 420/549, Loss: 2.0938
Epoch 59/100, Batch 430/549, Loss: 2.1798
Epoch 59/100, Batch 440/549, Loss: 2.1161
Epoch 59/100, Batch 450/549, Loss: 2.1830
Epoch 59/100, Batch 460/549, Loss: 2.0907
Epoch 59/100, Batch 470/549, Loss: 2.0496
Epoch 59/100, Batch 480/549, Loss: 2.0582
Epoch 59/100, Batch 490/549, Loss: 2.1432
Epoch 59/100, Batch 500/549, Loss: 2.0602
Epoch 59/100, Batch 510/549, Loss: 2.0926
Epoch 59/100, Batch 520/549, Loss: 2.0442
Epoch 59/100, Batch 530/549, Loss: 2.0499
Epoch 59/100, Batch 540/549, Loss: 2.0266
Epoch 59/100, Loss: 2.0899, Perplexity: 8.08, Val Loss: 2.0363, Val Perplexity: 7.66, Time: 1087.27s
Epoch 60/100, Batch 10/549, Loss: 2.0332
Epoch 60/100, Batch 20/549, Loss: 2.1311
Epoch 60/100, Batch 30/549, Loss: 2.1496
Epoch 60/100, Batch 40/549, Loss: 2.0892
Epoch 60/100, Batch 50/549, Loss: 2.0318
Epoch 60/100, Batch 60/549, Loss: 1.9813
Epoch 60/100, Batch 70/549, Loss: 2.0610
Epoch 60/100, Batch 80/549, Loss: 2.0610
Epoch 60/100, Batch 90/549, Loss: 2.0608
Epoch 60/100, Batch 100/549, Loss: 2.1289
Epoch 60/100, Batch 110/549, Loss: 2.1441
Epoch 60/100, Batch 120/549, Loss: 2.1519
Epoch 60/100, Batch 130/549, Loss: 2.0720
Epoch 60/100, Batch 140/549, Loss: 2.0551
Epoch 60/100, Batch 150/549, Loss: 2.1435
Epoch 60/100, Batch 160/549, Loss: 2.0906
Epoch 60/100, Batch 170/549, Loss: 2.0782
Epoch 60/100, Batch 180/549, Loss: 2.0819
Epoch 60/100, Batch 190/549, Loss: 2.0178
Epoch 60/100, Batch 200/549, Loss: 2.0683
Epoch 60/100, Batch 210/549, Loss: 2.0513
Epoch 60/100, Batch 220/549, Loss: 2.0322
Epoch 60/100, Batch 230/549, Loss: 2.0923
Epoch 60/100, Batch 240/549, Loss: 2.0073
Epoch 60/100, Batch 250/549, Loss: 2.0291
Epoch 60/100, Batch 260/549, Loss: 2.0150
Epoch 60/100, Batch 270/549, Loss: 2.0579
Epoch 60/100, Batch 280/549, Loss: 2.0964
Epoch 60/100, Batch 290/549, Loss: 2.0271
Epoch 60/100, Batch 300/549, Loss: 2.1088
Epoch 60/100, Batch 310/549, Loss: 2.1016
Epoch 60/100, Batch 320/549, Loss: 2.0033
Epoch 60/100, Batch 330/549, Loss: 2.0601
Epoch 60/100, Batch 340/549, Loss: 2.0508
Epoch 60/100, Batch 350/549, Loss: 2.1054
Epoch 60/100, Batch 360/549, Loss: 2.1335
Epoch 60/100, Batch 370/549, Loss: 2.0231
Epoch 60/100, Batch 380/549, Loss: 2.1014
Epoch 60/100, Batch 390/549, Loss: 2.1630
Epoch 60/100, Batch 400/549, Loss: 2.1157
Epoch 60/100, Batch 410/549, Loss: 2.0804
Epoch 60/100, Batch 420/549, Loss: 2.0820
Epoch 60/100, Batch 430/549, Loss: 2.1738
Epoch 60/100, Batch 440/549, Loss: 2.0832
Epoch 60/100, Batch 450/549, Loss: 2.1033
Epoch 60/100, Batch 460/549, Loss: 2.0776
Epoch 60/100, Batch 470/549, Loss: 2.0370
Epoch 60/100, Batch 480/549, Loss: 2.0826
Epoch 60/100, Batch 490/549, Loss: 2.1300
Epoch 60/100, Batch 500/549, Loss: 2.0476
Epoch 60/100, Batch 510/549, Loss: 2.1097
Epoch 60/100, Batch 520/549, Loss: 2.0400
Epoch 60/100, Batch 530/549, Loss: 2.0346
Epoch 60/100, Batch 540/549, Loss: 2.0535
New best model with validation loss: 2.0335, perplexity: 7.64
Epoch 60/100, Loss: 2.0856, Perplexity: 8.05, Val Loss: 2.0335, Val Perplexity: 7.64, Time: 1087.46s
Epoch 61/100, Batch 10/549, Loss: 2.0146
Epoch 61/100, Batch 20/549, Loss: 2.1172
Epoch 61/100, Batch 30/549, Loss: 2.1265
Epoch 61/100, Batch 40/549, Loss: 2.0995
Epoch 61/100, Batch 50/549, Loss: 2.0192
Epoch 61/100, Batch 60/549, Loss: 1.9646
Epoch 61/100, Batch 70/549, Loss: 2.0590
Epoch 61/100, Batch 80/549, Loss: 2.0910
Epoch 61/100, Batch 90/549, Loss: 2.0676
Epoch 61/100, Batch 100/549, Loss: 2.1469
Epoch 61/100, Batch 110/549, Loss: 2.1691
Epoch 61/100, Batch 120/549, Loss: 2.1522
Epoch 61/100, Batch 130/549, Loss: 2.0614
Epoch 61/100, Batch 140/549, Loss: 2.0837
Epoch 61/100, Batch 150/549, Loss: 2.1161
Epoch 61/100, Batch 160/549, Loss: 2.1313
Epoch 61/100, Batch 170/549, Loss: 2.0773
Epoch 61/100, Batch 180/549, Loss: 2.0742
Epoch 61/100, Batch 190/549, Loss: 2.0145
Epoch 61/100, Batch 200/549, Loss: 2.0615
Epoch 61/100, Batch 210/549, Loss: 2.0420
Epoch 61/100, Batch 220/549, Loss: 2.0415
Epoch 61/100, Batch 230/549, Loss: 2.1165
Epoch 61/100, Batch 240/549, Loss: 1.9882
Epoch 61/100, Batch 250/549, Loss: 2.0028
Epoch 61/100, Batch 260/549, Loss: 2.0012
Epoch 61/100, Batch 270/549, Loss: 2.0786
Epoch 61/100, Batch 280/549, Loss: 2.0659
Epoch 61/100, Batch 290/549, Loss: 2.0334
Epoch 61/100, Batch 300/549, Loss: 2.0954
Epoch 61/100, Batch 310/549, Loss: 2.1370
Epoch 61/100, Batch 320/549, Loss: 2.0054
Epoch 61/100, Batch 330/549, Loss: 1.9821
Epoch 61/100, Batch 340/549, Loss: 2.0487
Epoch 61/100, Batch 350/549, Loss: 2.1081
Epoch 61/100, Batch 360/549, Loss: 2.1251
Epoch 61/100, Batch 370/549, Loss: 2.0134
Epoch 61/100, Batch 380/549, Loss: 2.1171
Epoch 61/100, Batch 390/549, Loss: 2.0685
Epoch 61/100, Batch 400/549, Loss: 2.1116
Epoch 61/100, Batch 410/549, Loss: 2.0762
Epoch 61/100, Batch 420/549, Loss: 2.1009
Epoch 61/100, Batch 430/549, Loss: 2.1969
Epoch 61/100, Batch 440/549, Loss: 2.0811
Epoch 61/100, Batch 450/549, Loss: 2.1033
Epoch 61/100, Batch 460/549, Loss: 2.0897
Epoch 61/100, Batch 470/549, Loss: 2.0910
Epoch 61/100, Batch 480/549, Loss: 2.0593
Epoch 61/100, Batch 490/549, Loss: 2.1620
Epoch 61/100, Batch 500/549, Loss: 2.0441
Epoch 61/100, Batch 510/549, Loss: 2.1015
Epoch 61/100, Batch 520/549, Loss: 2.0425
Epoch 61/100, Batch 530/549, Loss: 2.0338
Epoch 61/100, Batch 540/549, Loss: 2.0181
New best model with validation loss: 2.0329, perplexity: 7.64
Epoch 61/100, Loss: 2.0813, Perplexity: 8.01, Val Loss: 2.0329, Val Perplexity: 7.64, Time: 1086.73s
Epoch 62/100, Batch 10/549, Loss: 2.0149
Epoch 62/100, Batch 20/549, Loss: 2.1506
Epoch 62/100, Batch 30/549, Loss: 2.1346
Epoch 62/100, Batch 40/549, Loss: 2.0716
Epoch 62/100, Batch 50/549, Loss: 2.0259
Epoch 62/100, Batch 60/549, Loss: 1.9557
Epoch 62/100, Batch 70/549, Loss: 2.0530
Epoch 62/100, Batch 80/549, Loss: 2.0530
Epoch 62/100, Batch 90/549, Loss: 2.0595
Epoch 62/100, Batch 100/549, Loss: 2.1214
Epoch 62/100, Batch 110/549, Loss: 2.1302
Epoch 62/100, Batch 120/549, Loss: 2.1435
Epoch 62/100, Batch 130/549, Loss: 2.0539
Epoch 62/100, Batch 140/549, Loss: 2.0379
Epoch 62/100, Batch 150/549, Loss: 2.1193
Epoch 62/100, Batch 160/549, Loss: 2.0878
Epoch 62/100, Batch 170/549, Loss: 2.0715
Epoch 62/100, Batch 180/549, Loss: 2.0815
Epoch 62/100, Batch 190/549, Loss: 2.0469
Epoch 62/100, Batch 200/549, Loss: 2.0581
Epoch 62/100, Batch 210/549, Loss: 2.0395
Epoch 62/100, Batch 220/549, Loss: 2.0264
Epoch 62/100, Batch 230/549, Loss: 2.0882
Epoch 62/100, Batch 240/549, Loss: 2.0026
Epoch 62/100, Batch 250/549, Loss: 1.9884
Epoch 62/100, Batch 260/549, Loss: 1.9938
Epoch 62/100, Batch 270/549, Loss: 2.0587
Epoch 62/100, Batch 280/549, Loss: 2.0574
Epoch 62/100, Batch 290/549, Loss: 2.0184
Epoch 62/100, Batch 300/549, Loss: 2.0826
Epoch 62/100, Batch 310/549, Loss: 2.1090
Epoch 62/100, Batch 320/549, Loss: 2.0087
Epoch 62/100, Batch 330/549, Loss: 1.9914
Epoch 62/100, Batch 340/549, Loss: 2.0432
Epoch 62/100, Batch 350/549, Loss: 2.1078
Epoch 62/100, Batch 360/549, Loss: 2.1204
Epoch 62/100, Batch 370/549, Loss: 2.0090
Epoch 62/100, Batch 380/549, Loss: 2.0999
Epoch 62/100, Batch 390/549, Loss: 2.0651
Epoch 62/100, Batch 400/549, Loss: 2.1061
Epoch 62/100, Batch 410/549, Loss: 2.1139
Epoch 62/100, Batch 420/549, Loss: 2.0876
Epoch 62/100, Batch 430/549, Loss: 2.2027
Epoch 62/100, Batch 440/549, Loss: 2.1162
Epoch 62/100, Batch 450/549, Loss: 2.0982
Epoch 62/100, Batch 460/549, Loss: 2.0669
Epoch 62/100, Batch 470/549, Loss: 2.0404
Epoch 62/100, Batch 480/549, Loss: 2.0457
Epoch 62/100, Batch 490/549, Loss: 2.1215
Epoch 62/100, Batch 500/549, Loss: 2.0560
Epoch 62/100, Batch 510/549, Loss: 2.1011
Epoch 62/100, Batch 520/549, Loss: 2.0374
Epoch 62/100, Batch 530/549, Loss: 2.0333
Epoch 62/100, Batch 540/549, Loss: 2.0160
Epoch 62/100, Loss: 2.0783, Perplexity: 7.99, Val Loss: 2.0351, Val Perplexity: 7.65, Time: 1090.05s
Epoch 63/100, Batch 10/549, Loss: 2.0133
Epoch 63/100, Batch 20/549, Loss: 2.1186
Epoch 63/100, Batch 30/549, Loss: 2.1545
Epoch 63/100, Batch 40/549, Loss: 2.0749
Epoch 63/100, Batch 50/549, Loss: 2.0199
Epoch 63/100, Batch 60/549, Loss: 1.9643
Epoch 63/100, Batch 70/549, Loss: 2.0521
Epoch 63/100, Batch 80/549, Loss: 2.0862
Epoch 63/100, Batch 90/549, Loss: 2.0730
Epoch 63/100, Batch 100/549, Loss: 2.1262
Epoch 63/100, Batch 110/549, Loss: 2.1333
Epoch 63/100, Batch 120/549, Loss: 2.1282
Epoch 63/100, Batch 130/549, Loss: 2.0594
Epoch 63/100, Batch 140/549, Loss: 2.0330
Epoch 63/100, Batch 150/549, Loss: 2.1112
Epoch 63/100, Batch 160/549, Loss: 2.0747
Epoch 63/100, Batch 170/549, Loss: 2.0614
Epoch 63/100, Batch 180/549, Loss: 2.0620
Epoch 63/100, Batch 190/549, Loss: 2.0052
Epoch 63/100, Batch 200/549, Loss: 2.0605
Epoch 63/100, Batch 210/549, Loss: 2.0379
Epoch 63/100, Batch 220/549, Loss: 2.0277
Epoch 63/100, Batch 230/549, Loss: 2.0795
Epoch 63/100, Batch 240/549, Loss: 1.9817
Epoch 63/100, Batch 250/549, Loss: 2.0136
Epoch 63/100, Batch 260/549, Loss: 1.9922
Epoch 63/100, Batch 270/549, Loss: 2.0880
Epoch 63/100, Batch 280/549, Loss: 2.0503
Epoch 63/100, Batch 290/549, Loss: 2.0335
Epoch 63/100, Batch 300/549, Loss: 2.0905
Epoch 63/100, Batch 310/549, Loss: 2.0912
Epoch 63/100, Batch 320/549, Loss: 2.0158
Epoch 63/100, Batch 330/549, Loss: 1.9840
Epoch 63/100, Batch 340/549, Loss: 2.0407
Epoch 63/100, Batch 350/549, Loss: 2.1167
Epoch 63/100, Batch 360/549, Loss: 2.1153
Epoch 63/100, Batch 370/549, Loss: 2.0252
Epoch 63/100, Batch 380/549, Loss: 2.0846
Epoch 63/100, Batch 390/549, Loss: 2.0599
Epoch 63/100, Batch 400/549, Loss: 2.1198
Epoch 63/100, Batch 410/549, Loss: 2.0596
Epoch 63/100, Batch 420/549, Loss: 2.0689
Epoch 63/100, Batch 430/549, Loss: 2.1897
Epoch 63/100, Batch 440/549, Loss: 2.0843
Epoch 63/100, Batch 450/549, Loss: 2.0906
Epoch 63/100, Batch 460/549, Loss: 2.1170
Epoch 63/100, Batch 470/549, Loss: 2.0248
Epoch 63/100, Batch 480/549, Loss: 2.0678
Epoch 63/100, Batch 490/549, Loss: 2.1197
Epoch 63/100, Batch 500/549, Loss: 2.0446
Epoch 63/100, Batch 510/549, Loss: 2.1599
Epoch 63/100, Batch 520/549, Loss: 2.0325
Epoch 63/100, Batch 530/549, Loss: 2.0454
Epoch 63/100, Batch 540/549, Loss: 2.0079
New best model with validation loss: 2.0308, perplexity: 7.62
Epoch 63/100, Loss: 2.0767, Perplexity: 7.98, Val Loss: 2.0308, Val Perplexity: 7.62, Time: 1083.52s
Epoch 64/100, Batch 10/549, Loss: 2.0043
Epoch 64/100, Batch 20/549, Loss: 2.1294
Epoch 64/100, Batch 30/549, Loss: 2.1255
Epoch 64/100, Batch 40/549, Loss: 2.0706
Epoch 64/100, Batch 50/549, Loss: 2.0107
Epoch 64/100, Batch 60/549, Loss: 1.9659
Epoch 64/100, Batch 70/549, Loss: 2.0984
Epoch 64/100, Batch 80/549, Loss: 2.0474
Epoch 64/100, Batch 90/549, Loss: 2.0554
Epoch 64/100, Batch 100/549, Loss: 2.1219
Epoch 64/100, Batch 110/549, Loss: 2.1245
Epoch 64/100, Batch 120/549, Loss: 2.1403
Epoch 64/100, Batch 130/549, Loss: 2.0943
Epoch 64/100, Batch 140/549, Loss: 2.0666
Epoch 64/100, Batch 150/549, Loss: 2.1186
Epoch 64/100, Batch 160/549, Loss: 2.0747
Epoch 64/100, Batch 170/549, Loss: 2.0760
Epoch 64/100, Batch 180/549, Loss: 2.0601
Epoch 64/100, Batch 190/549, Loss: 1.9908
Epoch 64/100, Batch 200/549, Loss: 2.1213
Epoch 64/100, Batch 210/549, Loss: 2.0411
Epoch 64/100, Batch 220/549, Loss: 2.0251
Epoch 64/100, Batch 230/549, Loss: 2.0778
Epoch 64/100, Batch 240/549, Loss: 2.0154
Epoch 64/100, Batch 250/549, Loss: 2.0154
Epoch 64/100, Batch 260/549, Loss: 2.0181
Epoch 64/100, Batch 270/549, Loss: 2.0528
Epoch 64/100, Batch 280/549, Loss: 2.0542
Epoch 64/100, Batch 290/549, Loss: 2.0556
Epoch 64/100, Batch 300/549, Loss: 2.0979
Epoch 64/100, Batch 310/549, Loss: 2.0962
Epoch 64/100, Batch 320/549, Loss: 2.0417
Epoch 64/100, Batch 330/549, Loss: 1.9800
Epoch 64/100, Batch 340/549, Loss: 2.0381
Epoch 64/100, Batch 350/549, Loss: 2.0962
Epoch 64/100, Batch 360/549, Loss: 2.1116
Epoch 64/100, Batch 370/549, Loss: 2.0031
Epoch 64/100, Batch 380/549, Loss: 2.1101
Epoch 64/100, Batch 390/549, Loss: 2.0565
Epoch 64/100, Batch 400/549, Loss: 2.1065
Epoch 64/100, Batch 410/549, Loss: 2.0532
Epoch 64/100, Batch 420/549, Loss: 2.0757
Epoch 64/100, Batch 430/549, Loss: 2.1718
Epoch 64/100, Batch 440/549, Loss: 2.0694
Epoch 64/100, Batch 450/549, Loss: 2.0916
Epoch 64/100, Batch 460/549, Loss: 2.0750
Epoch 64/100, Batch 470/549, Loss: 2.0286
Epoch 64/100, Batch 480/549, Loss: 2.0293
Epoch 64/100, Batch 490/549, Loss: 2.1100
Epoch 64/100, Batch 500/549, Loss: 2.0294
Epoch 64/100, Batch 510/549, Loss: 2.0793
Epoch 64/100, Batch 520/549, Loss: 2.0946
Epoch 64/100, Batch 530/549, Loss: 2.0280
Epoch 64/100, Batch 540/549, Loss: 1.9982
New best model with validation loss: 2.0256, perplexity: 7.58
Epoch 64/100, Loss: 2.0722, Perplexity: 7.94, Val Loss: 2.0256, Val Perplexity: 7.58, Time: 1088.01s
Epoch 65/100, Batch 10/549, Loss: 2.0045
Epoch 65/100, Batch 20/549, Loss: 2.1465
Epoch 65/100, Batch 30/549, Loss: 2.1650
Epoch 65/100, Batch 40/549, Loss: 2.0819
Epoch 65/100, Batch 50/549, Loss: 2.0021
Epoch 65/100, Batch 60/549, Loss: 1.9424
Epoch 65/100, Batch 70/549, Loss: 2.0444
Epoch 65/100, Batch 80/549, Loss: 2.0446
Epoch 65/100, Batch 90/549, Loss: 2.0480
Epoch 65/100, Batch 100/549, Loss: 2.1160
Epoch 65/100, Batch 110/549, Loss: 2.1101
Epoch 65/100, Batch 120/549, Loss: 2.1310
Epoch 65/100, Batch 130/549, Loss: 2.0588
Epoch 65/100, Batch 140/549, Loss: 2.0186
Epoch 65/100, Batch 150/549, Loss: 2.1133
Epoch 65/100, Batch 160/549, Loss: 2.1064
Epoch 65/100, Batch 170/549, Loss: 2.0913
Epoch 65/100, Batch 180/549, Loss: 2.0758
Epoch 65/100, Batch 190/549, Loss: 2.0754
Epoch 65/100, Batch 200/549, Loss: 2.0633
Epoch 65/100, Batch 210/549, Loss: 2.0318
Epoch 65/100, Batch 220/549, Loss: 2.0629
Epoch 65/100, Batch 230/549, Loss: 2.0742
Epoch 65/100, Batch 240/549, Loss: 1.9713
Epoch 65/100, Batch 250/549, Loss: 2.0091
Epoch 65/100, Batch 260/549, Loss: 1.9856
Epoch 65/100, Batch 270/549, Loss: 2.0373
Epoch 65/100, Batch 280/549, Loss: 2.0507
Epoch 65/100, Batch 290/549, Loss: 2.0128
Epoch 65/100, Batch 300/549, Loss: 2.0897
Epoch 65/100, Batch 310/549, Loss: 2.0788
Epoch 65/100, Batch 320/549, Loss: 1.9971
Epoch 65/100, Batch 330/549, Loss: 2.0314
Epoch 65/100, Batch 340/549, Loss: 2.0264
Epoch 65/100, Batch 350/549, Loss: 2.0941
Epoch 65/100, Batch 360/549, Loss: 2.1566
Epoch 65/100, Batch 370/549, Loss: 2.0376
Epoch 65/100, Batch 380/549, Loss: 2.0857
Epoch 65/100, Batch 390/549, Loss: 2.0556
Epoch 65/100, Batch 400/549, Loss: 2.1102
Epoch 65/100, Batch 410/549, Loss: 2.0548
Epoch 65/100, Batch 420/549, Loss: 2.0587
Epoch 65/100, Batch 430/549, Loss: 2.1533
Epoch 65/100, Batch 440/549, Loss: 2.0675
Epoch 65/100, Batch 450/549, Loss: 2.0819
Epoch 65/100, Batch 460/549, Loss: 2.0658
Epoch 65/100, Batch 470/549, Loss: 2.0270
Epoch 65/100, Batch 480/549, Loss: 2.0250
Epoch 65/100, Batch 490/549, Loss: 2.1531
Epoch 65/100, Batch 500/549, Loss: 2.0419
Epoch 65/100, Batch 510/549, Loss: 2.1384
Epoch 65/100, Batch 520/549, Loss: 2.0200
Epoch 65/100, Batch 530/549, Loss: 2.0256
Epoch 65/100, Batch 540/549, Loss: 1.9958
Epoch 65/100, Loss: 2.0673, Perplexity: 7.90, Val Loss: 2.0300, Val Perplexity: 7.61, Time: 1086.51s
Epoch 66/100, Batch 10/549, Loss: 2.0016
Epoch 66/100, Batch 20/549, Loss: 2.0943
Epoch 66/100, Batch 30/549, Loss: 2.1168
Epoch 66/100, Batch 40/549, Loss: 2.0690
Epoch 66/100, Batch 50/549, Loss: 2.0374
Epoch 66/100, Batch 60/549, Loss: 2.0026
Epoch 66/100, Batch 70/549, Loss: 2.0458
Epoch 66/100, Batch 80/549, Loss: 2.0409
Epoch 66/100, Batch 90/549, Loss: 2.0572
Epoch 66/100, Batch 100/549, Loss: 2.1012
Epoch 66/100, Batch 110/549, Loss: 2.1216
Epoch 66/100, Batch 120/549, Loss: 2.1274
Epoch 66/100, Batch 130/549, Loss: 2.0463
Epoch 66/100, Batch 140/549, Loss: 2.0174
Epoch 66/100, Batch 150/549, Loss: 2.0974
Epoch 66/100, Batch 160/549, Loss: 2.0727
Epoch 66/100, Batch 170/549, Loss: 2.1346
Epoch 66/100, Batch 180/549, Loss: 2.0560
Epoch 66/100, Batch 190/549, Loss: 2.0458
Epoch 66/100, Batch 200/549, Loss: 2.0488
Epoch 66/100, Batch 210/549, Loss: 2.0274
Epoch 66/100, Batch 220/549, Loss: 2.0458
Epoch 66/100, Batch 230/549, Loss: 2.0974
Epoch 66/100, Batch 240/549, Loss: 1.9710
Epoch 66/100, Batch 250/549, Loss: 1.9768
Epoch 66/100, Batch 260/549, Loss: 1.9843
Epoch 66/100, Batch 270/549, Loss: 2.0427
Epoch 66/100, Batch 280/549, Loss: 2.0484
Epoch 66/100, Batch 290/549, Loss: 2.0151
Epoch 66/100, Batch 300/549, Loss: 2.1036
Epoch 66/100, Batch 310/549, Loss: 2.0904
Epoch 66/100, Batch 320/549, Loss: 1.9783
Epoch 66/100, Batch 330/549, Loss: 1.9631
Epoch 66/100, Batch 340/549, Loss: 2.0492
Epoch 66/100, Batch 350/549, Loss: 2.0928
Epoch 66/100, Batch 360/549, Loss: 2.1670
Epoch 66/100, Batch 370/549, Loss: 1.9971
Epoch 66/100, Batch 380/549, Loss: 2.0765
Epoch 66/100, Batch 390/549, Loss: 2.0685
Epoch 66/100, Batch 400/549, Loss: 2.0999
Epoch 66/100, Batch 410/549, Loss: 2.0467
Epoch 66/100, Batch 420/549, Loss: 2.0655
Epoch 66/100, Batch 430/549, Loss: 2.1571
Epoch 66/100, Batch 440/549, Loss: 2.0788
Epoch 66/100, Batch 450/549, Loss: 2.0703
Epoch 66/100, Batch 460/549, Loss: 2.0456
Epoch 66/100, Batch 470/549, Loss: 2.0315
Epoch 66/100, Batch 480/549, Loss: 2.0218
Epoch 66/100, Batch 490/549, Loss: 2.1043
Epoch 66/100, Batch 500/549, Loss: 2.0204
Epoch 66/100, Batch 510/549, Loss: 2.0816
Epoch 66/100, Batch 520/549, Loss: 2.0218
Epoch 66/100, Batch 530/549, Loss: 2.0618
Epoch 66/100, Batch 540/549, Loss: 2.0048
Epoch 66/100, Loss: 2.0647, Perplexity: 7.88, Val Loss: 2.0285, Val Perplexity: 7.60, Time: 1085.84s
Epoch 67/100, Batch 10/549, Loss: 1.9930
Epoch 67/100, Batch 20/549, Loss: 2.0870
Epoch 67/100, Batch 30/549, Loss: 2.1131
Epoch 67/100, Batch 40/549, Loss: 2.0557
Epoch 67/100, Batch 50/549, Loss: 2.0026
Epoch 67/100, Batch 60/549, Loss: 1.9439
Epoch 67/100, Batch 70/549, Loss: 2.0401
Epoch 67/100, Batch 80/549, Loss: 2.0354
Epoch 67/100, Batch 90/549, Loss: 2.0494
Epoch 67/100, Batch 100/549, Loss: 2.1793
Epoch 67/100, Batch 110/549, Loss: 2.1121
Epoch 67/100, Batch 120/549, Loss: 2.1300
Epoch 67/100, Batch 130/549, Loss: 2.0560
Epoch 67/100, Batch 140/549, Loss: 2.0527
Epoch 67/100, Batch 150/549, Loss: 2.1158
Epoch 67/100, Batch 160/549, Loss: 2.0614
Epoch 67/100, Batch 170/549, Loss: 2.0567
Epoch 67/100, Batch 180/549, Loss: 2.1015
Epoch 67/100, Batch 190/549, Loss: 2.0129
Epoch 67/100, Batch 200/549, Loss: 2.0658
Epoch 67/100, Batch 210/549, Loss: 2.0243
Epoch 67/100, Batch 220/549, Loss: 2.0347
Epoch 67/100, Batch 230/549, Loss: 2.0729
Epoch 67/100, Batch 240/549, Loss: 1.9732
Epoch 67/100, Batch 250/549, Loss: 1.9763
Epoch 67/100, Batch 260/549, Loss: 2.0216
Epoch 67/100, Batch 270/549, Loss: 2.0349
Epoch 67/100, Batch 280/549, Loss: 2.0445
Epoch 67/100, Batch 290/549, Loss: 2.0047
Epoch 67/100, Batch 300/549, Loss: 2.0848
Epoch 67/100, Batch 310/549, Loss: 2.0782
Epoch 67/100, Batch 320/549, Loss: 2.0019
Epoch 67/100, Batch 330/549, Loss: 1.9740
Epoch 67/100, Batch 340/549, Loss: 2.0325
Epoch 67/100, Batch 350/549, Loss: 2.1027
Epoch 67/100, Batch 360/549, Loss: 2.0958
Epoch 67/100, Batch 370/549, Loss: 1.9886
Epoch 67/100, Batch 380/549, Loss: 2.0729
Epoch 67/100, Batch 390/549, Loss: 2.0406
Epoch 67/100, Batch 400/549, Loss: 2.0977
Epoch 67/100, Batch 410/549, Loss: 2.0505
Epoch 67/100, Batch 420/549, Loss: 2.0848
Epoch 67/100, Batch 430/549, Loss: 2.1477
Epoch 67/100, Batch 440/549, Loss: 2.0645
Epoch 67/100, Batch 450/549, Loss: 2.0811
Epoch 67/100, Batch 460/549, Loss: 2.0717
Epoch 67/100, Batch 470/549, Loss: 2.0219
Epoch 67/100, Batch 480/549, Loss: 2.0211
Epoch 67/100, Batch 490/549, Loss: 2.1042
Epoch 67/100, Batch 500/549, Loss: 2.0316
Epoch 67/100, Batch 510/549, Loss: 2.0785
Epoch 67/100, Batch 520/549, Loss: 2.0045
Epoch 67/100, Batch 530/549, Loss: 2.0063
Epoch 67/100, Batch 540/549, Loss: 1.9882
Epoch 67/100, Loss: 2.0620, Perplexity: 7.86, Val Loss: 2.0289, Val Perplexity: 7.61, Time: 1080.96s
Epoch 68/100, Batch 10/549, Loss: 1.9909
Epoch 68/100, Batch 20/549, Loss: 2.0941
Epoch 68/100, Batch 30/549, Loss: 2.1347
Epoch 68/100, Batch 40/549, Loss: 2.1727
Epoch 68/100, Batch 50/549, Loss: 1.9987
Epoch 68/100, Batch 60/549, Loss: 1.9371
Epoch 68/100, Batch 70/549, Loss: 2.0832
Epoch 68/100, Batch 80/549, Loss: 2.0868
Epoch 68/100, Batch 90/549, Loss: 2.0696
Epoch 68/100, Batch 100/549, Loss: 2.0948
Epoch 68/100, Batch 110/549, Loss: 2.1457
Epoch 68/100, Batch 120/549, Loss: 2.1301
Epoch 68/100, Batch 130/549, Loss: 2.0385
Epoch 68/100, Batch 140/549, Loss: 2.0092
Epoch 68/100, Batch 150/549, Loss: 2.0868
Epoch 68/100, Batch 160/549, Loss: 2.0554
Epoch 68/100, Batch 170/549, Loss: 2.0506
Epoch 68/100, Batch 180/549, Loss: 2.0446
Epoch 68/100, Batch 190/549, Loss: 2.0239
Epoch 68/100, Batch 200/549, Loss: 2.0378
Epoch 68/100, Batch 210/549, Loss: 2.0194
Epoch 68/100, Batch 220/549, Loss: 2.0024
Epoch 68/100, Batch 230/549, Loss: 2.0727
Epoch 68/100, Batch 240/549, Loss: 1.9670
Epoch 68/100, Batch 250/549, Loss: 1.9757
Epoch 68/100, Batch 260/549, Loss: 1.9644
Epoch 68/100, Batch 270/549, Loss: 2.0376
Epoch 68/100, Batch 280/549, Loss: 2.0458
Epoch 68/100, Batch 290/549, Loss: 2.0002
Epoch 68/100, Batch 300/549, Loss: 2.1052
Epoch 68/100, Batch 310/549, Loss: 2.0736
Epoch 68/100, Batch 320/549, Loss: 2.0130
Epoch 68/100, Batch 330/549, Loss: 2.0470
Epoch 68/100, Batch 340/549, Loss: 2.0569
Epoch 68/100, Batch 350/549, Loss: 2.0909
Epoch 68/100, Batch 360/549, Loss: 2.1212
Epoch 68/100, Batch 370/549, Loss: 1.9837
Epoch 68/100, Batch 380/549, Loss: 2.0694
Epoch 68/100, Batch 390/549, Loss: 2.0878
Epoch 68/100, Batch 400/549, Loss: 2.0954
Epoch 68/100, Batch 410/549, Loss: 2.0416
Epoch 68/100, Batch 420/549, Loss: 2.0731
Epoch 68/100, Batch 430/549, Loss: 2.1414
Epoch 68/100, Batch 440/549, Loss: 2.1012
Epoch 68/100, Batch 450/549, Loss: 2.0761
Epoch 68/100, Batch 460/549, Loss: 2.0497
Epoch 68/100, Batch 470/549, Loss: 2.0078
Epoch 68/100, Batch 480/549, Loss: 2.0157
Epoch 68/100, Batch 490/549, Loss: 2.1092
Epoch 68/100, Batch 500/549, Loss: 2.0111
Epoch 68/100, Batch 510/549, Loss: 2.0741
Epoch 68/100, Batch 520/549, Loss: 2.0828
Epoch 68/100, Batch 530/549, Loss: 2.0091
Epoch 68/100, Batch 540/549, Loss: 1.9770
Epoch 68/100, Loss: 2.0578, Perplexity: 7.83, Val Loss: 2.0283, Val Perplexity: 7.60, Time: 1087.42s
Epoch 69/100, Batch 10/549, Loss: 1.9921
Epoch 69/100, Batch 20/549, Loss: 2.0912
Epoch 69/100, Batch 30/549, Loss: 2.0904
Epoch 69/100, Batch 40/549, Loss: 2.0812
Epoch 69/100, Batch 50/549, Loss: 2.0493
Epoch 69/100, Batch 60/549, Loss: 1.9420
Epoch 69/100, Batch 70/549, Loss: 2.0792
Epoch 69/100, Batch 80/549, Loss: 2.0418
Epoch 69/100, Batch 90/549, Loss: 2.0258
Epoch 69/100, Batch 100/549, Loss: 2.1027
Epoch 69/100, Batch 110/549, Loss: 2.1025
Epoch 69/100, Batch 120/549, Loss: 2.1530
Epoch 69/100, Batch 130/549, Loss: 2.0376
Epoch 69/100, Batch 140/549, Loss: 2.0443
Epoch 69/100, Batch 150/549, Loss: 2.0926
Epoch 69/100, Batch 160/549, Loss: 2.0824
Epoch 69/100, Batch 170/549, Loss: 2.0505
Epoch 69/100, Batch 180/549, Loss: 2.0571
Epoch 69/100, Batch 190/549, Loss: 2.0374
Epoch 69/100, Batch 200/549, Loss: 2.0356
Epoch 69/100, Batch 210/549, Loss: 2.0158
Epoch 69/100, Batch 220/549, Loss: 2.0042
Epoch 69/100, Batch 230/549, Loss: 2.1008
Epoch 69/100, Batch 240/549, Loss: 1.9615
Epoch 69/100, Batch 250/549, Loss: 1.9753
Epoch 69/100, Batch 260/549, Loss: 1.9733
Epoch 69/100, Batch 270/549, Loss: 2.0516
Epoch 69/100, Batch 280/549, Loss: 2.0320
Epoch 69/100, Batch 290/549, Loss: 2.0377
Epoch 69/100, Batch 300/549, Loss: 2.0886
Epoch 69/100, Batch 310/549, Loss: 2.0595
Epoch 69/100, Batch 320/549, Loss: 1.9658
Epoch 69/100, Batch 330/549, Loss: 1.9772
Epoch 69/100, Batch 340/549, Loss: 2.0420
Epoch 69/100, Batch 350/549, Loss: 2.1501
Epoch 69/100, Batch 360/549, Loss: 2.0856
Epoch 69/100, Batch 370/549, Loss: 1.9848
Epoch 69/100, Batch 380/549, Loss: 2.1667
Epoch 69/100, Batch 390/549, Loss: 2.1534
Epoch 69/100, Batch 400/549, Loss: 2.0901
Epoch 69/100, Batch 410/549, Loss: 2.0805
Epoch 69/100, Batch 420/549, Loss: 2.0714
Epoch 69/100, Batch 430/549, Loss: 2.1469
Epoch 69/100, Batch 440/549, Loss: 2.0516
Epoch 69/100, Batch 450/549, Loss: 2.0699
Epoch 69/100, Batch 460/549, Loss: 2.0505
Epoch 69/100, Batch 470/549, Loss: 1.9960
Epoch 69/100, Batch 480/549, Loss: 2.0188
Epoch 69/100, Batch 490/549, Loss: 2.0989
Epoch 69/100, Batch 500/549, Loss: 2.0080
Epoch 69/100, Batch 510/549, Loss: 2.0719
Epoch 69/100, Batch 520/549, Loss: 2.0264
Epoch 69/100, Batch 530/549, Loss: 2.0025
Epoch 69/100, Batch 540/549, Loss: 1.9980
Epoch 69/100, Loss: 2.0550, Perplexity: 7.81, Val Loss: 2.0321, Val Perplexity: 7.63, Time: 1089.26s
Epoch 70/100, Batch 10/549, Loss: 2.0012
Epoch 70/100, Batch 20/549, Loss: 2.0818
Epoch 70/100, Batch 30/549, Loss: 2.0950
Epoch 70/100, Batch 40/549, Loss: 2.0626
Epoch 70/100, Batch 50/549, Loss: 1.9944
Epoch 70/100, Batch 60/549, Loss: 1.9308
Epoch 70/100, Batch 70/549, Loss: 2.0307
Epoch 70/100, Batch 80/549, Loss: 2.0200
Epoch 70/100, Batch 90/549, Loss: 2.0310
Epoch 70/100, Batch 100/549, Loss: 2.0971
Epoch 70/100, Batch 110/549, Loss: 2.1124
Epoch 70/100, Batch 120/549, Loss: 2.1240
Epoch 70/100, Batch 130/549, Loss: 2.0323
Epoch 70/100, Batch 140/549, Loss: 2.0112
Epoch 70/100, Batch 150/549, Loss: 2.0911
Epoch 70/100, Batch 160/549, Loss: 2.0409
Epoch 70/100, Batch 170/549, Loss: 2.0421
Epoch 70/100, Batch 180/549, Loss: 2.0376
Epoch 70/100, Batch 190/549, Loss: 1.9829
Epoch 70/100, Batch 200/549, Loss: 2.0311
Epoch 70/100, Batch 210/549, Loss: 2.1474
Epoch 70/100, Batch 220/549, Loss: 1.9962
Epoch 70/100, Batch 230/549, Loss: 2.0547
Epoch 70/100, Batch 240/549, Loss: 1.9914
Epoch 70/100, Batch 250/549, Loss: 2.0097
Epoch 70/100, Batch 260/549, Loss: 1.9640
Epoch 70/100, Batch 270/549, Loss: 2.0408
Epoch 70/100, Batch 280/549, Loss: 2.0314
Epoch 70/100, Batch 290/549, Loss: 1.9964
Epoch 70/100, Batch 300/549, Loss: 2.0829
Epoch 70/100, Batch 310/549, Loss: 2.0635
Epoch 70/100, Batch 320/549, Loss: 1.9667
Epoch 70/100, Batch 330/549, Loss: 1.9580
Epoch 70/100, Batch 340/549, Loss: 2.0191
Epoch 70/100, Batch 350/549, Loss: 2.0848
Epoch 70/100, Batch 360/549, Loss: 2.0850
Epoch 70/100, Batch 370/549, Loss: 1.9775
Epoch 70/100, Batch 380/549, Loss: 2.1083
Epoch 70/100, Batch 390/549, Loss: 2.1005
Epoch 70/100, Batch 400/549, Loss: 2.0970
Epoch 70/100, Batch 410/549, Loss: 2.0422
Epoch 70/100, Batch 420/549, Loss: 2.0601
Epoch 70/100, Batch 430/549, Loss: 2.1234
Epoch 70/100, Batch 440/549, Loss: 2.0523
Epoch 70/100, Batch 450/549, Loss: 2.0572
Epoch 70/100, Batch 460/549, Loss: 2.0516
Epoch 70/100, Batch 470/549, Loss: 2.0031
Epoch 70/100, Batch 480/549, Loss: 2.0115
Epoch 70/100, Batch 490/549, Loss: 2.0977
Epoch 70/100, Batch 500/549, Loss: 2.0139
Epoch 70/100, Batch 510/549, Loss: 2.0667
Epoch 70/100, Batch 520/549, Loss: 2.0039
Epoch 70/100, Batch 530/549, Loss: 1.9957
Epoch 70/100, Batch 540/549, Loss: 1.9885
Epoch 70/100, Loss: 2.0498, Perplexity: 7.77, Val Loss: 2.0310, Val Perplexity: 7.62, Time: 1090.89s
Epoch 71/100, Batch 10/549, Loss: 1.9856
Epoch 71/100, Batch 20/549, Loss: 2.1521
Epoch 71/100, Batch 30/549, Loss: 2.1823
Epoch 71/100, Batch 40/549, Loss: 2.0422
Epoch 71/100, Batch 50/549, Loss: 1.9896
Epoch 71/100, Batch 60/549, Loss: 1.9278
Epoch 71/100, Batch 70/549, Loss: 2.0270
Epoch 71/100, Batch 80/549, Loss: 2.0254
Epoch 71/100, Batch 90/549, Loss: 2.0365
Epoch 71/100, Batch 100/549, Loss: 2.0822
Epoch 71/100, Batch 110/549, Loss: 2.0940
Epoch 71/100, Batch 120/549, Loss: 2.1154
Epoch 71/100, Batch 130/549, Loss: 2.0344
Epoch 71/100, Batch 140/549, Loss: 2.0094
Epoch 71/100, Batch 150/549, Loss: 2.1380
Epoch 71/100, Batch 160/549, Loss: 2.0595
Epoch 71/100, Batch 170/549, Loss: 2.0692
Epoch 71/100, Batch 180/549, Loss: 2.0445
Epoch 71/100, Batch 190/549, Loss: 2.0288
Epoch 71/100, Batch 200/549, Loss: 2.0244
Epoch 71/100, Batch 210/549, Loss: 2.0069
Epoch 71/100, Batch 220/549, Loss: 2.0017
Epoch 71/100, Batch 230/549, Loss: 2.0473
Epoch 71/100, Batch 240/549, Loss: 1.9563
Epoch 71/100, Batch 250/549, Loss: 1.9581
Epoch 71/100, Batch 260/549, Loss: 2.0101
Epoch 71/100, Batch 270/549, Loss: 2.0308
Epoch 71/100, Batch 280/549, Loss: 2.0330
Epoch 71/100, Batch 290/549, Loss: 1.9802
Epoch 71/100, Batch 300/549, Loss: 2.1236
Epoch 71/100, Batch 310/549, Loss: 2.0898
Epoch 71/100, Batch 320/549, Loss: 1.9826
Epoch 71/100, Batch 330/549, Loss: 1.9532
Epoch 71/100, Batch 340/549, Loss: 2.0052
Epoch 71/100, Batch 350/549, Loss: 2.0736
Epoch 71/100, Batch 360/549, Loss: 2.0801
Epoch 71/100, Batch 370/549, Loss: 1.9685
Epoch 71/100, Batch 380/549, Loss: 2.0545
Epoch 71/100, Batch 390/549, Loss: 2.0251
Epoch 71/100, Batch 400/549, Loss: 2.0816
Epoch 71/100, Batch 410/549, Loss: 2.0448
Epoch 71/100, Batch 420/549, Loss: 2.0592
Epoch 71/100, Batch 430/549, Loss: 2.1308
Epoch 71/100, Batch 440/549, Loss: 2.0713
Epoch 71/100, Batch 450/549, Loss: 2.0771
Epoch 71/100, Batch 460/549, Loss: 2.0370
Epoch 71/100, Batch 470/549, Loss: 2.1071
Epoch 71/100, Batch 480/549, Loss: 2.0077
Epoch 71/100, Batch 490/549, Loss: 2.0969
Epoch 71/100, Batch 500/549, Loss: 2.0526
Epoch 71/100, Batch 510/549, Loss: 2.0689
Epoch 71/100, Batch 520/549, Loss: 2.0144
Epoch 71/100, Batch 530/549, Loss: 2.0013
Epoch 71/100, Batch 540/549, Loss: 1.9903
Epoch 71/100, Loss: 2.0491, Perplexity: 7.76, Val Loss: 2.0302, Val Perplexity: 7.62, Time: 1082.25s
Epoch 72/100, Batch 10/549, Loss: 1.9825
Epoch 72/100, Batch 20/549, Loss: 2.0911
Epoch 72/100, Batch 30/549, Loss: 2.0978
Epoch 72/100, Batch 40/549, Loss: 2.0482
Epoch 72/100, Batch 50/549, Loss: 1.9881
Epoch 72/100, Batch 60/549, Loss: 1.9340
Epoch 72/100, Batch 70/549, Loss: 2.0220
Epoch 72/100, Batch 80/549, Loss: 2.0673
Epoch 72/100, Batch 90/549, Loss: 2.0280
Epoch 72/100, Batch 100/549, Loss: 2.0739
Epoch 72/100, Batch 110/549, Loss: 2.1084
Epoch 72/100, Batch 120/549, Loss: 2.1124
Epoch 72/100, Batch 130/549, Loss: 2.0298
Epoch 72/100, Batch 140/549, Loss: 2.0044
Epoch 72/100, Batch 150/549, Loss: 2.0880
Epoch 72/100, Batch 160/549, Loss: 2.0484
Epoch 72/100, Batch 170/549, Loss: 2.0369
Epoch 72/100, Batch 180/549, Loss: 2.0387
Epoch 72/100, Batch 190/549, Loss: 1.9785
Epoch 72/100, Batch 200/549, Loss: 2.0736
Epoch 72/100, Batch 210/549, Loss: 2.0160
Epoch 72/100, Batch 220/549, Loss: 1.9948
Epoch 72/100, Batch 230/549, Loss: 2.0537
Epoch 72/100, Batch 240/549, Loss: 1.9467
Epoch 72/100, Batch 250/549, Loss: 2.0088
Epoch 72/100, Batch 260/549, Loss: 1.9968
Epoch 72/100, Batch 270/549, Loss: 2.0354
Epoch 72/100, Batch 280/549, Loss: 2.0342
Epoch 72/100, Batch 290/549, Loss: 2.0117
Epoch 72/100, Batch 300/549, Loss: 2.0967
Epoch 72/100, Batch 310/549, Loss: 2.1360
Epoch 72/100, Batch 320/549, Loss: 1.9683
Epoch 72/100, Batch 330/549, Loss: 1.9634
Epoch 72/100, Batch 340/549, Loss: 2.0110
Epoch 72/100, Batch 350/549, Loss: 2.0766
Epoch 72/100, Batch 360/549, Loss: 2.0794
Epoch 72/100, Batch 370/549, Loss: 1.9958
Epoch 72/100, Batch 380/549, Loss: 2.0520
Epoch 72/100, Batch 390/549, Loss: 2.0288
Epoch 72/100, Batch 400/549, Loss: 2.0709
Epoch 72/100, Batch 410/549, Loss: 2.0247
Epoch 72/100, Batch 420/549, Loss: 2.0748
Epoch 72/100, Batch 430/549, Loss: 2.1430
Epoch 72/100, Batch 440/549, Loss: 2.0445
Epoch 72/100, Batch 450/549, Loss: 2.0921
Epoch 72/100, Batch 460/549, Loss: 2.0569
Epoch 72/100, Batch 470/549, Loss: 1.9896
Epoch 72/100, Batch 480/549, Loss: 2.0078
Epoch 72/100, Batch 490/549, Loss: 2.1230
Epoch 72/100, Batch 500/549, Loss: 2.0049
Epoch 72/100, Batch 510/549, Loss: 2.0613
Epoch 72/100, Batch 520/549, Loss: 1.9976
Epoch 72/100, Batch 530/549, Loss: 1.9903
Epoch 72/100, Batch 540/549, Loss: 1.9723
No improvement for 8 epochs. Early stopping.
Loaded best model with validation loss: 2.0256, perplexity: 7.58

Training visualization saved to enhanced_char_transformer_loss.png

=== Generating Text ===
Prompt: The quick brown fox
Generated: The quick brown fox at the [[Spanish Civil War]]. His famous succession, he was adopted by [[Alexander III of Portugal|Alexander III]] in 1862.

His father's concept was the first [[Church of England|Church of England]] as the [[United States Democratic Republic]] of [[James Lewis III of Portugal|James Lewis]] (which was a [[Fortunate States Democratic Party|Fortunate]] of [[Cape Canaveral]]).

==References==
*{{1911}}

[[Category:1743 births|Alexander III, Alexander III]]
[[Category:1865 deaths|Alexander III of P
Model saved to enhanced_char_transformer_model.pt

=== Generating with Different Temperatures ===

Temperature: 0.5
Generated: The quick brown fox attacks to [[Apple II]], and the Apple II compatible was the first compatible machine computer.

===Process program===
The Apple II was processor at the [[Macintosh IIc]] for [[Software Language|Software]] [[International Phonetic Alphabet|IPA]] to computers with [[Software Language|Software]] and [[International Phonetic Alphabet|IPA]] alphabet. The Apple II was the last computer system that would be involved in the [[Apple II Plus]] and the [[Apple II Plus]] in [[1976]]. The Apple II was the 

Temperature: 0.7
Generated: The quick brown fox in the film.

==Major works==
*[http://www.androga.org/ Androga Ga] - The film ''[[Iliad Roga]]''
*[http://www.androga-info/ Androga Info] - An animal to website of an Androga Info
*[http://www.androga-info.org/ Androga Info] - An animal to website
*[http://www.androga-info.org/ Androga Info] - An animal to website
*[http://www.androga-info.org/ Androga Info] - An animal to website
*[http://www.androgacorg/ Androga Environment] - Character of an Androga Info
*[http://www.androgacorg/ Androga Or

Temperature: 0.9
Generated: The quick brown fox lasting people who had been re-used, an [[Office of Commonwealth]] carried a defendant in [[1927]] to give a capacity with a small green-defense.

In 1937, Maria Cornelius accepted a capacity of founders for the [[Confederacy]] at the [[University of Finland]]. She had taken a whole child directly in over her husband.

==References==
*{{1911}}

{{s-start}}
{{s-bef|right|2005|Alexander Hoffman Democratic}}
{{s-ttl|title=[[King's Labour]]|years=1878–1882}}
{| border=&quot;1&quot; cellpadding=&quo
